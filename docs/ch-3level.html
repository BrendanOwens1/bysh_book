<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Broadening Your Statistical Horizons</title>
  <meta name="description" content="Test.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Broadening Your Statistical Horizons" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Test." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Broadening Your Statistical Horizons" />
  
  <meta name="twitter:description" content="Test." />
  

<meta name="author" content="J. Legler and P. Roback">


<meta name="date" content="2018-02-02">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="ch-lon.html">
<link rel="next" href="ch-GLMM.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Broadening Your Statistical Horizons</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html"><i class="fa fa-check"></i><b>1</b> Review of Multiple Linear Regression</a><ul>
<li class="chapter" data-level="1.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="1.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#introduction"><i class="fa fa-check"></i><b>1.2</b> Introduction</a></li>
<li class="chapter" data-level="1.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#ordinary-least-squares-ols-assumptions"><i class="fa fa-check"></i><b>1.3</b> Ordinary Least Squares (OLS) Assumptions</a><ul>
<li class="chapter" data-level="1.3.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#cases-that-do-not-violate-the-ols-assumptions-for-inference"><i class="fa fa-check"></i><b>1.3.1</b> Cases that do not violate the OLS assumptions for inference</a></li>
<li class="chapter" data-level="1.3.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#cases-where-the-ols-assumptions-for-inference-are-violated"><i class="fa fa-check"></i><b>1.3.2</b> Cases where the OLS assumptions for inference are violated</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#cs:derby"><i class="fa fa-check"></i><b>1.4</b> Case Study: Kentucky Derby</a></li>
<li class="chapter" data-level="1.5" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#explore"><i class="fa fa-check"></i><b>1.5</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="1.5.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#data-organization"><i class="fa fa-check"></i><b>1.5.1</b> Data Organization</a></li>
<li class="chapter" data-level="1.5.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#univariate-summaries"><i class="fa fa-check"></i><b>1.5.2</b> Univariate Summaries</a></li>
<li class="chapter" data-level="1.5.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#bivariate-summaries"><i class="fa fa-check"></i><b>1.5.3</b> Bivariate Summaries</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multreg"><i class="fa fa-check"></i><b>1.6</b> Multiple linear regression modeling</a><ul>
<li class="chapter" data-level="1.6.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#SLRcontinuous"><i class="fa fa-check"></i><b>1.6.1</b> Simple linear regression with a continuous predictor</a></li>
<li class="chapter" data-level="1.6.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#simple-linear-regression-with-a-binary-predictor"><i class="fa fa-check"></i><b>1.6.2</b> Simple linear regression with a binary predictor</a></li>
<li class="chapter" data-level="1.6.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multiple-linear-regression-with-two-predictors"><i class="fa fa-check"></i><b>1.6.3</b> Multiple linear regression with two predictors</a></li>
<li class="chapter" data-level="1.6.4" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multreg-inference"><i class="fa fa-check"></i><b>1.6.4</b> Inference in multiple linear regression</a></li>
<li class="chapter" data-level="1.6.5" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multiple-linear-regression-with-an-interaction-term"><i class="fa fa-check"></i><b>1.6.5</b> Multiple linear regression with an interaction term</a></li>
<li class="chapter" data-level="1.6.6" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multreg_build"><i class="fa fa-check"></i><b>1.6.6</b> Building a multiple linear regression model</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#preview"><i class="fa fa-check"></i><b>1.7</b> Preview</a><ul>
<li class="chapter" data-level="1.7.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#soccer"><i class="fa fa-check"></i><b>1.7.1</b> Soccer</a></li>
<li class="chapter" data-level="1.7.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#elephant-mating"><i class="fa fa-check"></i><b>1.7.2</b> Elephant Mating</a></li>
<li class="chapter" data-level="1.7.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#parenting-and-gang-activity"><i class="fa fa-check"></i><b>1.7.3</b> Parenting and Gang Activity</a></li>
<li class="chapter" data-level="1.7.4" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#crime"><i class="fa fa-check"></i><b>1.7.4</b> Crime</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a><ul>
<li class="chapter" data-level="1.8.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#conceptual-exercises"><i class="fa fa-check"></i><b>1.8.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="1.8.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#guided-exercise"><i class="fa fa-check"></i><b>1.8.2</b> Guided Exercise</a></li>
<li class="chapter" data-level="1.8.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#open-ended-exercises"><i class="fa fa-check"></i><b>1.8.3</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html"><i class="fa fa-check"></i><b>2</b> Beyond Least Squares: Using Likelihoods to Fit and Compare Models</a><ul>
<li class="chapter" data-level="2.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#learning-objectives-1"><i class="fa fa-check"></i><b>2.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#case-study-does-sex-run-in-families"><i class="fa fa-check"></i><b>2.2</b> Case Study: Does sex run in families?</a><ul>
<li class="chapter" data-level="2.2.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#research-questions"><i class="fa fa-check"></i><b>2.2.1</b> Research Questions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-0-sex-unconditional-model-equal-probabilities-independence"><i class="fa fa-check"></i><b>2.3</b> Model 0: Sex Unconditional Model (Equal probabilities, Independence)</a></li>
<li class="chapter" data-level="2.4" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#sex_unconditional_model"><i class="fa fa-check"></i><b>2.4</b> Model 1: Sex Unconditional Model (Any Probability, Independence) and the Principle of Maximum Likelihood</a><ul>
<li class="chapter" data-level="2.4.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#what-is-a-likelihood"><i class="fa fa-check"></i><b>2.4.1</b> What is a likelihood?</a></li>
<li class="chapter" data-level="2.4.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#findMLE.sec"><i class="fa fa-check"></i><b>2.4.2</b> Finding MLEs</a></li>
<li class="chapter" data-level="2.4.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#summary"><i class="fa fa-check"></i><b>2.4.3</b> Summary</a></li>
<li class="chapter" data-level="2.4.4" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#is-a-likelihood-a-probability-function-optional"><i class="fa fa-check"></i><b>2.4.4</b> Is a likelihood a probability function? (Optional)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#sex_conditional.sec"><i class="fa fa-check"></i><b>2.5</b> Model 2: A Sex Conditional Model (Sex Bias) and Model Specification</a><ul>
<li class="chapter" data-level="2.5.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-specification"><i class="fa fa-check"></i><b>2.5.1</b> Model Specification</a></li>
<li class="chapter" data-level="2.5.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#application-to-hypothetical-data"><i class="fa fa-check"></i><b>2.5.2</b> Application to Hypothetical Data</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#case-study-analysis-of-the-nlsy-data"><i class="fa fa-check"></i><b>2.6</b> Case Study: Analysis of the NLSY data</a><ul>
<li class="chapter" data-level="2.6.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-building-plan"><i class="fa fa-check"></i><b>2.6.1</b> Model Building Plan</a></li>
<li class="chapter" data-level="2.6.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#EDA.sec"><i class="fa fa-check"></i><b>2.6.2</b> Family Composition of Boys and Girls, NLSY: Exploratory Data Analysis</a></li>
<li class="chapter" data-level="2.6.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#likelihood-for-the-sex-unconditional-model-the-nlsy-data"><i class="fa fa-check"></i><b>2.6.3</b> Likelihood for the Sex Unconditional Model: the NLSY data</a></li>
<li class="chapter" data-level="2.6.4" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#sex_cond_lik.sec"><i class="fa fa-check"></i><b>2.6.4</b> Likelihood for the Sex Conditional Model</a></li>
<li class="chapter" data-level="2.6.5" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#comparing-the-sex-unconditional-to-the-sex-conditional-model"><i class="fa fa-check"></i><b>2.6.5</b> Comparing the Sex Unconditional to the Sex Conditional Model</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-3-stopping-rule-model-waiting-for-a-boy"><i class="fa fa-check"></i><b>2.7</b> Model 3: Stopping Rule Model (Waiting for a boy)</a><ul>
<li class="chapter" data-level="2.7.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#non-nested-models"><i class="fa fa-check"></i><b>2.7.1</b> Non-nested Models</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#summary-of-model-building"><i class="fa fa-check"></i><b>2.8</b> Summary of Model Building</a></li>
<li class="chapter" data-level="2.9" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#likelihood-based-methods"><i class="fa fa-check"></i><b>2.9</b> Likelihood-based Methods</a></li>
<li class="chapter" data-level="2.10" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#likelihoods-and-this-course"><i class="fa fa-check"></i><b>2.10</b> Likelihoods and this Course</a></li>
<li class="chapter" data-level="2.11" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#exercises-1"><i class="fa fa-check"></i><b>2.11</b> Exercises</a><ul>
<li class="chapter" data-level="2.11.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#conceptual-exercises-1"><i class="fa fa-check"></i><b>2.11.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="2.11.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#guided-exercise-1"><i class="fa fa-check"></i><b>2.11.2</b> Guided Exercise</a></li>
<li class="chapter" data-level="2.11.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#open-ended-exercise"><i class="fa fa-check"></i><b>2.11.3</b> Open-ended Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch-distthry.html"><a href="ch-distthry.html"><i class="fa fa-check"></i><b>3</b> Distribution Theory</a><ul>
<li class="chapter" data-level="3.1" data-path="ch-distthry.html"><a href="ch-distthry.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a><ul>
<li class="chapter" data-level="3.1.1" data-path="ch-distthry.html"><a href="ch-distthry.html#characteristics-of-random-variables"><i class="fa fa-check"></i><b>3.1.1</b> Characteristics of Random Variables</a></li>
<li class="chapter" data-level="3.1.2" data-path="ch-distthry.html"><a href="ch-distthry.html#location-scale-and-shape-parameters"><i class="fa fa-check"></i><b>3.1.2</b> Location, scale and shape parameters</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="ch-distthry.html"><a href="ch-distthry.html#modeling-responses"><i class="fa fa-check"></i><b>3.2</b> Modeling Responses</a><ul>
<li class="chapter" data-level="3.2.1" data-path="ch-distthry.html"><a href="ch-distthry.html#discrete-random-variables"><i class="fa fa-check"></i><b>3.2.1</b> Discrete Random Variables</a></li>
<li class="chapter" data-level="3.2.2" data-path="ch-distthry.html"><a href="ch-distthry.html#bernoulli-process"><i class="fa fa-check"></i><b>3.2.2</b> Bernoulli Process</a></li>
<li class="chapter" data-level="3.2.3" data-path="ch-distthry.html"><a href="ch-distthry.html#poisson-process"><i class="fa fa-check"></i><b>3.2.3</b> Poisson Process</a></li>
<li class="chapter" data-level="3.2.4" data-path="ch-distthry.html"><a href="ch-distthry.html#continuous-random-variables"><i class="fa fa-check"></i><b>3.2.4</b> Continuous Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ch-distthry.html"><a href="ch-distthry.html#distributions-used-in-testing"><i class="fa fa-check"></i><b>3.3</b> Distributions used in Testing</a><ul>
<li class="chapter" data-level="3.3.1" data-path="ch-distthry.html"><a href="ch-distthry.html#chi2"><i class="fa fa-check"></i><b>3.3.1</b> <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="3.3.2" data-path="ch-distthry.html"><a href="ch-distthry.html#f"><i class="fa fa-check"></i><b>3.3.2</b> F</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ch-distthry.html"><a href="ch-distthry.html#mixtures"><i class="fa fa-check"></i><b>3.4</b> Mixtures</a><ul>
<li class="chapter" data-level="3.4.1" data-path="ch-distthry.html"><a href="ch-distthry.html#zero-inflated-poisson"><i class="fa fa-check"></i><b>3.4.1</b> Zero-inflated Poisson</a></li>
<li class="chapter" data-level="3.4.2" data-path="ch-distthry.html"><a href="ch-distthry.html#mixture-of-two-normal-distributions"><i class="fa fa-check"></i><b>3.4.2</b> Mixture of Two Normal Distributions</a></li>
<li class="chapter" data-level="3.4.3" data-path="ch-distthry.html"><a href="ch-distthry.html#beta-binomial"><i class="fa fa-check"></i><b>3.4.3</b> Beta-Binomial</a></li>
<li class="chapter" data-level="3.4.4" data-path="ch-distthry.html"><a href="ch-distthry.html#negative-binomial-1"><i class="fa fa-check"></i><b>3.4.4</b> Negative Binomial</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ch-distthry.html"><a href="ch-distthry.html#exercises-2"><i class="fa fa-check"></i><b>3.5</b> Exercises</a><ul>
<li class="chapter" data-level="3.5.1" data-path="ch-distthry.html"><a href="ch-distthry.html#conceptual-exercises-2"><i class="fa fa-check"></i><b>3.5.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="3.5.2" data-path="ch-distthry.html"><a href="ch-distthry.html#guided-exercises"><i class="fa fa-check"></i><b>3.5.2</b> Guided Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html"><i class="fa fa-check"></i><b>4</b> Poisson Regression</a><ul>
<li class="chapter" data-level="4.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#learning-objectives-2"><i class="fa fa-check"></i><b>4.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#preface-1"><i class="fa fa-check"></i><b>4.2</b> Preface</a></li>
<li class="chapter" data-level="4.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#poisintrosec"><i class="fa fa-check"></i><b>4.3</b> Introduction to Poisson Regression</a><ul>
<li class="chapter" data-level="4.3.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#initial-examples"><i class="fa fa-check"></i><b>4.3.1</b> Initial Examples</a></li>
<li class="chapter" data-level="4.3.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-Prop"><i class="fa fa-check"></i><b>4.3.2</b> Poisson Random Variables</a></li>
<li class="chapter" data-level="4.3.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#modeling-with-poisson-variables"><i class="fa fa-check"></i><b>4.3.3</b> Modeling with Poisson variables</a></li>
<li class="chapter" data-level="4.3.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#a-graphical-look-at-poisson-regression"><i class="fa fa-check"></i><b>4.3.4</b> A Graphical Look at Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#case-studies-overview"><i class="fa fa-check"></i><b>4.4</b> Case Studies Overview</a></li>
<li class="chapter" data-level="4.5" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#case-study-household-size-in-haiti"><i class="fa fa-check"></i><b>4.5</b> Case Study: Household Size in Haiti</a><ul>
<li class="chapter" data-level="4.5.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#research-question"><i class="fa fa-check"></i><b>4.5.1</b> Research Question</a></li>
<li class="chapter" data-level="4.5.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#data-collection"><i class="fa fa-check"></i><b>4.5.2</b> Data Collection</a></li>
<li class="chapter" data-level="4.5.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#data-organization-1"><i class="fa fa-check"></i><b>4.5.3</b> Data Organization</a></li>
<li class="chapter" data-level="4.5.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>4.5.4</b> Exploratory Data Analysis</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#likelihood.sec"><i class="fa fa-check"></i><b>4.6</b> Using Likelihoods to fit Poisson Regression Models (Optional)</a></li>
<li class="chapter" data-level="4.7" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#modeling"><i class="fa fa-check"></i><b>4.7</b> Modeling</a><ul>
<li class="chapter" data-level="4.7.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#first-order-model"><i class="fa fa-check"></i><b>4.7.1</b> First Order Model</a></li>
<li class="chapter" data-level="4.7.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-PoisInference"><i class="fa fa-check"></i><b>4.7.2</b> Estimation and Inference</a></li>
<li class="chapter" data-level="4.7.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#using-deviances-to-compare-models"><i class="fa fa-check"></i><b>4.7.3</b> Using Deviances to Compare Models</a></li>
<li class="chapter" data-level="4.7.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#poisson-regression-assumptions-1"><i class="fa fa-check"></i><b>4.7.4</b> Poisson Regression Assumptions</a></li>
<li class="chapter" data-level="4.7.5" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#residual-plot"><i class="fa fa-check"></i><b>4.7.5</b> Residual Plot</a></li>
<li class="chapter" data-level="4.7.6" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#residuals-for-poisson-models-optional"><i class="fa fa-check"></i><b>4.7.6</b> Residuals for Poisson Models (Optional)</a></li>
<li class="chapter" data-level="4.7.7" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#second-order-model"><i class="fa fa-check"></i><b>4.7.7</b> Second Order Model</a></li>
<li class="chapter" data-level="4.7.8" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#finding-the-age-where-the-number-in-the-house-is-a-maximum"><i class="fa fa-check"></i><b>4.7.8</b> Finding the age where the number in the house is a maximum</a></li>
<li class="chapter" data-level="4.7.9" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#adding-a-covariate"><i class="fa fa-check"></i><b>4.7.9</b> Adding a covariate</a></li>
<li class="chapter" data-level="4.7.10" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-PoisGOF"><i class="fa fa-check"></i><b>4.7.10</b> Goodness-of-fit</a></li>
<li class="chapter" data-level="4.7.11" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#least-squares-regression-vs.poisson-regression"><i class="fa fa-check"></i><b>4.7.11</b> Least Squares Regression vs. Poisson Regression</a></li>
<li class="chapter" data-level="4.7.12" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#optional-topics-to-be-developed"><i class="fa fa-check"></i><b>4.7.12</b> Optional topics to be developed</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#case-study-campus-crime"><i class="fa fa-check"></i><b>4.8</b> Case Study: Campus Crime</a></li>
<li class="chapter" data-level="4.9" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#analysis-for-crime-data"><i class="fa fa-check"></i><b>4.9</b> Analysis for crime data</a><ul>
<li class="chapter" data-level="4.9.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#research-question-1"><i class="fa fa-check"></i><b>4.9.1</b> Research Question</a></li>
<li class="chapter" data-level="4.9.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#data-organization-2"><i class="fa fa-check"></i><b>4.9.2</b> Data Organization</a></li>
<li class="chapter" data-level="4.9.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exploratory-data-analysis-1"><i class="fa fa-check"></i><b>4.9.3</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="4.9.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#accounting-for-enrollment"><i class="fa fa-check"></i><b>4.9.4</b> Accounting for Enrollment</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#checking-assumptions"><i class="fa fa-check"></i><b>4.10</b> Checking Assumptions</a><ul>
<li class="chapter" data-level="4.10.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#is-the-mean-equal-to-the-variance"><i class="fa fa-check"></i><b>4.10.1</b> Is the Mean equal to the Variance?</a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#modeling-1"><i class="fa fa-check"></i><b>4.11</b> Modeling</a></li>
<li class="chapter" data-level="4.12" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-overdispPois"><i class="fa fa-check"></i><b>4.12</b> Overdispersion</a><ul>
<li class="chapter" data-level="4.12.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#dispersion-parameter-adjustment"><i class="fa fa-check"></i><b>4.12.1</b> Dispersion parameter adjustment</a></li>
<li class="chapter" data-level="4.12.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#negative-binomial-modeling"><i class="fa fa-check"></i><b>4.12.2</b> Negative binomial modeling</a></li>
</ul></li>
<li class="chapter" data-level="4.13" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#case-study-weekend-drinking-csdrinking"><i class="fa fa-check"></i><b>4.13</b> Case Study: Weekend drinking {cs:drinking}</a><ul>
<li class="chapter" data-level="4.13.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#research-question-2"><i class="fa fa-check"></i><b>4.13.1</b> Research Question</a></li>
<li class="chapter" data-level="4.13.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#data-organization-3"><i class="fa fa-check"></i><b>4.13.2</b> Data Organization</a></li>
<li class="chapter" data-level="4.13.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exploratory-data-analysis-2"><i class="fa fa-check"></i><b>4.13.3</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="4.13.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#modeling-2"><i class="fa fa-check"></i><b>4.13.4</b> Modeling</a></li>
<li class="chapter" data-level="4.13.5" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#fitting-a-zip-model"><i class="fa fa-check"></i><b>4.13.5</b> Fitting a ZIP Model</a></li>
<li class="chapter" data-level="4.13.6" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#comparing-the-ordinary-poisson-regression-model-to-the-zip-model"><i class="fa fa-check"></i><b>4.13.6</b> Comparing the ordinary Poisson regression model to the ZIP model</a></li>
<li class="chapter" data-level="4.13.7" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#residual-plot-1"><i class="fa fa-check"></i><b>4.13.7</b> Residual Plot</a></li>
<li class="chapter" data-level="4.13.8" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#caveats-and-extensions"><i class="fa fa-check"></i><b>4.13.8</b> Caveats and Extensions</a></li>
</ul></li>
<li class="chapter" data-level="4.14" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#references"><i class="fa fa-check"></i><b>4.14</b> References</a></li>
<li class="chapter" data-level="4.15" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exercises-3"><i class="fa fa-check"></i><b>4.15</b> Exercises</a><ul>
<li class="chapter" data-level="4.15.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exer:concept"><i class="fa fa-check"></i><b>4.15.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="4.15.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#guided-exercise-2"><i class="fa fa-check"></i><b>4.15.2</b> Guided Exercise</a></li>
<li class="chapter" data-level="4.15.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#open-ended"><i class="fa fa-check"></i><b>4.15.3</b> Open-ended</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-glms.html"><a href="ch-glms.html"><i class="fa fa-check"></i><b>5</b> Generalized Linear Models (GLMs): A Unifying Theory</a><ul>
<li class="chapter" data-level="5.1" data-path="ch-glms.html"><a href="ch-glms.html#learning-objectives-3"><i class="fa fa-check"></i><b>5.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="ch-glms.html"><a href="ch-glms.html#one-parameter-exponential-families"><i class="fa fa-check"></i><b>5.2</b> One parameter exponential families</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ch-glms.html"><a href="ch-glms.html#one-parameter-exponential-family-possion"><i class="fa fa-check"></i><b>5.2.1</b> One Parameter Exponential Family: Possion</a></li>
<li class="chapter" data-level="5.2.2" data-path="ch-glms.html"><a href="ch-glms.html#one-parameter-exponential-family-normal"><i class="fa fa-check"></i><b>5.2.2</b> One parameter exponential family: Normal</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ch-glms.html"><a href="ch-glms.html#generalized-linear-modeling"><i class="fa fa-check"></i><b>5.3</b> Generalized Linear Modeling</a></li>
<li class="chapter" data-level="5.4" data-path="ch-glms.html"><a href="ch-glms.html#exercises-4"><i class="fa fa-check"></i><b>5.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch-logreg.html"><a href="ch-logreg.html"><i class="fa fa-check"></i><b>6</b> Logistic Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="ch-logreg.html"><a href="ch-logreg.html#learning-objectives-4"><i class="fa fa-check"></i><b>6.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="ch-logreg.html"><a href="ch-logreg.html#introduction-2"><i class="fa fa-check"></i><b>6.2</b> Introduction</a><ul>
<li class="chapter" data-level="6.2.1" data-path="ch-logreg.html"><a href="ch-logreg.html#binary-responses"><i class="fa fa-check"></i><b>6.2.1</b> Binary Responses</a></li>
<li class="chapter" data-level="6.2.2" data-path="ch-logreg.html"><a href="ch-logreg.html#binomial-responses-sums-of-binary-responses"><i class="fa fa-check"></i><b>6.2.2</b> Binomial Responses: sums of binary responses</a></li>
<li class="chapter" data-level="6.2.3" data-path="ch-logreg.html"><a href="ch-logreg.html#an-example-binge-drinking"><i class="fa fa-check"></i><b>6.2.3</b> An Example: Binge Drinking</a></li>
<li class="chapter" data-level="6.2.4" data-path="ch-logreg.html"><a href="ch-logreg.html#a-graphical-look-at-binomial-regression"><i class="fa fa-check"></i><b>6.2.4</b> A Graphical Look at Binomial Regression</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ch-logreg.html"><a href="ch-logreg.html#sec-modelframework"><i class="fa fa-check"></i><b>6.3</b> A Modeling Framework</a></li>
<li class="chapter" data-level="6.4" data-path="ch-logreg.html"><a href="ch-logreg.html#case-studies-overview-1"><i class="fa fa-check"></i><b>6.4</b> Case Studies Overview</a></li>
<li class="chapter" data-level="6.5" data-path="ch-logreg.html"><a href="ch-logreg.html#glm-theory-for-binomial-outcomes"><i class="fa fa-check"></i><b>6.5</b> GLM Theory for Binomial Outcomes</a><ul>
<li class="chapter" data-level="6.5.1" data-path="ch-logreg.html"><a href="ch-logreg.html#case-study-soccer-goalkeeper-saves"><i class="fa fa-check"></i><b>6.5.1</b> Case Study: Soccer Goalkeeper Saves</a></li>
<li class="chapter" data-level="6.5.2" data-path="ch-logreg.html"><a href="ch-logreg.html#research-question-3"><i class="fa fa-check"></i><b>6.5.2</b> Research Question</a></li>
<li class="chapter" data-level="6.5.3" data-path="ch-logreg.html"><a href="ch-logreg.html#data-organization-4"><i class="fa fa-check"></i><b>6.5.3</b> Data Organization</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="ch-logreg.html"><a href="ch-logreg.html#case-study-reconstructing-alabama"><i class="fa fa-check"></i><b>6.6</b> Case Study: Reconstructing Alabama</a><ul>
<li class="chapter" data-level="6.6.1" data-path="ch-logreg.html"><a href="ch-logreg.html#research-question-4"><i class="fa fa-check"></i><b>6.6.1</b> Research Question</a></li>
<li class="chapter" data-level="6.6.2" data-path="ch-logreg.html"><a href="ch-logreg.html#data-organization-5"><i class="fa fa-check"></i><b>6.6.2</b> Data Organization</a></li>
<li class="chapter" data-level="6.6.3" data-path="ch-logreg.html"><a href="ch-logreg.html#exploratory-data-analysis-3"><i class="fa fa-check"></i><b>6.6.3</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="6.6.4" data-path="ch-logreg.html"><a href="ch-logreg.html#modeling-overview"><i class="fa fa-check"></i><b>6.6.4</b> Modeling Overview</a></li>
<li class="chapter" data-level="6.6.5" data-path="ch-logreg.html"><a href="ch-logreg.html#results"><i class="fa fa-check"></i><b>6.6.5</b> Results</a></li>
<li class="chapter" data-level="6.6.6" data-path="ch-logreg.html"><a href="ch-logreg.html#least-squares-regression-vs.logistic-regression"><i class="fa fa-check"></i><b>6.6.6</b> Least Squares Regression vs. Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="ch-logreg.html"><a href="ch-logreg.html#case-study-who-wants-to-lose-weight-sex-media-sports-and-bmi."><i class="fa fa-check"></i><b>6.7</b> Case Study: Who wants to lose weight? Sex, Media, Sports, and BMI.</a><ul>
<li class="chapter" data-level="6.7.1" data-path="ch-logreg.html"><a href="ch-logreg.html#background"><i class="fa fa-check"></i><b>6.7.1</b> Background</a></li>
<li class="chapter" data-level="6.7.2" data-path="ch-logreg.html"><a href="ch-logreg.html#research-questions-1"><i class="fa fa-check"></i><b>6.7.2</b> Research Questions</a></li>
<li class="chapter" data-level="6.7.3" data-path="ch-logreg.html"><a href="ch-logreg.html#data-collection-1"><i class="fa fa-check"></i><b>6.7.3</b> Data Collection</a></li>
<li class="chapter" data-level="6.7.4" data-path="ch-logreg.html"><a href="ch-logreg.html#data-organization-6"><i class="fa fa-check"></i><b>6.7.4</b> Data Organization</a></li>
<li class="chapter" data-level="6.7.5" data-path="ch-logreg.html"><a href="ch-logreg.html#exploratory-data-analysis-4"><i class="fa fa-check"></i><b>6.7.5</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="6.7.6" data-path="ch-logreg.html"><a href="ch-logreg.html#modeling-3"><i class="fa fa-check"></i><b>6.7.6</b> Modeling</a></li>
<li class="chapter" data-level="6.7.7" data-path="ch-logreg.html"><a href="ch-logreg.html#discussion"><i class="fa fa-check"></i><b>6.7.7</b> Discussion</a></li>
<li class="chapter" data-level="6.7.8" data-path="ch-logreg.html"><a href="ch-logreg.html#optional-topics-to-be-developed-1"><i class="fa fa-check"></i><b>6.7.8</b> Optional topics to be developed</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="ch-logreg.html"><a href="ch-logreg.html#references-1"><i class="fa fa-check"></i><b>6.8</b> References</a></li>
<li class="chapter" data-level="6.9" data-path="ch-logreg.html"><a href="ch-logreg.html#exercises-5"><i class="fa fa-check"></i><b>6.9</b> Exercises</a><ul>
<li class="chapter" data-level="6.9.1" data-path="ch-logreg.html"><a href="ch-logreg.html#interpret-article-abstracts"><i class="fa fa-check"></i><b>6.9.1</b> Interpret article abstracts</a></li>
<li class="chapter" data-level="6.9.2" data-path="ch-logreg.html"><a href="ch-logreg.html#guided-exercises-1"><i class="fa fa-check"></i><b>6.9.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="6.9.3" data-path="ch-logreg.html"><a href="ch-logreg.html#open-ended-exercises-1"><i class="fa fa-check"></i><b>6.9.3</b> Open-ended Exercises</a></li>
<li class="chapter" data-level="6.9.4" data-path="ch-logreg.html"><a href="ch-logreg.html#project-ideas"><i class="fa fa-check"></i><b>6.9.4</b> Project Ideas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch-corrdata.html"><a href="ch-corrdata.html"><i class="fa fa-check"></i><b>7</b> Correlated Data</a><ul>
<li class="chapter" data-level="7.1" data-path="ch-corrdata.html"><a href="ch-corrdata.html#learning-objectives-5"><i class="fa fa-check"></i><b>7.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="7.2" data-path="ch-corrdata.html"><a href="ch-corrdata.html#recognizing-correlation"><i class="fa fa-check"></i><b>7.2</b> Recognizing correlation</a></li>
<li class="chapter" data-level="7.3" data-path="ch-corrdata.html"><a href="ch-corrdata.html#case-study-dams-and-pups-correlated-binary-outcomes"><i class="fa fa-check"></i><b>7.3</b> Case Study: Dams and pups, Correlated Binary Outcomes</a><ul>
<li class="chapter" data-level="7.3.1" data-path="ch-corrdata.html"><a href="ch-corrdata.html#sources-of-variability"><i class="fa fa-check"></i><b>7.3.1</b> Sources of Variability</a></li>
<li class="chapter" data-level="7.3.2" data-path="ch-corrdata.html"><a href="ch-corrdata.html#analyzing-a-control-group"><i class="fa fa-check"></i><b>7.3.2</b> Analyzing a control group</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ch-corrdata.html"><a href="ch-corrdata.html#under-construction"><i class="fa fa-check"></i><b>7.4</b> Under Construction…</a><ul>
<li class="chapter" data-level="7.4.1" data-path="ch-corrdata.html"><a href="ch-corrdata.html#correlated-data-simulation"><i class="fa fa-check"></i><b>7.4.1</b> Correlated Data Simulation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html"><i class="fa fa-check"></i><b>8</b> Introduction to Multilevel Models</a><ul>
<li class="chapter" data-level="8.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#learning-objectives-6"><i class="fa fa-check"></i><b>8.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="8.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#cs:music"><i class="fa fa-check"></i><b>8.2</b> Case Study: Music Performance Anxiety</a></li>
<li class="chapter" data-level="8.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#explore"><i class="fa fa-check"></i><b>8.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="8.3.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#organizedata1"><i class="fa fa-check"></i><b>8.3.1</b> Data Organization</a></li>
<li class="chapter" data-level="8.3.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#explore1"><i class="fa fa-check"></i><b>8.3.2</b> Exploratory Analyses: Univariate Summaries</a></li>
<li class="chapter" data-level="8.3.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#explore2"><i class="fa fa-check"></i><b>8.3.3</b> Exploratory Analyses: Bivariate Summaries</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#twolevelmodeling"><i class="fa fa-check"></i><b>8.4</b> Two level modeling: preliminary considerations</a><ul>
<li class="chapter" data-level="8.4.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#multregr"><i class="fa fa-check"></i><b>8.4.1</b> Ignoring the two level structure (not recommended)</a></li>
<li class="chapter" data-level="8.4.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#twostage"><i class="fa fa-check"></i><b>8.4.2</b> A two-stage modeling approach (better but imperfect)</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#twolevelmodelingunified"><i class="fa fa-check"></i><b>8.5</b> Two level modeling: a unified approach</a><ul>
<li class="chapter" data-level="8.5.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#ourframework"><i class="fa fa-check"></i><b>8.5.1</b> Our framework</a></li>
<li class="chapter" data-level="8.5.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#random-vs.fixed-effects"><i class="fa fa-check"></i><b>8.5.2</b> Random vs. fixed effects</a></li>
<li class="chapter" data-level="8.5.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#MVN"><i class="fa fa-check"></i><b>8.5.3</b> Distribution of errors: the multivariate normal distribution</a></li>
<li class="chapter" data-level="8.5.4" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#multileveltechnical"><i class="fa fa-check"></i><b>8.5.4</b> Technical issues when estimating and testing parameters (Optional)</a></li>
<li class="chapter" data-level="8.5.5" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#initialmodel"><i class="fa fa-check"></i><b>8.5.5</b> An initial model with parameter interpretations</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#sec:buildmodel"><i class="fa fa-check"></i><b>8.6</b> Building a multilevel model</a><ul>
<li class="chapter" data-level="8.6.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#buildstrategy"><i class="fa fa-check"></i><b>8.6.1</b> Model building strategy</a></li>
<li class="chapter" data-level="8.6.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modela"><i class="fa fa-check"></i><b>8.6.2</b> An initial model: unconditional means or random intercepts</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modelb"><i class="fa fa-check"></i><b>8.7</b> Binary covariates at Level One and Level Two</a><ul>
<li class="chapter" data-level="8.7.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#randomslopeandint"><i class="fa fa-check"></i><b>8.7.1</b> Random slopes and intercepts model</a></li>
<li class="chapter" data-level="8.7.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#pseudoR2"><i class="fa fa-check"></i><b>8.7.2</b> Pseudo <span class="math inline">\(R^2\)</span> values</a></li>
<li class="chapter" data-level="8.7.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modelc"><i class="fa fa-check"></i><b>8.7.3</b> Adding a covariate at Level Two</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#sec:modeld"><i class="fa fa-check"></i><b>8.8</b> Additional covariates: model comparison and interpretability</a><ul>
<li class="chapter" data-level="8.8.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#interp:modeld"><i class="fa fa-check"></i><b>8.8.1</b> Interpretation of parameter estimates</a></li>
<li class="chapter" data-level="8.8.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#compare:modeld"><i class="fa fa-check"></i><b>8.8.2</b> Model comparisons</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#sec:modele"><i class="fa fa-check"></i><b>8.9</b> Center covariates</a></li>
<li class="chapter" data-level="8.10" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modelf"><i class="fa fa-check"></i><b>8.10</b> A potential final model for music performance anxiety</a></li>
<li class="chapter" data-level="8.11" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#multinecessary"><i class="fa fa-check"></i><b>8.11</b> Modeling the multilevel structure: is it really necessary?</a></li>
<li class="chapter" data-level="8.12" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#notesr8"><i class="fa fa-check"></i><b>8.12</b> Notes on Using R (Optional)</a></li>
<li class="chapter" data-level="8.13" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#exercises-6"><i class="fa fa-check"></i><b>8.13</b> Exercises</a><ul>
<li class="chapter" data-level="8.13.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#conceptual-exercises-3"><i class="fa fa-check"></i><b>8.13.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="8.13.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#guided-exercise-3"><i class="fa fa-check"></i><b>8.13.2</b> Guided Exercise</a></li>
<li class="chapter" data-level="8.13.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#open-ended-exercises-2"><i class="fa fa-check"></i><b>8.13.3</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-lon.html"><a href="ch-lon.html"><i class="fa fa-check"></i><b>9</b> Two Level Longitudinal Data</a><ul>
<li class="chapter" data-level="9.1" data-path="ch-lon.html"><a href="ch-lon.html#learning-objectives-7"><i class="fa fa-check"></i><b>9.1</b> Learning objectives</a></li>
<li class="chapter" data-level="9.2" data-path="ch-lon.html"><a href="ch-lon.html#cs:charter"><i class="fa fa-check"></i><b>9.2</b> Case study: Charter schools</a></li>
<li class="chapter" data-level="9.3" data-path="ch-lon.html"><a href="ch-lon.html#exploratoryanalysis"><i class="fa fa-check"></i><b>9.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="9.3.1" data-path="ch-lon.html"><a href="ch-lon.html#data"><i class="fa fa-check"></i><b>9.3.1</b> Data organization</a></li>
<li class="chapter" data-level="9.3.2" data-path="ch-lon.html"><a href="ch-lon.html#missing"><i class="fa fa-check"></i><b>9.3.2</b> Missing data</a></li>
<li class="chapter" data-level="9.3.3" data-path="ch-lon.html"><a href="ch-lon.html#generalanalyses"><i class="fa fa-check"></i><b>9.3.3</b> Exploratory analyses for general multilevel models</a></li>
<li class="chapter" data-level="9.3.4" data-path="ch-lon.html"><a href="ch-lon.html#longitudinalanalyses"><i class="fa fa-check"></i><b>9.3.4</b> Exploratory analyses for longitudinal data</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="ch-lon.html"><a href="ch-lon.html#twostage9"><i class="fa fa-check"></i><b>9.4</b> Preliminary two-stage modeling</a><ul>
<li class="chapter" data-level="9.4.1" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostage"><i class="fa fa-check"></i><b>9.4.1</b> Linear trends within schools</a></li>
<li class="chapter" data-level="9.4.2" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostageL2effects"><i class="fa fa-check"></i><b>9.4.2</b> Effects of level two covariates on linear time trends</a></li>
<li class="chapter" data-level="9.4.3" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostageerror"><i class="fa fa-check"></i><b>9.4.3</b> Error structure within schools</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostageerror"><i class="fa fa-check"></i><b>9.5</b> Initial models</a><ul>
<li class="chapter" data-level="9.5.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modela"><i class="fa fa-check"></i><b>9.5.1</b> Unconditional means model</a></li>
<li class="chapter" data-level="9.5.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modelb"><i class="fa fa-check"></i><b>9.5.2</b> Unconditional growth model</a></li>
<li class="chapter" data-level="9.5.3" data-path="ch-lon.html"><a href="ch-lon.html#othertimetrends"><i class="fa fa-check"></i><b>9.5.3</b> Modeling other trends over time</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="ch-lon.html"><a href="ch-lon.html#finalmodel"><i class="fa fa-check"></i><b>9.6</b> Building to a final model</a><ul>
<li class="chapter" data-level="9.6.1" data-path="ch-lon.html"><a href="ch-lon.html#modelc9"><i class="fa fa-check"></i><b>9.6.1</b> Uncontrolled effects of school type</a></li>
<li class="chapter" data-level="9.6.2" data-path="ch-lon.html"><a href="ch-lon.html#modeld"><i class="fa fa-check"></i><b>9.6.2</b> Add percent free and reduced lunch as a covariate</a></li>
<li class="chapter" data-level="9.6.3" data-path="ch-lon.html"><a href="ch-lon.html#modelf9"><i class="fa fa-check"></i><b>9.6.3</b> A potential final model with three Level Two covariates</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="ch-lon.html"><a href="ch-lon.html#errorcovariance"><i class="fa fa-check"></i><b>9.7</b> Covariance structure among observations</a><ul>
<li class="chapter" data-level="9.7.1" data-path="ch-lon.html"><a href="ch-lon.html#standarderror"><i class="fa fa-check"></i><b>9.7.1</b> Standard covariance structure</a></li>
<li class="chapter" data-level="9.7.2" data-path="ch-lon.html"><a href="ch-lon.html#alternateerror"><i class="fa fa-check"></i><b>9.7.2</b> Alternative covariance structures</a></li>
<li class="chapter" data-level="9.7.3" data-path="ch-lon.html"><a href="ch-lon.html#covariance-structure-in-non-longitudinal-multilevel-models"><i class="fa fa-check"></i><b>9.7.3</b> Covariance structure in non-longitudinal multilevel models</a></li>
<li class="chapter" data-level="9.7.4" data-path="ch-lon.html"><a href="ch-lon.html#final-thoughts-regarding-covariance-structures"><i class="fa fa-check"></i><b>9.7.4</b> Final thoughts regarding covariance structures</a></li>
<li class="chapter" data-level="9.7.5" data-path="ch-lon.html"><a href="ch-lon.html#optionalcov"><i class="fa fa-check"></i><b>9.7.5</b> Details of covariance structures (Optional)</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="ch-lon.html"><a href="ch-lon.html#notesr9"><i class="fa fa-check"></i><b>9.8</b> Notes on Using R (Optional)</a></li>
<li class="chapter" data-level="9.9" data-path="ch-lon.html"><a href="ch-lon.html#exercises-7"><i class="fa fa-check"></i><b>9.9</b> Exercises</a><ul>
<li class="chapter" data-level="9.9.1" data-path="ch-lon.html"><a href="ch-lon.html#conceptual-exercises-4"><i class="fa fa-check"></i><b>9.9.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="9.9.2" data-path="ch-lon.html"><a href="ch-lon.html#guided-exercise-4"><i class="fa fa-check"></i><b>9.9.2</b> Guided Exercise</a></li>
<li class="chapter" data-level="9.9.3" data-path="ch-lon.html"><a href="ch-lon.html#open-ended-exercises-3"><i class="fa fa-check"></i><b>9.9.3</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch-3level.html"><a href="ch-3level.html"><i class="fa fa-check"></i><b>10</b> Multilevel Data With More Than Two Levels</a><ul>
<li class="chapter" data-level="10.1" data-path="ch-3level.html"><a href="ch-3level.html#learning-objectives-8"><i class="fa fa-check"></i><b>10.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="10.2" data-path="ch-3level.html"><a href="ch-3level.html#cs:seeds"><i class="fa fa-check"></i><b>10.2</b> Case Studies: Seed Germination</a></li>
<li class="chapter" data-level="10.3" data-path="ch-3level.html"><a href="ch-3level.html#explore3"><i class="fa fa-check"></i><b>10.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="10.3.1" data-path="ch-3level.html"><a href="ch-3level.html#organizedata3"><i class="fa fa-check"></i><b>10.3.1</b> Data Organization</a></li>
<li class="chapter" data-level="10.3.2" data-path="ch-3level.html"><a href="ch-3level.html#explore3v2"><i class="fa fa-check"></i><b>10.3.2</b> Exploratory Analyses</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="ch-3level.html"><a href="ch-3level.html#initialmodels-3level"><i class="fa fa-check"></i><b>10.4</b> Initial models: unconditional means and unconditional growth</a></li>
<li class="chapter" data-level="10.5" data-path="ch-3level.html"><a href="ch-3level.html#sec:boundary"><i class="fa fa-check"></i><b>10.5</b> Encountering boundary constraints</a></li>
<li class="chapter" data-level="10.6" data-path="ch-3level.html"><a href="ch-3level.html#threelevel-paraboot"><i class="fa fa-check"></i><b>10.6</b> Parametric bootstrap testing</a></li>
<li class="chapter" data-level="10.7" data-path="ch-3level.html"><a href="ch-3level.html#sec:explodingvarcomps"><i class="fa fa-check"></i><b>10.7</b> Exploding variance components</a></li>
<li class="chapter" data-level="10.8" data-path="ch-3level.html"><a href="ch-3level.html#modelsDEF"><i class="fa fa-check"></i><b>10.8</b> Building to a final model</a></li>
<li class="chapter" data-level="10.9" data-path="ch-3level.html"><a href="ch-3level.html#error-3level"><i class="fa fa-check"></i><b>10.9</b> Covariance structure (Optional)</a><ul>
<li class="chapter" data-level="10.9.1" data-path="ch-3level.html"><a href="ch-3level.html#optionalerror"><i class="fa fa-check"></i><b>10.9.1</b> Details of covariance structures</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="ch-3level.html"><a href="ch-3level.html#usingR3"><i class="fa fa-check"></i><b>10.10</b> Notes on Using R (Optional)</a></li>
<li class="chapter" data-level="10.11" data-path="ch-3level.html"><a href="ch-3level.html#exercises-8"><i class="fa fa-check"></i><b>10.11</b> Exercises</a><ul>
<li class="chapter" data-level="10.11.1" data-path="ch-3level.html"><a href="ch-3level.html#conceptual-exercises-5"><i class="fa fa-check"></i><b>10.11.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="10.11.2" data-path="ch-3level.html"><a href="ch-3level.html#guided-exercise-5"><i class="fa fa-check"></i><b>10.11.2</b> Guided Exercise</a></li>
<li class="chapter" data-level="10.11.3" data-path="ch-3level.html"><a href="ch-3level.html#open-ended-exercises-4"><i class="fa fa-check"></i><b>10.11.3</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-GLMM.html"><a href="ch-GLMM.html"><i class="fa fa-check"></i><b>11</b> Generalized Linear Multilevel Models</a><ul>
<li class="chapter" data-level="11.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#objectives"><i class="fa fa-check"></i><b>11.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="11.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#cs:refs"><i class="fa fa-check"></i><b>11.2</b> Case Study: College Basketball Referees</a></li>
<li class="chapter" data-level="11.3" data-path="ch-GLMM.html"><a href="ch-GLMM.html#explore-glmm"><i class="fa fa-check"></i><b>11.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="11.3.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#data-organization-7"><i class="fa fa-check"></i><b>11.3.1</b> Data organization</a></li>
<li class="chapter" data-level="11.3.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#glmm-eda"><i class="fa fa-check"></i><b>11.3.2</b> Exploratory analyses</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ch-GLMM.html"><a href="ch-GLMM.html#twolevelmodeling-glmm"><i class="fa fa-check"></i><b>11.4</b> Two level Modeling with a Generalized Response</a><ul>
<li class="chapter" data-level="11.4.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#multregr-glmm"><i class="fa fa-check"></i><b>11.4.1</b> A multiple generalized linear model approach (correlation not accounted for)</a></li>
<li class="chapter" data-level="11.4.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#twostage-glmm"><i class="fa fa-check"></i><b>11.4.2</b> A two-stage modeling approach (provides the basic idea for multilevel modeling)</a></li>
<li class="chapter" data-level="11.4.3" data-path="ch-GLMM.html"><a href="ch-GLMM.html#unified-glmm"><i class="fa fa-check"></i><b>11.4.3</b> A unified multilevel approach (the framework we’ll use)</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="ch-GLMM.html"><a href="ch-GLMM.html#crossedre"><i class="fa fa-check"></i><b>11.5</b> Crossed Random Effects</a></li>
<li class="chapter" data-level="11.6" data-path="ch-GLMM.html"><a href="ch-GLMM.html#glmm-paraboot"><i class="fa fa-check"></i><b>11.6</b> Model Comparisons Using the Parametric Bootstrap</a></li>
<li class="chapter" data-level="11.7" data-path="ch-GLMM.html"><a href="ch-GLMM.html#sec:finalmodel-glmm"><i class="fa fa-check"></i><b>11.7</b> A Potential Final Model for Examining Referee Bias</a></li>
<li class="chapter" data-level="11.8" data-path="ch-GLMM.html"><a href="ch-GLMM.html#estimatedRE"><i class="fa fa-check"></i><b>11.8</b> Estimated Random Effects</a></li>
<li class="chapter" data-level="11.9" data-path="ch-GLMM.html"><a href="ch-GLMM.html#usingR-glmm"><i class="fa fa-check"></i><b>11.9</b> Notes on Using R (Optional)</a></li>
<li class="chapter" data-level="11.10" data-path="ch-GLMM.html"><a href="ch-GLMM.html#exercises-9"><i class="fa fa-check"></i><b>11.10</b> Exercises</a></li>
<li class="chapter" data-level="11.11" data-path="ch-GLMM.html"><a href="ch-GLMM.html#conceptual-exercises-6"><i class="fa fa-check"></i><b>11.11</b> Conceptual Exercises</a><ul>
<li class="chapter" data-level="11.11.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#guided-exercise-6"><i class="fa fa-check"></i><b>11.11.1</b> Guided Exercise</a></li>
<li class="chapter" data-level="11.11.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#open-ended-exercises-5"><i class="fa fa-check"></i><b>11.11.2</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Broadening Your Statistical Horizons</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-3level" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> Multilevel Data With More Than Two Levels</h1>
<div id="learning-objectives-8" class="section level2">
<h2><span class="header-section-number">10.1</span> Learning Objectives</h2>
<p>After finishing this chapter, you should be able to:</p>
<ul>
<li>Extend the standard multilevel model to cases with more than two levels.</li>
<li>Apply exploratory data analysis techniques specific to data from more than two levels.</li>
<li>Formulate multilevel models including the variance-covariance structure.</li>
<li>Build and understand a taxonomy of models for data with more than two levels.</li>
<li>Interpret parameters in models with more than two levels.</li>
<li>Develop strategies for handling an exploding number of parameters in multilevel models.</li>
<li>Recognize when a fitted model has encountered boundary constraints and understand strategies for moving forward.</li>
<li>Understand how a parametric bootstrap test of significance works and when it might be useful.</li>
</ul>
</div>
<div id="cs:seeds" class="section level2">
<h2><span class="header-section-number">10.2</span> Case Studies: Seed Germination</h2>
<p>It is estimated that 82-99% of historic tallgrass prairie ecosystems have been converted to agricultural use (Baer et al. 2002). A prime example of this large scale conversion of native prairie to agricultural purposes can be seen in Minnesota, where less than 1% of the prairies that once existed in the state still remain (Camill et al. 2004). Such large scale alteration of prairie communities has been associated with numerous problems. For example, erosion and decomposition that readily take place in cultivated soils have increased atmospheric CO2 levels and increased nitrogen inputs to adjacent waterways (Baer et al. 2002, Camill et al. 2004, Knops and Tilman 2000). In addition, cultivation practices are known to affect rhizosphere composition as tilling can disrupt networks of soil microbes (Allison et al. 2005). The <a href="http://en.wikipedia.org/wiki/Rhizosphere">rhizosphere</a> is the narrow region of soil that is directly influenced by root secretions and associated soil microorganisms; much of the nutrient cycling and disease suppression needed by plants occur immediately adjacent to roots. It is important to note that microbial communities in prairie soils have been implicated with plant diversity and overall ecosystem function by controlling carbon and nitrogen cycling in the soils (Zak et al. 2003).</p>
<p>There have been many responses to these claims, but one response in recent years is reconstruction of the native prairie community. These reconstruction projects provide new habitat for a variety of native prairie species, yet it is important to know as much as possible about the outcomes of prairie reconstruction projects in order to ensure that a functioning prairie community is established. The ecological repercussions resulting from prairie reconstruction are not well known. For example, all of the aforementioned changes associated with cultivation practices are known to affect the subsequent reconstructed prairie community (Baer et al. 2002, Camill et al. 2004), yet there are few explanations for this phenomenon. For instance, prairies reconstructed in different years (using the same seed combinations and dispersal techniques) have yielded disparate prairie communities.</p>
<p>Researchers at a small Midwestern college decided to experimentally explore the underlying causes of variation in reconstruction projects in order to make future projects more effective. Introductory ecology classes were organized to collect longitudinal data on native plant species grown in a greenhouse setting, using soil samples from surrounding lands. We will examine their data to compare germination and growth of two species of prairie plants—leadplants (<em>Amorpha canescens</em>) and coneflowers (<em>Ratibida pinnata</em>)—in soils taken from a remnant (natural) prairie, a cultivated (agricultural) field, and a restored (reconstructed) prairie. Additionally, half of the sampled soil was sterilized to determine if rhizosphere differences were responsible for the observed variation, so we will examine the effects of sterilization as well.</p>
<p>The data we’ll examine was collected through an experiment run using a 3x2x2 factorial design, with 3 levels of soil type (remnant, cultivated, and restored), 2 levels of sterilization (yes or no), and 2 levels of species (leadplant and coneflower). Each of the 12 treatments (unique combinations of factor levels) was replicated in 6 pots, for a total of 72 pots. Six seeds were planted in each pot (although a few pots had 7 or 8 seeds), and initially student researchers recorded days to germination (defined as when two leaves are visible), if germination occurred. In addition, the height of each germinated plant (in mm) was measured at 13, 18, 23, and 28 days after planting. The study design is illustrated in the diagram below.</p>
<div class="figure">
<img src="data/StudyDesignDiagram.PNG" alt="The design of the seed germination study" />
<p class="caption">The design of the seed germination study</p>
</div>
</div>
<div id="explore3" class="section level2">
<h2><span class="header-section-number">10.3</span> Initial Exploratory Analyses</h2>
<div id="organizedata3" class="section level3">
<h3><span class="header-section-number">10.3.1</span> Data Organization</h3>
<p>Data for Case Study <a href="ch-3level.html#cs:seeds">10.2</a> contains the following variables:</p>
<ul>
<li><code>pot</code> = Pot plant was grown in (1-72)</li>
<li><code>plant</code> = Unique plant identification number</li>
<li><code>species</code> = L for leadplant and C for coneflower</li>
<li><code>soil</code> = STP for reconstructed prairie, REM for remnant prairie, and CULT for cultivated land</li>
<li><code>sterile</code> = Y for yes and N for no</li>
<li><code>germin</code> = Y if plant germinated, N if not</li>
<li><code>hgt13</code> = height of plant (in mm) 13 days after seeds planted</li>
<li><code>hgt18</code> = height of plant (in mm) 18 days after seeds planted</li>
<li><code>hgt23</code> = height of plant (in mm) 23 days after seeds planted</li>
<li><code>hgt28</code> = height of plant (in mm) 28 days after seeds planted</li>
</ul>
<p>This data is stored in wide format, with one row per plant (see 12 sample plants in Table <a href="ch-3level.html#tab:table1chp10">10.1</a>). As we have done in previous multilevel analyses, we will convert to long format (one observation per plant-time combination) after examining the missing data pattern and removing any plants with no growth data. In this case, we are almost assuredly losing information by removing plants with no height data at all four time points, since these plants did not germinate, and there may well be differences between species, soil type, and sterilization with respect to germination rates. We will handle this possibility by analyzing germination rates separately (see Chapter <a href="#ch-glmms"><strong>??</strong></a>); the analysis in this chapter will focus on effects of species, soil type, and sterilization on initial growth and growth rate among plants that germinate.</p>
<table>
<caption><span id="tab:table1chp10">Table 10.1: </span>A snapshot of data (Plants 231-246) from the Seed Germination case study in wide format.</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">pot</th>
<th align="right">plant</th>
<th align="left">soil</th>
<th align="left">sterile</th>
<th align="left">species</th>
<th align="left">germin</th>
<th align="right">hgt13</th>
<th align="right">hgt18</th>
<th align="right">hgt23</th>
<th align="right">hgt28</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>135</td>
<td align="right">23</td>
<td align="right">231</td>
<td align="left">CULT</td>
<td align="left">N</td>
<td align="left">C</td>
<td align="left">Y</td>
<td align="right">1.1</td>
<td align="right">1.4</td>
<td align="right">1.6</td>
<td align="right">1.7</td>
</tr>
<tr class="even">
<td>136</td>
<td align="right">23</td>
<td align="right">232</td>
<td align="left">CULT</td>
<td align="left">N</td>
<td align="left">C</td>
<td align="left">Y</td>
<td align="right">1.3</td>
<td align="right">2.2</td>
<td align="right">2.5</td>
<td align="right">2.7</td>
</tr>
<tr class="odd">
<td>137</td>
<td align="right">23</td>
<td align="right">233</td>
<td align="left">CULT</td>
<td align="left">N</td>
<td align="left">C</td>
<td align="left">Y</td>
<td align="right">0.5</td>
<td align="right">1.4</td>
<td align="right">2.0</td>
<td align="right">2.3</td>
</tr>
<tr class="even">
<td>138</td>
<td align="right">23</td>
<td align="right">234</td>
<td align="left">CULT</td>
<td align="left">N</td>
<td align="left">C</td>
<td align="left">Y</td>
<td align="right">0.3</td>
<td align="right">0.4</td>
<td align="right">1.2</td>
<td align="right">1.7</td>
</tr>
<tr class="odd">
<td>139</td>
<td align="right">23</td>
<td align="right">235</td>
<td align="left">CULT</td>
<td align="left">N</td>
<td align="left">C</td>
<td align="left">Y</td>
<td align="right">0.5</td>
<td align="right">0.5</td>
<td align="right">0.8</td>
<td align="right">2.0</td>
</tr>
<tr class="even">
<td>140</td>
<td align="right">23</td>
<td align="right">236</td>
<td align="left">CULT</td>
<td align="left">N</td>
<td align="left">C</td>
<td align="left">Y</td>
<td align="right">0.1</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td>141</td>
<td align="right">24</td>
<td align="right">241</td>
<td align="left">STP</td>
<td align="left">Y</td>
<td align="left">L</td>
<td align="left">Y</td>
<td align="right">1.8</td>
<td align="right">2.6</td>
<td align="right">3.9</td>
<td align="right">4.2</td>
</tr>
<tr class="even">
<td>142</td>
<td align="right">24</td>
<td align="right">242</td>
<td align="left">STP</td>
<td align="left">Y</td>
<td align="left">L</td>
<td align="left">Y</td>
<td align="right">1.3</td>
<td align="right">1.7</td>
<td align="right">2.8</td>
<td align="right">3.7</td>
</tr>
<tr class="odd">
<td>143</td>
<td align="right">24</td>
<td align="right">243</td>
<td align="left">STP</td>
<td align="left">Y</td>
<td align="left">L</td>
<td align="left">Y</td>
<td align="right">1.5</td>
<td align="right">1.6</td>
<td align="right">3.9</td>
<td align="right">3.9</td>
</tr>
<tr class="even">
<td>144</td>
<td align="right">24</td>
<td align="right">244</td>
<td align="left">STP</td>
<td align="left">Y</td>
<td align="left">L</td>
<td align="left">Y</td>
<td align="right">NA</td>
<td align="right">1.0</td>
<td align="right">2.3</td>
<td align="right">3.8</td>
</tr>
<tr class="odd">
<td>145</td>
<td align="right">24</td>
<td align="right">245</td>
<td align="left">STP</td>
<td align="left">Y</td>
<td align="left">L</td>
<td align="left">N</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td>146</td>
<td align="right">24</td>
<td align="right">246</td>
<td align="left">STP</td>
<td align="left">Y</td>
<td align="left">L</td>
<td align="left">N</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
<p>Although the experimental design called for <span class="math inline">\(72*6=432\)</span> plants, the wide data set has 437 plants because a few pots had more than six plants (likely because two of the microscopically small seeds stuck together when planted). Of those 437 plants, 154 had no height data (did not germinate by the 28th day) and were removed from analysis (for example, see rows 145-146 in Table <a href="ch-3level.html#tab:table1chp10">10.1</a>). 248 plants had complete height data (e.g., rows 135-139 and 141-143), 13 germinated later than the 13th day but had complete heights once they germinated (e.g., row 144), and 22 germinated and had measurable height on the 13th day but died before the 28th day (e.g., row 140). Ultimately, the long data set contains 1132 unique observations where plants heights were recorded; representation of plants 236-242 in the long data set can be seen in Table <a href="ch-3level.html#tab:table2chp10">10.2</a>.</p>
<table>
<caption><span id="tab:table2chp10">Table 10.2: </span>A snapshot of data (Plants 236-242) from the Seed Germination case study in long format.</caption>
<thead>
<tr class="header">
<th align="right">pot</th>
<th align="right">plant</th>
<th align="left">soil</th>
<th align="left">sterile</th>
<th align="left">species</th>
<th align="left">germin</th>
<th align="right">hgt</th>
<th align="right">time13</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">23</td>
<td align="right">236</td>
<td align="left">CULT</td>
<td align="left">N</td>
<td align="left">C</td>
<td align="left">Y</td>
<td align="right">0.1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">23</td>
<td align="right">236</td>
<td align="left">CULT</td>
<td align="left">N</td>
<td align="left">C</td>
<td align="left">Y</td>
<td align="right">NA</td>
<td align="right">5</td>
</tr>
<tr class="odd">
<td align="right">23</td>
<td align="right">236</td>
<td align="left">CULT</td>
<td align="left">N</td>
<td align="left">C</td>
<td align="left">Y</td>
<td align="right">NA</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="right">23</td>
<td align="right">236</td>
<td align="left">CULT</td>
<td align="left">N</td>
<td align="left">C</td>
<td align="left">Y</td>
<td align="right">NA</td>
<td align="right">15</td>
</tr>
<tr class="odd">
<td align="right">24</td>
<td align="right">241</td>
<td align="left">STP</td>
<td align="left">Y</td>
<td align="left">L</td>
<td align="left">Y</td>
<td align="right">1.8</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">24</td>
<td align="right">241</td>
<td align="left">STP</td>
<td align="left">Y</td>
<td align="left">L</td>
<td align="left">Y</td>
<td align="right">2.6</td>
<td align="right">5</td>
</tr>
<tr class="odd">
<td align="right">24</td>
<td align="right">241</td>
<td align="left">STP</td>
<td align="left">Y</td>
<td align="left">L</td>
<td align="left">Y</td>
<td align="right">3.9</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="right">24</td>
<td align="right">241</td>
<td align="left">STP</td>
<td align="left">Y</td>
<td align="left">L</td>
<td align="left">Y</td>
<td align="right">4.2</td>
<td align="right">15</td>
</tr>
<tr class="odd">
<td align="right">24</td>
<td align="right">242</td>
<td align="left">STP</td>
<td align="left">Y</td>
<td align="left">L</td>
<td align="left">Y</td>
<td align="right">1.3</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">24</td>
<td align="right">242</td>
<td align="left">STP</td>
<td align="left">Y</td>
<td align="left">L</td>
<td align="left">Y</td>
<td align="right">1.7</td>
<td align="right">5</td>
</tr>
<tr class="odd">
<td align="right">24</td>
<td align="right">242</td>
<td align="left">STP</td>
<td align="left">Y</td>
<td align="left">L</td>
<td align="left">Y</td>
<td align="right">2.8</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="right">24</td>
<td align="right">242</td>
<td align="left">STP</td>
<td align="left">Y</td>
<td align="left">L</td>
<td align="left">Y</td>
<td align="right">3.7</td>
<td align="right">15</td>
</tr>
</tbody>
</table>
<p>Notice the <strong>three-level structure</strong> of this data. Treatments (levels of the three experimental factors) were assigned at the <code>pot</code> level, then multiple plants were grown in each pot, and multiple measurements were taken over time for each plant. Our multilevel analysis must therefore account for pot-to-pot variability in height measurements (which could result from factor effects), plant-to-plant variability in height within a single pot, and variability over time in height for individual plants. In order to fit such a three-level model, we must extend the two-level model which we have used thus far.</p>
</div>
<div id="explore3v2" class="section level3">
<h3><span class="header-section-number">10.3.2</span> Exploratory Analyses</h3>
<p>We start by taking an initial look at the effect of Level Three covariates (factors applied at the pot level: species, soil type, and sterilization) on plant height, pooling observations across pot, across plant, and across time of measurement within plant. First, we observe that the initial balance which existed after randomization of pot to treatment no longer holds. After removing plants that did not germinate (and therefore had no height data), more height measurements exist for coneflowers (n=704, compared to 428 for leadplants), soil from restored prairies (n=524, compared to 288 for cultivated land and 320 for remnant prairies), and unsterilized soil (n=612, compared to 520 for sterilized soil). This imbalance indicates possible factor effects on germination rate; we will take up those hypotheses in Chapter <a href="#ch-glmms"><strong>??</strong></a>. In this chapter, we will focus on the effects of species, soil type, and sterilization on the growth patterns of plants that germinate.</p>
<p>Because we suspect that height measurements over time for a single plant are highly correlated, while height measurements from different plants from the same pot are relatively uncorrelated, we calculate mean height per plant (over all available time points) before generating exploratory plots investigating Level Three factors. Figure <a href="ch-3level.html#fig:boxbyspec">10.1</a> then examines the effects of soil type and sterilization separately by species. Sterilization seems to have a bigger benefit for coneflowers, while soil from remnant prairies seems to lead to smaller leadplants and taller coneflowers.</p>
<div class="figure" style="text-align: center"><span id="fig:boxbyspec"></span>
<img src="bookdown-bysh_files/figure-html/boxbyspec-1.png" alt="Plant height comparisons of (a) soil type and (b) sterilization within species.  Each plant is represented by the mean height over all measurements at all time points for that plant." width="60%" />
<p class="caption">
Figure 10.1: Plant height comparisons of (a) soil type and (b) sterilization within species. Each plant is represented by the mean height over all measurements at all time points for that plant.
</p>
</div>
<p>We also use spaghetti plots to examine time trends within species to see (a) if it is reasonable to assume linear growth between Day 13 and Day 28 after planting, and (b) if initial height and rate of growth is similar in the two species. Figure <a href="ch-3level.html#fig:spagbyspec">10.2</a> illustrates differences between species. While both species have similar average heights 13 days after planting, coneflowers appear to have faster early growth which slows later, while leadplants have a more linear growth rate which culminates in greater average heights 28 days after planting. Coneflowers also appear to have greater variability in initial height and growth rate, although there are more coneflowers with height data.</p>
<div class="figure" style="text-align: center"><span id="fig:spagbyspec"></span>
<img src="bookdown-bysh_files/figure-html/spagbyspec-1.png" alt="Spaghetti plot by species with loess fit.  Each &quot;line&quot; represents one plant." width="60%" />
<p class="caption">
Figure 10.2: Spaghetti plot by species with loess fit. Each “line” represents one plant.
</p>
</div>
<p>Exploratory analyses such as these confirm the suspicions of biology researchers that leadplants and coneflowers should be analyzed separately. Because of biological differences, it is expected that these two species will show different growth patterns and respond differently to treatments such as fertilization. Coneflowers are members of the aster family, growing up to 4 feet tall with their distinctive gray seed heads and drooping yellow petals. Leadplants, on the other hand, are members of the bean family, with purple flowers, a height of 1 to 3 feet, and compound greyish green leaves which look to be dusted with white lead. Leadplants have deep root systems and are symbiotic N-fixers, which means they might experience stifled growth in sterilized soil compared with other species. For the remainder of this chapter, we will focus on <strong>leadplants</strong> and how their growth patterns are affected by soil type and sterilization. You will have a chance to analyze coneflower data later in the Exercises section.</p>
<p>Lattice plots, illustrating several observational units simultaneously, each with fitted lines where appropriate, are also valuable to examine during the exploratory analysis phase. Figure <a href="ch-3level.html#fig:lattlpall">10.3</a> shows height over time for 24 randomly selected leadplants that germinated in this study, with a fitted linear regression line. Linearity appears reasonable in most cases, although there is some variability in the intercepts and a good deal of variability in the slopes of the fitted lines. These intercepts and slopes by plant, of course, will be potential parameters in a multilevel model which we will fit to this data. Given the three-level nature of this data, it is also useful to examine a spaghetti plot by pot (Figure <a href="ch-3level.html#fig:spaglppot">10.4</a>). While linearity appears to reasonably model the average trend over time within pot, we see differences in the plant-to-plant variability within pot, but some consistency in intercept and slope from pot to pot.</p>
<div class="figure" style="text-align: center"><span id="fig:lattlpall"></span>
<img src="bookdown-bysh_files/figure-html/lattlpall-1.png" alt=" Lattice plot of linear trends fit to 24 randomly selected leadplants.  One plant with only a single height measurement has no associated regression line." width="60%" />
<p class="caption">
Figure 10.3:  Lattice plot of linear trends fit to 24 randomly selected leadplants. One plant with only a single height measurement has no associated regression line.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:spaglppot"></span>
<img src="bookdown-bysh_files/figure-html/spaglppot-1.png" alt="Spaghetti plot for leadplants by pot with loess fit." width="60%" />
<p class="caption">
Figure 10.4: Spaghetti plot for leadplants by pot with loess fit.
</p>
</div>
<p>Spaghetti plots can also be an effective tool for examining the potential effects of soil type and sterilization on growth patterns of leadplants. Figure <a href="ch-3level.html#fig:spaglpsoil">10.5</a> and Figure <a href="ch-3level.html#fig:spaglpster">10.6</a> illustrate how the growth patterns of leadplants depend on soil type and sterilization. In general, we observe slower growth in soil from remnant prairies and soil that has not been sterilized.</p>
<div class="figure" style="text-align: center"><span id="fig:spaglpsoil"></span>
<img src="bookdown-bysh_files/figure-html/spaglpsoil-1.png" alt="Spaghetti plot for leadplants by soil type with loess fit." width="60%" />
<p class="caption">
Figure 10.5: Spaghetti plot for leadplants by soil type with loess fit.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:spaglpster"></span>
<img src="bookdown-bysh_files/figure-html/spaglpster-1.png" alt="Spaghetti plot for leadplants by sterilization with loess fit." width="60%" />
<p class="caption">
Figure 10.6: Spaghetti plot for leadplants by sterilization with loess fit.
</p>
</div>
<p>We can further explore the variability in linear growth among plants and among pots by fitting regression lines and examining the estimated intercepts and slopes, as well as the corresponding R-squared values. Figures <a href="ch-3level.html#fig:intrateplant">10.7</a> and <a href="ch-3level.html#fig:intratepot">10.8</a> provide just such an analysis, where Figure <a href="ch-3level.html#fig:intrateplant">10.7</a> shows results of fitting lines by plant, and Figure <a href="ch-3level.html#fig:intratepot">10.8</a> shows results of fitting lines by pot. Certain caveats accompany these summaries. In the case of fitted lines by plant, each plant is given equal weight regardless of the number of observations (2-4) for a given plant, and in the case of fitted lines by pot, a line is estimated by simply pooling all observations from a given pot, ignoring the plant from which the observations came, and equally weighting pots regardless of how many plants germinated and survived to Day 28. Nevertheless, the summaries of fitted lines provide useful information. When fitting regression lines by plant, we see a mean intercept of 1.52 (SD=0.66), indicating an estimated average height at 13 days of 1.5 mm, and a mean slope of 0.114 mm per day of growth from Days 13 to 28 (SD=0.059). Most R-squared values were strong (e.g., 84% were above 0.8). Summaries of fitted regression lines by pot show similar mean intercepts (1.50) and slopes (0.107), but somewhat less variability pot-to-pot than we observed plant-to-plant (SD=0.46 for intercepts and SD=0.050 for slopes).</p>
<div class="figure" style="text-align: center"><span id="fig:intrateplant"></span>
<img src="bookdown-bysh_files/figure-html/intrateplant-1.png" alt=" Histograms of (a) intercepts, (b) slopes, and (c) R-squared values for linear fits across all leadplants." width="60%" />
<p class="caption">
Figure 10.7:  Histograms of (a) intercepts, (b) slopes, and (c) R-squared values for linear fits across all leadplants.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:intratepot"></span>
<img src="bookdown-bysh_files/figure-html/intratepot-1.png" alt="Histograms of (a) intercepts, (b) slopes, and (c) R-squared values for linear fits across all pots with leadplants." width="60%" />
<p class="caption">
Figure 10.8: Histograms of (a) intercepts, (b) slopes, and (c) R-squared values for linear fits across all pots with leadplants.
</p>
</div>
<p>Another way to examine variability due to plant vs. variability due to pot is through summary statistics. Plant-to-plant variability can be estimated by averaging standard deviations from each pot (.489 for intercepts and .039 for slopes), while pot-to-pot variability can be estimated by finding the standard deviation of average intercept (.478) or slope (.051) within pot. Based on these rough measurements, variability due to plants and pots is comparable.</p>
<p>Fitted lines by plant and pot are modeled using a centered time variable (<code>time13</code>), adjusted so that the first day of height measurements (13 days after planting) corresponds to <code>time13</code>=0. This centering has two primary advantages. First, the estimated intercept becomes more interpretable. Rather than representing height on the day of planting (which should be 0 mm, but which represents a hefty extrapolation from our observed range of days 13 to 28), the intercept now represents height on Day 13. Second, the intercept and slope are much less correlated (r=-0.16) than when uncentered time is used, which improves the stability of future models.</p>
<p>Fitted intercepts and slopes by plant can be used for an additional exploratory examination of factor effects to complement those from the earlier spaghetti plots. Figure <a href="ch-3level.html#fig:irboxbyspec">10.9</a> complements Figure <a href="ch-3level.html#fig:spagbyspec">10.2</a>, again showing differences between species—coneflowers tend to start smaller and have slower growth rates, although they have much more variability in growth patterns than leadplants. Returning to our focus on leadplants, Figure <a href="ch-3level.html#fig:irboxbysoil">10.10</a> shows that plants grown in soil from cultivated fields tends to be taller at Day 13, and plants grown in soil from remnant prairies tend to grow more slowly than plants grown in other soil types. Figure <a href="ch-3level.html#fig:irboxbyster">10.11</a> shows the strong tendency for plants grown in sterilized soil to grow faster than plants grown in non-sterilized soil. We will soon see if our fitted multilevel models support these observed trends.</p>
<div class="figure" style="text-align: center"><span id="fig:irboxbyspec"></span>
<img src="bookdown-bysh_files/figure-html/irboxbyspec-1.png" alt="Boxplots of (a) intercepts and (b) slopes for all plants by species, based on a linear fit to height data from each plant." width="60%" />
<p class="caption">
Figure 10.9: Boxplots of (a) intercepts and (b) slopes for all plants by species, based on a linear fit to height data from each plant.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:irboxbysoil"></span>
<img src="bookdown-bysh_files/figure-html/irboxbysoil-1.png" alt="Boxplots of (a) intercepts and (b) slopes for all leadplants by soil type, based on a linear fit to height data from each plant." width="60%" />
<p class="caption">
Figure 10.10: Boxplots of (a) intercepts and (b) slopes for all leadplants by soil type, based on a linear fit to height data from each plant.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:irboxbyster"></span>
<img src="bookdown-bysh_files/figure-html/irboxbyster-1.png" alt="Boxplots of (a) intercepts and (b) slopes for all leadplants by sterilization, based on a linear fit to height data from each plant." width="60%" />
<p class="caption">
Figure 10.11: Boxplots of (a) intercepts and (b) slopes for all leadplants by sterilization, based on a linear fit to height data from each plant.
</p>
</div>
<p>Since we have time at Level One, any exploratory analysis of Case Study <a href="ch-3level.html#cs:seeds">10.2</a> should contain an investigation of the variance-covariance structure within plant. Figure <a href="ch-3level.html#fig:corrstruct">10.12</a> shows the potential for an autocorrelation structure in which the correlation between observations from the same plant diminishes as the time between measurements increases. Residuals five days apart have correlations ranging from .77 to .91, while measurements ten days apart have correlations of .62 and .70, and measurements fifteen days apart have correlation of .58.</p>
<div class="figure" style="text-align: center"><span id="fig:corrstruct"></span>
<img src="bookdown-bysh_files/figure-html/corrstruct-1.png" alt="Correlation structure within plant.  The upper right contains correlation coefficients between residuals at pairs of time points, the lower left contains scatterplots of the residuals at time point pairs, and the diagonal contains histograms of residuals at each of the four time points." width="60%" />
<p class="caption">
Figure 10.12: Correlation structure within plant. The upper right contains correlation coefficients between residuals at pairs of time points, the lower left contains scatterplots of the residuals at time point pairs, and the diagonal contains histograms of residuals at each of the four time points.
</p>
</div>
</div>
</div>
<div id="initialmodels-3level" class="section level2">
<h2><span class="header-section-number">10.4</span> Initial models: unconditional means and unconditional growth</h2>
<p>The structure and notation for three level models will closely resemble the structure and notation for two level models, just with extra subscripts. Therein lies some of the power of multilevel models—extensions are relatively easy and allow you to control for many sources of variability, obtaining more precise estimates of important parameters. However, the number of variance component parameters to estimate can quickly mushroom as covariates are added at lower levels, so implementing simplifying restrictions will often become necessary (see Section <a href="ch-3level.html#sec:explodingvarcomps">10.7</a>).</p>
<p>We once again begin with the <strong>unconditional means model</strong>, in which there are no predictors at any level, in order to assess the amount of variation at each level. Here, Level Three is pot, Level Two is plant within pot, and Level One is time within plant. Using model formulations at each of the three levels, the unconditional means three-level model can be expressed as:</p>
<ul>
<li>Level One (timepoint within plant):
<span class="math display" id="eq:initunun">\[\begin{equation}
Y_{ijk} = a_{ij}+\epsilon_{ijk} \textrm{ where } \epsilon_{ijk}\sim N(0,\sigma^2)
\tag{10.1}
\end{equation}\]</span></li>
<li>Level Two (plant within pot):
<span class="math display" id="eq:initunun2">\[\begin{equation}
a_{ij} = a_{i}+u_{ij} \textrm{ where } u_{ij}\sim N(0,\sigma_{u}^{2})
\tag{10.2}
\end{equation}\]</span></li>
<li>Level Three (pot):
<span class="math display" id="eq:initunun3">\[\begin{equation}
a_{i} = \alpha_{0}+\tilde{u}_{i} \textrm{ where } \tilde{u}_{i} \sim N(0,\sigma_{\tilde{u}}^{2})
\tag{10.3}
\end{equation}\]</span></li>
</ul>
<p>where the heights of plants from different pots are considered independent, but plants from the same pot are correlated as well as measurements at different times from the same plant.</p>
<p>Keeping track of all the model terms, especially with three subscripts, is not a trivial task, but it’s worth spending time thinking through. Here is a quick guide to the meaning of terms found in our three-level model:</p>
<ul>
<li><span class="math inline">\(Y_{ijk}\)</span> is the height (in mm) of plant <span class="math inline">\(j\)</span> from pot <span class="math inline">\(i\)</span> at time <span class="math inline">\(k\)</span></li>
<li><span class="math inline">\(a_{ij}\)</span> is the true mean height for plant <span class="math inline">\(j\)</span> from pot <span class="math inline">\(i\)</span> across all time points. This is not considered a model parameter, since we further model <span class="math inline">\(a_{ij}\)</span> at Level Two.</li>
<li><span class="math inline">\(a_{i}\)</span> is the true mean height for pot <span class="math inline">\(i\)</span> across all plants from that pot and all time points. This is also not considered a model parameter, since we further model <span class="math inline">\(a_{i}\)</span> at Level Three.</li>
<li><span class="math inline">\(\alpha_{0}\)</span> is a fixed effects model parameter representing the true mean height across all pots, plants, and time points</li>
<li><span class="math inline">\(\epsilon_{ijk}\)</span> describes how far an observed height <span class="math inline">\(Y_{ijk}\)</span> is from the mean height for plant <span class="math inline">\(j\)</span> from pot <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(u_{ij}\)</span> describe how far the mean height of plant <span class="math inline">\(j\)</span> from pot <span class="math inline">\(i\)</span> is from the mean height of all plants from pot <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(\tilde{u}_{i}\)</span> describes how far the mean height of all observations from pot <span class="math inline">\(i\)</span> is from the overall mean height across all pots, plants, and time points. None of the error terms (<span class="math inline">\(\epsilon, u, \tilde{u}\)</span>) are considered model parameters; they simply account for differences between the observed data and expected values under our model.</li>
<li><span class="math inline">\(\sigma^2\)</span> is a variance component (random effects model parameter) that describes within-plant variability over time</li>
<li><span class="math inline">\(\sigma_{u}^{2}\)</span> is the variance component describing plant-to-plant variability within pot</li>
<li><span class="math inline">\(\sigma_{\tilde{u}}^{2}\)</span> is the variance component describing pot-to-pot variability.</li>
</ul>
The three-level unconditional means model can also be expressed as a composite model:
<span class="math display" id="eq:initununcomp">\[\begin{equation}
Y_{ijk}=\alpha_{0}+\tilde{u}_{i}+u_{ij}+\epsilon_{ijk}
\tag{10.4}
\end{equation}\]</span>
<p>and this composite model can be fit using statistical software:</p>
<pre><code>Formula: hgt ~ 1 + (1 | plant) + (1 | pot)

Random effects:
 Groups   Name        Variance Std.Dev.
 plant    (Intercept) 0.27817  0.5274  
 pot      (Intercept) 0.04873  0.2207  
 Residual             0.72782  0.8531  
Number of obs: 413, groups:  plant, 107; pot, 32

Fixed effects:
            Estimate Std. Error t value
(Intercept)  2.38808    0.07887   30.28</code></pre>
<p>From this output, we obtain estimates of our four model parameters:</p>
<ul>
<li><span class="math inline">\(\hat{\alpha}_{0}=2.39=\)</span> the mean height (in mm) across all time points, plants, and pots.</li>
<li><span class="math inline">\(\hat{\sigma}^2=0.728=\)</span> the variance over time within plants.</li>
<li><span class="math inline">\(\hat{\sigma}_{u}^{2}=0.278=\)</span> the variance between plants from the same pot.</li>
<li><span class="math inline">\(\hat{\sigma}_{\tilde{u}}^{2}=0.049=\)</span> the variance between pots.</li>
</ul>
<p>From the estimates of variance components, 69.0% of total variability in height measurements is due to differences over time for each plant, 26.4% of total variability is due to differences between plants from the same pot, and only 4.6% of total variability is due to difference between pots. Accordingly, we will next explore whether the incorporation of time as a linear predictor at Level One can reduce the unexplained variability within plant.</p>
<p>The <strong>unconditional growth model</strong> introduces time as a predictor at Level One, but there are still no predictors at Levels Two or Three. The unconditional growth model allows us to assess how much of the within-plant variability (the variability among height measurements from the same plant at different time points) can be attributed to linear changes over time, while also determining how much variability we see in the intercept (Day 13 height) and slope (daily growth rate) from plant-to-plant and pot-to-pot. Later, we can model plant-to-plant and pot-to-pot differences in intercepts and slopes with Level Two and Three covariates.</p>
<p>The three-level unconditional growth model (Model B) can be specified either using formulations at each level:</p>
<ul>
<li>Level One (timepoint within plant):
<span class="math display" id="eq:timewithplnt">\[\begin{equation}
Y_{ijk} = a_{ij}+b_{ij}\textstyle{time}_{ijk}+\epsilon_{ijk}
\tag{10.5}
\end{equation}\]</span></li>
<li>Level Two (plant within pot):
<span class="math display">\[\begin{eqnarray*}
a_{ij} &amp; = &amp; a_{i}+u_{ij} \\
b_{ij} &amp; = &amp; b_{i}+v_{ij}
\end{eqnarray*}\]</span></li>
<li>Level Three (pot):
<span class="math display">\[\begin{eqnarray*}
a_{i} &amp; = &amp; \alpha_{0}+\tilde{u}_{i} \\
b_{i} &amp; = &amp; \beta_{0}+\tilde{v}_{i}
\end{eqnarray*}\]</span></li>
</ul>
or as a composite model:
<span class="math display" id="eq:compmodb">\[\begin{equation}
Y_{ijk}=[\alpha_{0}+\beta_{0}\textstyle{time}_{ijk}]+
[\tilde{u}_{i}+{v}_{ij}+\epsilon_{ijk}+(\tilde{v}_{i}+{v}_{ij})\textstyle{time}_{ijk}]
\tag{10.6}
\end{equation}\]</span>
<p>where <span class="math inline">\(\epsilon_{ijk}\sim N(0,\sigma^2)\)</span>, <span class="math display">\[ \left[ \begin{array}{c}
            u_{ij} \\ v_{ij}
          \end{array}  \right] \sim N \left( \left[
          \begin{array}{c}
            0 \\ 0
          \end{array} \right], \left[
          \begin{array}{cc}
            \sigma_{u}^{2} &amp; \\
            \sigma_{uv} &amp; \sigma_{v}^{2}
          \end{array} \right] \right), \]</span> and <span class="math display">\[ \left[ \begin{array}{c}
            \tilde{u}_{i} \\ \tilde{v}_{i}
          \end{array}  \right] \sim N \left( \left[
          \begin{array}{c}
            0 \\ 0
          \end{array} \right], \left[
          \begin{array}{cc}
            \sigma_{\tilde{u}}^{2} &amp; \\
            \sigma_{\tilde{u}\tilde{v}} &amp; \sigma_{\tilde{v}}^{2}
          \end{array} \right] \right). \]</span></p>
<p>In this model, at Level One the trajectory for plant <span class="math inline">\(j\)</span> from pot <span class="math inline">\(i\)</span> is assumed to be linear, with intercept <span class="math inline">\(a_{ij}\)</span> (height on Day 13) and slope <span class="math inline">\(b_{ij}\)</span> (daily growth rate between Days 13 and 28); the <span class="math inline">\(\epsilon_{ijk}\)</span> terms capture the deviation between the true growth trajectory of plant <span class="math inline">\(j\)</span> from pot <span class="math inline">\(i\)</span> and its observed heights. At Level Two, <span class="math inline">\(a_{i}\)</span> represents the true mean intercept and <span class="math inline">\(b_{i}\)</span> represents the true mean slope for all plants from pot <span class="math inline">\(i\)</span>, while <span class="math inline">\(u_{ij}\)</span> and <span class="math inline">\(v_{ij}\)</span> capture the deviation between plant <span class="math inline">\(j\)</span>’s true growth trajectory and the mean intercept and slope for pot <span class="math inline">\(i\)</span>. The deviations in intercept and slope at Level Two are allowed to be correlated through the covariance parameter <span class="math inline">\(\sigma_{uv}\)</span>. Finally, <span class="math inline">\(\alpha_{0}\)</span> is the true mean intercept and <span class="math inline">\(\beta_{0}\)</span> is the true mean daily growth rate over the entire population of leadplants, while <span class="math inline">\(\tilde{u}_{i}\)</span> and <span class="math inline">\(\tilde{v}_{i}\)</span> capture the deviation between pot <span class="math inline">\(i\)</span>’s true overall growth trajectory and the population mean intercept and slope. Note that between-plant and between-pot variability are both partitioned now into variability in initial status (<span class="math inline">\(\sigma_{u}^{2}\)</span> and <span class="math inline">\(\sigma_{\tilde{u}}^{2}\)</span>) and variability in rates of change (<span class="math inline">\(\sigma_{v}^{2}\)</span> and <span class="math inline">\(\sigma_{\tilde{v}}^{2}\)</span>).</p>
<p>Using the composite model specification, the unconditional growth model can be fit to the seed germination data:</p>
<pre><code>Formula: hgt ~ time13 + (time13 | plant) + (time13 | pot)

Random effects:
 Groups   Name        Variance Std.Dev. Corr 
 plant    (Intercept) 0.299163 0.54696       
          time13      0.001194 0.03456  0.28 
 pot      (Intercept) 0.044219 0.21028       
          time13      0.001261 0.03551  -0.61
 Residual             0.082157 0.28663       
Number of obs: 413, groups:  plant, 107; pot, 32

Fixed effects:
            Estimate Std. Error t value
(Intercept) 1.537696   0.070304   21.87
time13      0.112117   0.007924   14.15</code></pre>
<p>From this output, we obtain estimates of our nine model parameters (two fixed effects and seven variance components):</p>
<ul>
<li><span class="math inline">\(\hat{\alpha}_{0}=1.538=\)</span> the mean height of leadplants 13 days after planting.</li>
<li><span class="math inline">\(\hat{\beta}_{0}=0.112=\)</span> the mean daily change in height of leadplants from 13 to 28 days after planting.</li>
<li><span class="math inline">\(\hat{\sigma}=.287=\)</span> the standard deviation in within-plant residuals after accounting for time.</li>
<li><span class="math inline">\(\hat{\sigma}_{u}=.547=\)</span> the standard deviation in Day 13 heights between plants from the same pot.</li>
<li><span class="math inline">\(\hat{\sigma}_{v}=.0346=\)</span> the standard deviation in rates of change in height between plants from the same pot.</li>
<li><span class="math inline">\(\hat{\rho}_{uv}=.280=\)</span> the correlation in plants’ Day 13 height and their rate of change in height.</li>
<li><span class="math inline">\(\hat{\sigma}_{\tilde{u}}=.210=\)</span> the standard deviation in Day 13 heights between pots.</li>
<li><span class="math inline">\(\hat{\sigma}_{\tilde{v}}=.0355=\)</span> the standard deviation in rates of change in height between pots.</li>
<li><span class="math inline">\(\hat{\rho}_{\tilde{u}\tilde{v}}=-.610=\)</span> the correlation in pots’ Day 13 height and their rate of change in height.</li>
</ul>
<p>We see that, on average, leadplants have a height of 1.54 mm thirteen days after planting (pooled across pots and treatment groups), and their heights tend to grow by 0.11 mm per day, producing an average height at the end of the study (Day 28) of 3.22 mm. According to the t-values listed in R, both the Day 13 height and the growth rate are statistically significant. The estimated within-plant variance <span class="math inline">\(\hat{\sigma}^2\)</span> decreased by 88.7% from the unconditional means model (from 0.728 to 0.082), implying that 88.7% of within-plant variability in height can be explained by linear growth over time.</p>
</div>
<div id="sec:boundary" class="section level2">
<h2><span class="header-section-number">10.5</span> Encountering boundary constraints</h2>
<p>Typically, with models consisting of three or more levels, the next step after adding covariates at Level One (such as time) is considering covariates at Level Two. In the seed germination experiment, however, there are no Level Two covariates of interest, and the treatments being studied were applied to pots (Level Three). We are primarily interested in the effects of soil type and sterilization on the growth of leadplants. Since soil type is a categorical factor with three levels, we can represent soil type in our model with indicator variables for cultivated lands (<code>cult</code>) and remnant prairies (<code>rem</code>), using reconstructed prairies as the reference level. For sterilization, we create a single indicator variable (<code>strl</code>) which takes on the value 1 for sterilized soil.</p>
<p>Our Level One and Level Two models will look identical to those from Model B; our Level Three models will contain the new covariates for soil type (<code>cult</code> and <code>rem</code>) and sterilization (<code>strl</code>):</p>
<span class="math display">\[\begin{eqnarray*}
a_{i} &amp; = &amp; \alpha_{0}+\alpha_{1}\textstyle{strl}_{i}+\alpha_{2}\textstyle{cult}_{i}+\alpha_{3}\textstyle{rem}_{i}+\tilde{u}_{i} \\
b_{i} &amp; = &amp; \beta_{0}+\beta_{1}\textstyle{strl}_{i}+\beta_{2}\textstyle{cult}_{i}+\beta_{3}\textstyle{rem}_{i}+\tilde{v}_{i}
\end{eqnarray*}\]</span>
<p>where the error terms at Level Three follow the same multivariate normal distribution as in Model B. In our case, the composite model can be written as:</p>
<span class="math display">\[\begin{eqnarray*}
Y_{ijk} &amp; = &amp; (\alpha_{0}+\alpha_{1}\textstyle{strl}_{i}+\alpha_{2}\textstyle{cult}_{i}+\alpha_{3}\textstyle{rem}_{i}+\tilde{u}_{i}+u_{ij}) + \\
 &amp; &amp; (\beta_{0}+\beta_{1}\textstyle{strl}_{i}+\beta_{2}\textstyle{cult}_{i}+\beta_{3}\textstyle{rem}_{i}+\tilde{v}_{i}+
 v_{ij})\textstyle{time}_{ijk}+\epsilon_{ijk} \\
\end{eqnarray*}\]</span>
<p>which, after combining fixed effects and random effects, can be rewritten as:</p>
<span class="math display">\[\begin{eqnarray*}
Y_{ijk} &amp; = &amp; [\alpha_{0}+\alpha_{1}\textstyle{strl}_{i}+\alpha_{2}\textstyle{cult}_{i}+\alpha_{3}\textstyle{rem}_{i} +
 \beta_{0}\textstyle{time}_{ijk} + \\
 &amp; &amp; \beta_{1}\textstyle{strl}_{i}\textstyle{time}_{ijk}+\beta_{2}\textstyle{cult}_{i}\textstyle{time}_{ijk}+ \beta_{3}\textstyle{rem}_{i}\textstyle{time}_{ijk}] + \\
 &amp; &amp; [\tilde{u}_{i}+u_{ij}+\epsilon_{ijk}+\tilde{v}_{i}\textstyle{time}_{ijk}+v_{ij}\textstyle{time}_{ijk}]
\end{eqnarray*}\]</span>
<p>From the output below, the addition of Level Three covariates in Model C (<code>cult</code>, <code>rem</code>, <code>strl</code>, and their interactions with <code>time</code>) appears to provide a significant improvement (likelihood ratio test statistic = 32.2 on 6 df, <span class="math inline">\(p&lt;.001\)</span>) to the unconditional growth model (Model B).</p>
<pre><code>Formula: hgt ~ time13 + strl + cult + rem + time13:strl + time13:cult +  
    time13:rem + (time13 | plant) + (time13 | pot)

Random effects:
 Groups   Name        Variance  Std.Dev. Corr 
 plant    (Intercept) 0.2980203 0.54591       
          time13      0.0012081 0.03476  0.28 
 pot      (Intercept) 0.0531506 0.23054       
          time13      0.0001317 0.01148  -1.00
 Residual             0.0820769 0.28649       
Number of obs: 413, groups:  plant, 107; pot, 32

Fixed effects:
             Estimate Std. Error t value
(Intercept)  1.502893   0.127001  11.834
time13       0.101069   0.008292  12.189
strl        -0.076546   0.151368  -0.506
cult         0.130013   0.182723   0.712
rem          0.138387   0.176196   0.785
time13:strl  0.058917   0.010282   5.730
time13:cult -0.029765   0.012263  -2.427
time13:rem  -0.035860   0.011978  -2.994</code></pre>
<pre><code>...
        Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(&gt;Chisq)    
modelbl  9 603.76 639.97 -292.88   585.76                             
modelcl 15 583.55 643.90 -276.78   553.55 32.202      6  1.493e-05 ***
...</code></pre>
<p>However, Model C has encountered a <strong>boundary constraint</strong> with an estimated Level 3 correlation between the intercept and slope error terms of -1. “Allowable” values of correlation coefficients run from -1 to 1; by definition, it is impossible to have a correlation between two error terms below -1. Thus, our estimate of -1 is right on the boundary of the allowable values. But how did this happen, and why is it potentially problematic?</p>
<p>Consider a model in which we have two parameters that must be estimated: <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\sigma^2\)</span>. As the intercept, <span class="math inline">\(\beta_0\)</span> can take on any value; any real number is “allowable”. But, by definition, variance terms such as <span class="math inline">\(\sigma^2\)</span> must be non-negative; that is, <span class="math inline">\(\sigma^2 \geq 0\)</span>. Under the Principle of Maximum Likelihood, maximum likelihood estimators for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\sigma^2\)</span> will be chosen to maximize the likelihood of observing our given data. The left plot in Figure <a href="ch-3level.html#fig:boundary">10.13</a> shows hypothetical contours of the likelihood function <span class="math inline">\(L(\beta_0, \sigma^2)\)</span>; the likelihood is clearly maximized at <span class="math inline">\((\hat{\beta}_0 , \hat{\sigma}^2)=(4,-2)\)</span>. However, variance terms cannot be negative! A more sensible approach would have been to perform a constrained search for MLEs, considering any potential values for <span class="math inline">\(\beta_0\)</span> but only non-negative values for <span class="math inline">\(\sigma^2\)</span>. This constrained search is illustrated in the right plot in Figure <a href="ch-3level.html#fig:boundary">10.13</a>. In this case, the likelihood is maximized at <span class="math inline">\((\hat{\beta}_0 , \hat{\sigma}^2)=(4,0)\)</span>. Note that the estimated intercept did not change, but the estimated variance is simply set at the smallest allowable value – at the <strong>boundary constraint</strong>.</p>

<div class="figure" style="text-align: center"><span id="fig:boundary"></span>
<img src="bookdown-bysh_files/figure-html/boundary-1.png" alt="Left (a): hypothetical contours of the likelihood function \(L(\beta_0, \sigma^2)\) with no restrictions on \(\sigma^2\); the likelihood function is maximized at \((\hat{\beta}_0, \hat{\sigma}^2)=(4,-2)\). Right (b): hypothetical contours of the likelihood function \(L(\beta_0, \sigma^2)\) with the restriction that \(\sigma^2 \geq 0\); the constrained likelihood function is maximized at \((\hat{\beta}_0, \hat{\sigma}^2)=(4,0)\)" width="60%" />
<p class="caption">
Figure 10.13: Left (a): hypothetical contours of the likelihood function <span class="math inline">\(L(\beta_0, \sigma^2)\)</span> with no restrictions on <span class="math inline">\(\sigma^2\)</span>; the likelihood function is maximized at <span class="math inline">\((\hat{\beta}_0, \hat{\sigma}^2)=(4,-2)\)</span>. Right (b): hypothetical contours of the likelihood function <span class="math inline">\(L(\beta_0, \sigma^2)\)</span> with the restriction that <span class="math inline">\(\sigma^2 \geq 0\)</span>; the constrained likelihood function is maximized at <span class="math inline">\((\hat{\beta}_0, \hat{\sigma}^2)=(4,0)\)</span>
</p>
</div>
<p>Graphically, in this simple illustration, the effect of the boundary constraint is to alter the likelihood function from a nice hill (in the left plot in Figure <a href="ch-3level.html#fig:boundary">10.13</a>) with a single peak at <span class="math inline">\((4,-2)\)</span>, to a hill with a huge cliff face where <span class="math inline">\(\sigma^2=0\)</span>. The highest point overlooking this cliff is at <span class="math inline">\((4,0)\)</span>, straight down the hill from the original peak.</p>
<p>In general, then, boundary constraints occur when the maximum likelihood estimator of at least one model parameter occurs at the limits of allowable values (such as estimated correlation coefficients of -1 or 1, or estimated variances of 0). Maximum likelihood estimates at the boundary tend to indicate that the likelihood function would be maximized at non-allowable values of that parameter, if an unconstrained search for MLEs was conducted. Most software packages, however, will only report maximum likelihood estimates with allowable values. Therefore, boundary constraints would ideally be avoided, if possible.</p>
<p>What should you do if you encounter boundary constraints? Often, boundary constraints signal that your model needs to be reparameterized – i.e., you should alter your model to feature different parameters or ones that are interpreted differently. This can be accomplished in several ways:</p>
<ul>
<li>remove parameters, especially those variance and correlation terms which are being estimated on their boundaries</li>
<li>fix the values of certain parameters; for instance, you could set two variance terms equal to each other, thereby reducing the number of unknown parameters to estimate by one</li>
<li>transform covariates. Centering variables, standardizing variables, or changing units can all help stabilize a model. Numerical procedures for searching for and finding maximum likelihood estimates can encounter difficulties when variables have very high or low values, extreme ranges, outliers, or are highly correlated.</li>
</ul>
<p>Although it is worthwhile attempting to reparameterize models to remove boundary constraints, sometimes they can be tolerated if (a) you are not interested in estimates of those parameters encountering boundary issues, and (b) removing those parameters does not affect conclusions about parameters of interest. For example, in the output below we explore the implications of simply removing the correlation between error terms at the pot level (i.e., assume <span class="math inline">\(\rho_{\tilde{u}\tilde{v}}=0\)</span> rather than accepting the (constrained) maximum likelihood estimate of <span class="math inline">\(\hat{\rho}_{\tilde{u}\tilde{v}}=-1\)</span> that we saw in Model C).</p>
<pre><code>Formula: hgt ~ time13 + strl + cult + rem + time13:strl + time13:cult +  
    time13:rem + (time13 | plant) + (1 | pot) + (0 + time13 |      pot)

Random effects:
 Groups   Name        Variance  Std.Dev. Corr
 plant    (Intercept) 0.2941010 0.54231      
          time13      0.0012062 0.03473  0.22
 pot      (Intercept) 0.0591621 0.24323      
 pot.1    time13      0.0001375 0.01173      
 Residual             0.0821742 0.28666      
Number of obs: 413, groups:  plant, 107; pot, 32

Fixed effects:
            Estimate Std. Error t value
(Intercept)  1.51209    0.12965  11.663
time13       0.10158    0.00836  12.150
strl        -0.08743    0.15407  -0.567
cult         0.13235    0.18563   0.713
rem          0.10661    0.17931   0.595
time13:strl  0.05869    0.01038   5.653
time13:cult -0.03065    0.01234  -2.484
time13:rem  -0.03810    0.01209  -3.150</code></pre>
<p>Note that the estimated variance components are all very similar to Model C, and the estimated fixed effects and their associated t-statistics are also very similar to Model C. Therefore, in this case we could consider simply reporting the results of Model C despite the boundary constraint.</p>
<p>However, when removing boundary constraints through reasonable model reparameterizations is possible, that is typically the preferred route. In this case, one option we might consider is simplifying Model C by setting <span class="math inline">\(\sigma_{\tilde{v}}^{2}=\sigma_{\tilde{u}\tilde{v}}=0\)</span>. We can then write our new model (Model C.1) in level-by-level formulation:</p>
<ul>
<li>Level One (timepoint within plant):
<span class="math display">\[\begin{equation}
Y_{ijk} = a_{ij}+b_{ij}\textstyle{time}_{ijk}+\epsilon_{ijk}
\end{equation}\]</span></li>
<li>Level Two (plant within pot):
<span class="math display">\[\begin{eqnarray*}
a_{ij} &amp; = &amp; a_{i}+u_{ij} \\
b_{ij} &amp; = &amp; b_{i}+v_{ij}
\end{eqnarray*}\]</span></li>
<li>Level Three (pot):
<span class="math display">\[\begin{eqnarray*}
a_{i} &amp; = &amp; \alpha_{0}+\alpha_{1}\textstyle{strl}_{i}+\alpha_{2}\textstyle{cult}_{i}+\alpha_{3}\textstyle{rem}_{i}+\tilde{u}_{i} \\
b_{i} &amp; = &amp; \beta_{0}+\beta_{1}\textstyle{strl}_{i}+\beta_{2}\textstyle{cult}_{i}+\beta_{3}\textstyle{rem}_{i}
\end{eqnarray*}\]</span></li>
</ul>
<p>Note that there is no longer an error term associated with the model for mean growth rate <span class="math inline">\(b_{i}\)</span> at the pot level. The growth rate for pot <span class="math inline">\(i\)</span> is assumed to be fixed, after accounting for soil type and sterilization; all pots with the same soil type and sterilization are assumed to have the same growth rate. As a result, our error assumption at Level Three is no longer bivariate normal, but rather univariate normal: <span class="math inline">\(\tilde{u}_{i}\sim N(0,\sigma_{\tilde{u}}^{2})\)</span>. By removing one of our two Level Three error terms (<span class="math inline">\(\tilde{v}_{i}\)</span>), we effectively removed two parameters – the variance for <span class="math inline">\(\tilde{v}_{i}\)</span> and the correlation between <span class="math inline">\(\tilde{u}_{i}\)</span> and <span class="math inline">\(\tilde{v}_{i}\)</span>. Fixed effects remain similar, as can be seen in the output below:</p>
<pre><code>Formula: hgt ~ time13 + strl + cult + rem + time13:strl + time13:cult +  
    time13:rem + (time13 | plant) + (1 | pot)

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 plant    (Intercept) 0.294718 0.54288      
          time13      0.001327 0.03642  0.19
 pot      (Intercept) 0.057654 0.24011      
 Residual             0.082221 0.28674      
Number of obs: 413, groups:  plant, 107; pot, 32

Fixed effects:
             Estimate Std. Error t value
(Intercept)  1.512224   0.129007  11.722
time13       0.101091   0.007453  13.565
strl        -0.087518   0.153441  -0.570
cult         0.132876   0.184887   0.719
rem          0.106536   0.178601   0.597
time13:strl  0.059264   0.009492   6.244
time13:cult -0.030824   0.011353  -2.715
time13:rem  -0.036244   0.011102  -3.265</code></pre>
<p>We now have a more stable model, free of boundary constraints. In fact, we can attempt to determine whether or not removing the two variance component parameters for Model C.1 provides a significant reduction in performance. Based on a likelihood ratio test (see below), we do not have significant evidence (chi-square test statistic=2.089 on 2 df, p=0.3519) that <span class="math inline">\(\sigma_{\tilde{v}}^{2}\)</span> or <span class="math inline">\(\sigma_{\tilde{u}\tilde{v}}\)</span> is non-zero, so it is advisable to use the simpler Model C.1. However, Section <a href="ch-3level.html#threelevel-paraboot">10.6</a> describes why this test may be misleading and prescribes a potentially better approach.</p>
<pre><code>...
         Df    AIC    BIC  logLik deviance Chisq Chi Df Pr(&gt;Chisq)
modelcl0 13 581.64 633.95 -277.82   555.64                        
modelcl  15 583.55 643.90 -276.78   553.55 2.089      2     0.3519
...</code></pre>
</div>
<div id="threelevel-paraboot" class="section level2">
<h2><span class="header-section-number">10.6</span> Parametric bootstrap testing</h2>
<p>When testing random effects at the boundary (such as <span class="math inline">\(\sigma_{\tilde{v}}^{2} = 0\)</span>), using a chi-square distribution to conduct a likelihood ratio test like we did in Section <a href="ch-3level.html#sec:boundary">10.5</a> is not appropriate. In fact, this will produce a conservative test, with p-values that are too large and not rejected enough (Raudenbush and Bryk, Singer and Willett, Faraway). For example, we should suspect that the p-value (.3519) produced by the likelihood ratio test comparing Models C and C.1 in Section <a href="ch-3level.html#sec:boundary">10.5</a> is too large, that the real probability of getting a likelihood ratio test statistic of 2.089 or greater when Model C.1 is true is smaller than .3519. Researchers often use the <strong>parametric bootstrap</strong> to better approximate the distribution of the likelihood test statistic and produce more accurate p-values by simulating data under the null hypothesis.</p>
<p>Here are the basic steps for running a parametric bootstrap procedure to compare Model C.1 with Model C (see associated diagram below):</p>
<ul>
<li>Fit Model C.1 (the null model) to obtain estimated fixed and random effects (This is the “parametric” part.)</li>
<li>Use the estimated fixed and random effects from the null model to regenerate a new set of plant heights with the same sample size (<span class="math inline">\(n=413\)</span>) and associated covariates for each observation as the original data (This is the “bootstrap” part.)</li>
<li>Fit both Model C.1 (the reduced model) and Model C (the full model) to the new data</li>
<li>Compute a likelihood ratio statistic comparing Models C.1 and C</li>
<li>Repeat the previous 3 steps many times (e.g., 1000)</li>
<li>Produce a histogram of likelihood ratio statistics to illustrate its behavior when the null hypothesis is true</li>
<li>Calculate a p-value by finding the proportion of times the bootstrapped test statistic is greater than our observed test statistic</li>
</ul>
<div class="figure">
<img src="data/ParametricBootstrapDiagram.PNG" alt="The steps in conducting a parametric bootstrap test comparing Models C and C.1." />
<p class="caption">The steps in conducting a parametric bootstrap test comparing Models C and C.1.</p>
</div>
<p>Let’s see how new plant heights are generated under the parametric bootstrap. Consider, for instance, <span class="math inline">\(i=1\)</span> and <span class="math inline">\(j=1,2\)</span>. That is, consider Plants #11 and #12. These plants are found in Pot #1, which was randomly assigned to contain sterilized soil from a restored prairie (STP):</p>
<pre><code>  pot plant soil sterile species germin hgt13 hgt18 hgt23 hgt28
1   1    11  STP       Y       L      Y   2.3   2.9   4.5   5.1
2   1    12  STP       Y       L      Y   1.9   2.0   2.6   3.5</code></pre>
<p><strong>Level Three</strong></p>
<p>One way to see the data generation process under the null model (Model C.1) is to start with Level Three and work backwards to Level One. Recall that our Level Three models for <span class="math inline">\(a_{i}\)</span> and <span class="math inline">\(b_{i}\)</span>, the true intercept and slope from Pot <span class="math inline">\(i\)</span>, in Model C.1 are:</p>
<span class="math display">\[\begin{eqnarray*}
a_{i} &amp; = &amp; \alpha_{0}+\alpha_{1}\textstyle{strl}_{i}+\alpha_{2}\textstyle{cult}_{i}+\alpha_{3}\textstyle{rem}_{i}+\tilde{u}_{i} \\
b_{i} &amp; = &amp; \beta_{0}+\beta_{1}\textstyle{strl}_{i}+\beta_{2}\textstyle{cult}_{i}+\beta_{3}\textstyle{rem}_{i}
\end{eqnarray*}\]</span>
<p>All the <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> terms will be fixed at their estimated values, so the one term that will change for each bootstrapped data set is <span class="math inline">\(\tilde{u}_{i}\)</span>. As we obtain a numeric value for <span class="math inline">\(\tilde{u}_{i}\)</span> for each pot, we will fix the subscript. For example, if <span class="math inline">\(\tilde{u}_{i}\)</span> is set to -.192 for Pot #1, then we would denote this by <span class="math inline">\(\tilde{u}_{1}=-.192\)</span>. Similarly, in the context of Model C.1, <span class="math inline">\(a_{1}\)</span> represents the mean height at Day 13 across all plants in Pot #1, where <span class="math inline">\(\tilde{u}_{1}\)</span> quantifies how Pot #1’s Day 13 height relates to other pots with the same sterilization and soil type.</p>
<p>According to Model C.1, each <span class="math inline">\(\tilde{u}_{i}\)</span> is sampled from a normal distribution with mean 0 and standard deviation .240 (note that the standard deviation <span class="math inline">\(\sigma^2_{u}\)</span> is also fixed at its estimated value from Model C.1, given in Section <a href="ch-3level.html#sec:boundary">10.5</a>). For example, a random component to the intercept for Pot #1 (<span class="math inline">\(\tilde{u}_{1}\)</span>) would be sampled from the just-mentioned normal distribution; say, for instance, <span class="math inline">\(\tilde{u}_{1}=-.192\)</span>. Then we can produce a model-based intercept and slope for Pot #1:</p>
<span class="math display">\[\begin{eqnarray*}
a_{1} &amp; = &amp; 1.512-.088(1)+.133(0)+.107(0)-.192 = 1.232 \\
b_{1} &amp; = &amp; .101+.059(1)-.031(0)-.036(0) = .160
\end{eqnarray*}\]</span>
<p>Notice a couple of features of the above derivations. First, all of the coefficients from the above equations (<span class="math inline">\(\alpha_{0}=1.512\)</span>, <span class="math inline">\(\alpha_{1}=-.088\)</span>, etc.) come from the estimated fixed effects from Model C.1 reported in Section <a href="ch-3level.html#sec:boundary">10.5</a>. Second, “restored prairie” is the reference level for soil type, so that indicators for “cultivated land” and “remnant prairie” are both 0. Third, the mean intercept (Day 13 height) for observations from sterilized restored prairie soil is 1.512 - 0.088 = 1.424 mm across all pots, while the mean daily growth is .160 mm. Pot #1 therefore has mean Day 13 height that is .192 mm below the mean for all pots with sterilized restored prairie soil, but every such pot is assumed to have the same growth rate of .160 mm/day because of our assumption that there is no pot-to-pot variability in growth rate (i.e., <span class="math inline">\(\tilde{v}_{i}=0\)</span>).</p>
<p><strong>Level Two</strong></p>
<p>We next proceed to Level Two, where our equations for Model C.1 are:</p>
<span class="math display">\[\begin{eqnarray*}
a_{ij} &amp; = &amp; a_{i}+u_{ij} \\
b_{ij} &amp; = &amp; b_{i}+v_{ij}
\end{eqnarray*}\]</span>
<p>We will initially focus on Plant #11 from Pot #1. Notice that the intercept (Day 13 height = <span class="math inline">\(a_{11}\)</span>) for Plant #11 has two components: the mean Day 13 height for Pot #1 (<span class="math inline">\(a_{1}\)</span>) which we specified at Level Three, and an error term (<span class="math inline">\(u_{11}\)</span>) which indicates how the Day 13 height for Plant #11 differs from the overall average for all plants from Pot #1. The slope (daily growth rate = <span class="math inline">\(b_{11}\)</span>) for Plant #11 similarly has two components. Since both <span class="math inline">\(a_{1}\)</span> and <span class="math inline">\(b_{1}\)</span> were determined at Level Three, at this point we need to find the two error terms for Plant #11: <span class="math inline">\(u_{11}\)</span> and <span class="math inline">\(v_{11}\)</span>. According to our multilevel model, we can sample <span class="math inline">\(u_{11}\)</span> and <span class="math inline">\(v_{11}\)</span> from a bivariate normal distribution with means both equal to 0, standard deviation for the intercept of .543, standard deviation for the slope of .036, and correlation between the intercept and slope of .194.</p>
For instance, suppose we sample <span class="math inline">\(u_{11}=.336\)</span> and <span class="math inline">\(v_{11}=.029\)</span>. Then we can produce a model-based intercept and slope for Plant #11:
<span class="math display">\[\begin{eqnarray*}
a_{11} &amp; = &amp; 1.232+.336 = 1.568 \\
b_{11} &amp; = &amp; .160+.029 = .189
\end{eqnarray*}\]</span>
<p>Although plants from Pot #1 have a mean Day 13 height of 1.232 mm, Plant #11’s mean Day 13 height is .336 mm above that. Similarly, although plants from Pot #1 have a mean growth rate of .160 mm/day (just like every other pot with sterilized restored prairie soil), Plant #11’s growth rate is .029 mm/day faster.</p>
<p><strong>Level One</strong></p>
<p>Finally we proceed to Level One, where the height of Plant #11 is modeled as a linear function of time (<span class="math inline">\(1.568 + .189\textstyle{time}_{11k}\)</span>) with a normally distributed residual <span class="math inline">\(\epsilon_{11k}\)</span> at each time point <span class="math inline">\(k\)</span>. Four residuals (one for each time point) are sampled independently from a normal distribution with mean 0 and standard deviation .287 – the standard deviation again coming from parameter estimates from fitting Model C.1 to the actual data as reported in Section <a href="ch-3level.html#sec:boundary">10.5</a>. Suppose we obtain residuals of <span class="math inline">\(\epsilon_{111}=-.311\)</span>, <span class="math inline">\(\epsilon_{112}=.119\)</span>, <span class="math inline">\(\epsilon_{113}=.241\)</span>, and <span class="math inline">\(\epsilon_{114}=-.066\)</span>. In that case, our parametrically generated data for Plant #11 from Pot #1 would look like:</p>
<p><span class="math display">\[ \begin{array}{rcccl}
   Y_{111} &amp; = &amp; 1.568+.189(0)-.311 &amp; = &amp; 1.257 \\
   Y_{112} &amp; = &amp; 1.568+.189(5)+.119 &amp; = &amp; 2.632 \\
   Y_{113} &amp; = &amp; 1.568+.189(10)+.241 &amp; = &amp; 3.699 \\
   Y_{114} &amp; = &amp; 1.568+.189(15)-.066 &amp; = &amp; 4.337 \\
   \end{array} \]</span></p>
<p>We would next turn to Plant #12 from Pot #1 (<span class="math inline">\(i=1\)</span> and <span class="math inline">\(j=2\)</span>). Fixed effects would remain the same, as would coefficients for Pot #1, <span class="math inline">\(a_{1} = 1.232\)</span> and <span class="math inline">\(b_{1} = .160\)</span>, at Level Three. We would, however, sample new residuals <span class="math inline">\(u_{12}\)</span> and <span class="math inline">\(v_{12}\)</span> at Level Two, producing a different intercept <span class="math inline">\(a_{12}\)</span> and slope <span class="math inline">\(b_{12}\)</span> than those observed for Plant #11. Four new independent residuals <span class="math inline">\(\epsilon_{12k}\)</span> would also be selected at Level One, from the same normal distribution as before with mean 0 and standard deviation .287.</p>
<p>Once an entire set of simulated heights for every pot, plant, and time point have been generated based on Model C.1, two models are fit to this data:</p>
<ul>
<li>Model C.1 – the correct (null) model that was actually used to generate the responses</li>
<li>Model C – the incorrect (full) model that contains two extra variance components – <span class="math inline">\(\sigma_{\tilde{v}}^{2}\)</span> and <span class="math inline">\(\sigma_{\tilde{u}\tilde{v}}\)</span> – that were not actually used when generating the responses</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generate 1 set of bootstrapped data and run chi-square test</span>
<span class="kw">set.seed</span>(<span class="dv">3333</span>)
d &lt;-<span class="st"> </span><span class="kw">drop</span>(<span class="kw">simulate</span>(modelcl0))
m2 &lt;-<span class="kw">refit</span>(modelcl, <span class="dt">newresp=</span>d)
m1 &lt;-<span class="kw">refit</span>(modelcl0, <span class="dt">newresp=</span>d)
<span class="kw">anova</span>(m2,m1)</code></pre></div>
<pre><code>## Data: leaddata
## Models:
## m1: hgt ~ time13 + strl + cult + rem + time13:strl + time13:cult + 
## m1:     time13:rem + (time13 | plant) + (1 | pot)
## m2: hgt ~ time13 + strl + cult + rem + time13:strl + time13:cult + 
## m2:     time13:rem + (time13 | plant) + (time13 | pot)
##    Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(&gt;Chisq)
## m1 13 588.48 640.78 -281.24   562.48                         
## m2 15 591.07 651.42 -280.54   561.07 1.4054      2     0.4953</code></pre>
<p>A likelihood ratio test statistic is calculated comparing Model C.1 to Model C. For example, after continuing as above to generate new <span class="math inline">\(Y_{ijk}\)</span> values corresponding to all 413 leadplant height measurements, we fit the “bootstrapped” data using both models. Since the data was generated using Model C.1, we would expect the two extra terms in Model C (<span class="math inline">\(\sigma^2_{\tilde{v}}\)</span> and <span class="math inline">\(\sigma_{\tilde{u}\tilde{v}}\)</span>) to contribute very little to the quality of the fit; Model C will have a slightly larger likelihood and loglikelihood since it contains every parameter from Model C.1 plus two more, but the difference in the likelihoods should be due to chance. In fact, that is what the output above shows. Model C does have a larger loglikelihood than Model C.1 (-280.54 vs. -281.24), but this small difference is not statistically significant based on a chi-square test with 2 degrees of freedom (p=.4953).</p>
<p>However, we are really only interested in saving the likelihood ratio test statistic from this bootstrapped sample (<span class="math inline">\(2*(-280.54 - (-281.24) = 1.40\)</span>). By generating (“bootstrapping”) many sets of responses based on estimated parameters from Model C.1 and calculating many likelihood ratio test statistics, we can observe how this test statistic behaves under the null hypothesis of <span class="math inline">\(\sigma_{\tilde{v}}^{2} = \sigma_{\tilde{u}\tilde{v}} = 0\)</span>, rather than making the (dubious) assumption that its behavior is described by a chi-square distribution with 2 degrees of freedom. Figure <a href="ch-3level.html#fig:paraboot">10.14</a> illustrates the null distribution of the likelihood ratio test statistic derived by the parametric bootstrap procedure as compared to a chi-square distribution. A p-value for comparing our full and reduced models can be approximated by finding the proportion of likelihood ratio test statistics generated under the null model which exceed our observed likelihood ratio test (2.089). The parametric bootstrap provides a more reliable p-value in this case (.088 from table below); a chi-square distribution puts too much mass in the tail and not enough near 0, leading to overestimation of the p-value. Based on this test, we would still choose our simpler Model C.1, but we nearly had enough evidence to favor the more complex model.</p>
<pre><code>Data: leaddata
Parametric bootstrap with 1000 samples.
Models:
m0: hgt ~ time13 + strl + cult + rem + time13:strl + time13:cult + 
m0:     time13:rem + (time13 | plant) + (1 | pot)
mA: hgt ~ time13 + strl + cult + rem + time13:strl + time13:cult + 
mA:     time13:rem + (time13 | plant) + (time13 | pot)
   Df    AIC    BIC  logLik deviance Chisq Chi Df Pr_boot(&gt;Chisq)
m0 13 581.64 633.95 -277.82   555.64                             
mA 15 583.55 643.90 -276.78   553.55 2.089      2           0.088</code></pre>
<div class="figure" style="text-align: center"><span id="fig:paraboot"></span>
<img src="bookdown-bysh_files/figure-html/paraboot-1.png" alt="Null distribution of likelihood ratio test statistic derived using parametric bootstrap (histogram) compared to a chi-square distribution with 2 degrees of freedom (smooth curve).  The horizontal line represents the observed likelihood ratio test statistic." width="60%" />
<p class="caption">
Figure 10.14: Null distribution of likelihood ratio test statistic derived using parametric bootstrap (histogram) compared to a chi-square distribution with 2 degrees of freedom (smooth curve). The horizontal line represents the observed likelihood ratio test statistic.
</p>
</div>
<p>Another way of testing whether or not we should stick with the reduced model or reject it in favor of the larger model is by generating parametric bootstrap samples, and then using those samples to produce 95% confidence intervals for both <span class="math inline">\(\sigma_{\tilde{u}\tilde{v}} = 0\)</span> and <span class="math inline">\(\sigma_{\tilde{v}}^{2} = 0\)</span>. From the output below, the confidence intervals for <span class="math inline">\(\sigma_{\tilde{u}\tilde{v}}\)</span> (Index 10) and <span class="math inline">\(\sigma_{\tilde{v}}^{2}\)</span> (Index 11) both contain 0, showing again that we do not have significant evidence to reject the reduced model in favor of the larger one.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Use lmeresampler to get bootstrapped CIs for var components</span>

## running a parametric bootstrap (30 seconds or so if B=100)
<span class="kw">set.seed</span>(<span class="dv">333</span>)
boo1 &lt;-<span class="st"> </span>lmeresampler<span class="op">::</span><span class="kw">bootstrap</span>(<span class="dt">model =</span> modelcl, <span class="dt">fn =</span> varcomp.mer, 
                                <span class="dt">type =</span> <span class="st">&quot;parametric&quot;</span>, <span class="dt">B =</span> <span class="dv">100</span>)

## bootstrap confidence intervals are easily found using &#39;boot.ci&#39;
##  - there are actually 7 variance components
##  - varcomp.mer lists 11, but 4 are actually 0
<span class="kw">boot.ci</span>(boo1, <span class="dt">index =</span> <span class="dv">10</span>, <span class="dt">type=</span><span class="st">&quot;perc&quot;</span>)</code></pre></div>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 100 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = boo1, type = &quot;perc&quot;, index = 10)
## 
## Intervals : 
## Level     Percentile     
## 95%   (-0.0043,  0.0012 )  
## Calculations and Intervals on Original Scale
## Some percentile intervals may be unstable</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">boot.ci</span>(boo1, <span class="dt">index =</span> <span class="dv">11</span>, <span class="dt">type=</span><span class="st">&quot;perc&quot;</span>)</code></pre></div>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 100 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = boo1, type = &quot;perc&quot;, index = 11)
## 
## Intervals : 
## Level     Percentile     
## 95%   ( 0.0000,  0.0004 )  
## Calculations and Intervals on Original Scale
## Some percentile intervals may be unstable</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## you can also examine the bootstrap samples graphically
<span class="co"># plot(boo1, index = 10)</span>
<span class="co"># plot(boo1, index = 11)</span></code></pre></div>
<p>In this section, we have offered the parametric bootstrap as a noticeable improvement over the likelihood ratio test with an approximate chi-square distribution for testing random effects near the boundary. And typically when we conduct hypothesis tests involving variance terms we are testing at the boundary, since we are asking if the variance term is really necessary (i.e., <span class="math inline">\(H_O: \sigma^2=0\)</span> vs. <span class="math inline">\(H_A: \sigma^2 &gt; 0\)</span>). However, what if we are conducting a hypothesis test about a fixed effect? For the typical test of whether or not a fixed effect is significant – e.g., <span class="math inline">\(H_O: \alpha_i=0\)</span> vs. <span class="math inline">\(H_A: \alpha_i \neq 0\)</span> – we are <em>not</em> testing at the boundary, since most fixed effects have no bounds on allowable values. We have often used a likelihood ratio test with an approximate chi-square distribution in these settings – does that provide accurate p-values? Although some research (e.g., Faraway, 2006) shows that p-values of fixed effects from likelihood ratio tests can tend to be anti-conservative (too high), in general the approximation is not bad. We will continue to use the likelihood ratio test with a chi-square distribution for fixed effects, but you could always check your p-values using a parametric bootstrap approach.</p>
</div>
<div id="sec:explodingvarcomps" class="section level2">
<h2><span class="header-section-number">10.7</span> Exploding variance components</h2>
<p>Our modeling task in Section <a href="ch-3level.html#sec:boundary">10.5</a> was simplified by the absence of covariates at Level Two. As multilevel models grow to include three or more levels, the addition of just a few covariates at lower levels can lead to a huge increase in the number of parameters (fixed effects and variance components) that must be estimated throughout the model. In this section, we will examine when and why the number of model parameters might explode, and we will consider strategies for dealing with these potentially complex models.</p>
<p>For instance, consider Model C, where we must estimate a total of 15 parameters: 8 fixed effects plus 7 variance components (1 at Level One, 3 at Level Two, and 3 at Level Three). By adding just a single covariate to the equations for <span class="math inline">\(a_{ij}\)</span> and <span class="math inline">\(b_{ij}\)</span> at Level Two in Model C (say, for instance, the <code>size of each seed</code>), we would now have a total of 30 parameters to estimate! The new multilevel model (Model Cplus) could be written as follows:</p>
<ul>
<li>Level One (timepoint within plant):
<span class="math display" id="eq:lev1timemodcp">\[\begin{equation}
Y_{ijk} = a_{ij}+b_{ij}\textstyle{time}_{ijk}+\epsilon_{ijk}
\tag{10.7}
\end{equation}\]</span></li>
<li>Level Two (plant within pot):
<span class="math display">\[\begin{eqnarray*}
a_{ij} &amp; = &amp; a_{i}+c_{i}\textstyle{seedsize}_{ij}+u_{ij} \\
b_{ij} &amp; = &amp; b_{i}+d_{i}\textstyle{seedsize}_{ij}+v_{ij}
\end{eqnarray*}\]</span></li>
<li>Level Three (pot):
<span class="math display">\[\begin{eqnarray*}
a_{i} &amp; = &amp; \alpha_{0}+\alpha_{1}\textstyle{strl}_{i}+\alpha_{2}\textstyle{cult}_{i}+\alpha_{3}\textstyle{rem}_{i}+ \tilde{u}_{i}\\
b_{i} &amp; = &amp; \beta_{0}+\beta_{1}\textstyle{strl}_{i}+\beta_{2}\textstyle{cult}_{i}+\beta_{3}\textstyle{rem}_{i}+ \tilde{v}_{i} \\
c_{i} &amp; = &amp; \gamma_{0}+\gamma_{1}\textstyle{strl}_{i}+\gamma_{2}\textstyle{cult}_{i}+\gamma_{3}\textstyle{rem}_{i}+ \tilde{w}_{i} \\
d_{i} &amp; = &amp; \delta_{0}+\delta_{1}\textstyle{strl}_{i}+\delta_{2}\textstyle{cult}_{i}+\delta_{3}\textstyle{rem}_{i}+ \tilde{z}_{i}
\end{eqnarray*}\]</span></li>
</ul>
or as a composite model:
<span class="math display">\[\begin{eqnarray*}
Y_{ijk} &amp; = &amp; [\alpha_{0}+\alpha_{1}\textstyle{strl}_{i}+\alpha_{2}\textstyle{cult}_{i}+\alpha_{3}\textstyle{rem}_{i} +
 \gamma_{0}\textstyle{seedsize}_{ij} + \\
 &amp; &amp; \beta_{0}\textstyle{time}_{ijk} + \beta_{1}\textstyle{strl}_{i}\textstyle{time}_{ijk}+\beta_{2}\textstyle{cult}_{i}\textstyle{time}_{ijk}+ \beta_{3}\textstyle{rem}_{i}\textstyle{time}_{ijk} + \\
 &amp; &amp; \gamma_{1}\textstyle{strl}_{i}\textstyle{seedsize}_{ij}+\gamma_{2}\textstyle{cult}_{i}\textstyle{seedsize}_{ij}+ \gamma_{3}\textstyle{rem}_{i}\textstyle{seedsize}_{ij} + \\
 &amp; &amp; \delta_{0}\textstyle{seedsize}_{ij}\textstyle{time}_{ijk} + \delta_{1}\textstyle{strl}_{i}\textstyle{seedsize}_{ij}\textstyle{time}_{ijk} + \delta_{2}\textstyle{cult}_{i}\textstyle{seedsize}_{ij}\textstyle{time}_{ijk} + \\
 &amp; &amp; \delta_{3}\textstyle{rem}_{i}\textstyle{seedsize}_{ij}\textstyle{time}_{ijk}] + \\
 &amp; &amp; [\tilde{u}_{i} + u_{ij} + \epsilon_{ijk} + \tilde{w}_{i}\textstyle{seedsize}_{ij} + \tilde{v}_{i}\textstyle{time}_{ijk} + v_{ij}\textstyle{time}_{ijk} + \tilde{z}_{i}\textstyle{seedsize}_{ij}\textstyle{time}_{ijk} ]
\end{eqnarray*}\]</span>
<p>where <span class="math inline">\(\epsilon_{ijk}\sim N(0,\sigma^2)\)</span>, <span class="math display">\[ \left[ \begin{array}{c}
            u_{ij} \\ v_{ij}
          \end{array}  \right] \sim N \left( \left[
          \begin{array}{c}
            0 \\ 0
          \end{array} \right], \left[
          \begin{array}{cc}
            \sigma_{u}^{2} &amp; \\
            \sigma_{uv} &amp; \sigma_{v}^{2}
          \end{array} \right] \right), \]</span> and <span class="math display">\[ \left[ \begin{array}{c}
            \tilde{u}_{i} \\ \tilde{v}_{i} \\ \tilde{w}_{i} \\ \tilde{z}_{i}
          \end{array}  \right] \sim N \left( \left[
          \begin{array}{c}
            0 \\ 0 \\ 0 \\ 0
          \end{array} \right], \left[
          \begin{array}{cccc}
            \sigma_{\tilde{u}}^{2} &amp; &amp; &amp; \\
            \sigma_{\tilde{u}\tilde{v}} &amp; \sigma_{\tilde{v}}^{2} &amp; &amp; \\
            \sigma_{\tilde{u}\tilde{w}} &amp; \sigma_{\tilde{v}\tilde{w}} &amp; \sigma_{\tilde{w}}^{2} &amp; \\
            \sigma_{\tilde{u}\tilde{z}} &amp; \sigma_{\tilde{v}\tilde{z}} &amp; \sigma_{\tilde{w}\tilde{z}} &amp; \sigma_{\tilde{z}}^{2}
          \end{array} \right] \right). \]</span> We would have 16 fixed effects from the four equations at Level Three, each with 4 fixed effects to estimate if we use the same 3 indicators for soil type and sterilization for each <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(c\)</span>, and <span class="math inline">\(d\)</span>. And, with four equations at Level Three, the error covariance matrix at the pot level would be 4x4 with 10 variance components to estimate; each error term (4) has a variance associated with it, and each pair of error terms (6) has an associated correlation. The error structure at Levels One (1 variance term) and Two (2 variance terms and 1 correlation) would remain the same, for a total of 14 variance components.</p>
<p>Now consider adding an extra Level One covariate to the model in the previous paragraph. How many model parameters would now need to be estimated? (Try writing out the multilevel models and counting parameters…) The correct answer is 52 total parameters! There are 24 fixed effects (from 6 Level Three equations) and 28 variance components (1 at Level One, 6 at Level Two, and 21 at Level Three).</p>
<p>Estimating even 30 parameters as in Model Cplus from a single set of data is an ambitious task and computationally very challenging. Essentially we (or the statistics package we are using) must determine which combination of values for the 30 parameters would maximize the likelihood associated with our model and the observed data. Even in the absolute simplest case, with only two options for each parameter, there would be over one billion possible combinations to consider. But if our primary interest is in fixed effects, we really only have 5 covariates (and their associated interactions) in our model. What can be done to make fitting a 3-level model with 1 covariate at Level One, 1 at Level Two, and 3 at Level Three more manageable? Reasonable options include:</p>
<ul>
<li>Reduce the number of variance components by assuming all error terms to be independent; that is, set all correlation terms to 0.</li>
<li>Reduce the number of variance components by removing error terms from certain Level Two and Three equations. Often, researchers will begin with a <strong>random intercepts model</strong>, in which only the first equation at Level Two and Three has an error term. With the leadplant data, we would account for variability in Day 13 height (intercept) among plants and pots, but assume that the effects of time and seed size are constant among pots and plants.</li>
<li>Reduce the number of fixed effects by removing interaction terms that are not expected to be meaningful. Interaction terms between covariates at different levels can be eliminated simply by reducing the number of terms in certain equations at Levels Two and Three. There is no requirement that all equations at a certain level contain the same set of predictors. Often, researchers will not include covariates in equations beyond the intercept at a certain level unless there’s a compelling reason.</li>
</ul>
<p>By following the options above, our potential 30-parameter model can be simplified to this 9-parameter model:</p>
<ul>
<li>Level One:
<span class="math display">\[\begin{equation}
Y_{ijk} = a_{ij}+b_{ij}\textstyle{time}_{ijk}+\epsilon_{ijk}
\end{equation}\]</span></li>
<li>Level Two:
<span class="math display">\[\begin{eqnarray*}
a_{ij} &amp; = &amp; a_{i}+c_{i}\textstyle{seedsize}_{ij}+u_{ij} \\
b_{ij} &amp; = &amp; b_{i}
\end{eqnarray*}\]</span></li>
<li>Level Three:
<span class="math display">\[\begin{eqnarray*}
a_{i} &amp; = &amp; \alpha_{0} + \alpha_{1}\textstyle{strl}_{i} + \alpha_{2}\textstyle{cult}_{i} + \alpha_{3}\textstyle{rem}_{i} + \tilde{u}_{i} \\
b_{i} &amp; = &amp; \beta_{0} \\
c_{i} &amp; = &amp; \gamma_{0}
\end{eqnarray*}\]</span></li>
</ul>
<p>where <span class="math inline">\(\epsilon_{ijk}\sim N(0,\sigma^2)\)</span>, <span class="math inline">\(u_{ij}\sim N(0,\sigma_{u}^{2})\)</span>, and <span class="math inline">\(\tilde{u}_{i}\sim N(0,\sigma_{\tilde{u}}^{2})\)</span>. Or, in terms of a composite model:</p>
<span class="math display">\[\begin{eqnarray*}
Y_{ijk} &amp; = &amp; [\alpha_{0}+\alpha_{1}\textstyle{strl}_{i}+\alpha_{2}\textstyle{cult}_{i}+\alpha_{3}\textstyle{rem}_{i} +
 \gamma_{0}\textstyle{seedsize}_{ij} + \beta_{0}\textstyle{time}_{ijk}] + \\
 &amp; &amp; [\tilde{u}_{i}+u_{ij}+\epsilon_{ijk}]
\end{eqnarray*}\]</span>
<p>According to the second option, we have built a random intercepts model with error terms only at the first (intercept) equation at each level. Not only does this eliminate variance terms associated with the missing error terms, but it also eliminates correlation terms between errors (as suggested by Option 1) since there are no pairs of error terms that can be formed at any level. In addition, as suggested by Option 3, we have eliminated predictors (and their fixed effects coefficients) at every equation other than the intercept at each level.</p>
<p>The simplified 9-parameter model essentially includes a random effect for pot (<span class="math inline">\(\sigma_{\tilde{u}}^{2}\)</span>) after controlling for sterilization and soil type, a random effect for plant within pot (<span class="math inline">\(\sigma_{0}^{2}\)</span>) after controlling for seed size, and a random effect for error about the time trend for individual plants (<span class="math inline">\(\sigma^{2}\)</span>). We must assume that the effect of time is the same for all plants and all pots, and it does not depend on seed size, sterilization, or soil type. Similarly, we must assume that the effect of seed size is the same for each pot and does not depend on sterilization or soil type. While somewhat proscriptive, a <strong>random intercepts model</strong> such as this can be a sensible starting point, since the simple act of accounting for variability of observational units at Level Two or Three can produce better estimates of fixed effects of interest and their standard errors.</p>
</div>
<div id="modelsDEF" class="section level2">
<h2><span class="header-section-number">10.8</span> Building to a final model</h2>
<p>In Model C we considered the main effects of soil type and sterilization on leadplant initial height and growth rate, but we did not consider interactions—even though biology researchers expect that sterilization will aid growth in certain soil types more than others. Thus, in Model D we will build Level Three interaction terms into Model C.1:</p>
<ul>
<li>Level One:
<span class="math display">\[\begin{equation}
Y_{ijk} = a_{ij}+b_{ij}\textstyle{time}_{ijk}+\epsilon_{ijk}
\end{equation}\]</span></li>
<li>Level Two:
<span class="math display">\[\begin{eqnarray*}
a_{ij} &amp; = &amp; a_{i}+u_{ij} \\
b_{ij} &amp; = &amp; b_{i}+v_{ij}
\end{eqnarray*}\]</span></li>
<li>Level Three:
<span class="math display">\[\begin{eqnarray*}
a_{i} &amp; = &amp; \alpha_{0} + \alpha_{1}\textstyle{strl}_{i} + \alpha_{2}\textstyle{cult}_{i} + \alpha_{3}\textstyle{rem}_{i} + \alpha_{4}\textstyle{strl}_{i}\textstyle{rem}_{i} + \alpha_{5}\textstyle{strl}_{i}\textstyle{cult}_{i} + \tilde{u}_{i} \\
b_{i} &amp; = &amp; \beta_{0}+\beta_{1}\textstyle{strl}_{i}+\beta_{2}\textstyle{cult}_{i}+\beta_{3}\textstyle{rem}_{i} + \beta_{4}\textstyle{strl}_{i}\textstyle{rem}_{i} + \beta_{5}\textstyle{strl}_{i}\textstyle{cult}_{i}
\end{eqnarray*}\]</span></li>
</ul>
<p>where error terms are defined as in Model C.1.</p>
<p>From the output below, we see that the interaction terms were not especially helpful, except possibly for a differential effect of sterilization in remnant and reconstructed prairies on the growth rate of leadplants. But it’s clear that Model D can be simplified through the removal of certain fixed effects with low t-ratios.</p>
<pre><code>Formula: hgt ~ time13 + strl + cult + rem + time13:strl + time13:cult +  
    time13:rem + strl:cult + strl:rem + time13:strl:cult + time13:strl:rem +  
    (time13 | plant) + (1 | pot)

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 plant    (Intercept) 0.292722 0.54104      
          time13      0.001276 0.03573  0.20
 pot      (Intercept) 0.070544 0.26560      
 Residual             0.082139 0.28660      
Number of obs: 413, groups:  plant, 107; pot, 32

Fixed effects:
                  Estimate Std. Error t value
(Intercept)       1.531250   0.153897   9.950
time13            0.094919   0.008119  11.692
strl             -0.126511   0.222661  -0.568
cult             -0.061835   0.329916  -0.187
rem               0.124258   0.239585   0.519
time13:strl       0.072790   0.012005   6.063
time13:cult      -0.022624   0.020836  -1.086
time13:rem       -0.020474   0.013165  -1.555
strl:cult         0.276162   0.407097   0.678
strl:rem         -0.071397   0.378048  -0.189
time13:strl:cult -0.016082   0.024812  -0.648
time13:strl:rem  -0.051990   0.023951  -2.171</code></pre>
<p>To form Model F, we begin by removing all covariates describing the intercept (Day 13 height), since neither sterilization nor soil type nor their interaction appear to be significantly related to initial height. However, sterilization, remnant prairie soil, and their interaction appear to have significant influences on growth rate, although the effect of cultivated soil on growth rate did not appear significantly different from that of restored prairie soil (the reference level). A likelihood ratio test shows no significant difference between Models D and F (chi-square test statistic = 11.15 on 7 df, p=.1323), supporting the use of simplified Model F.</p>
<pre><code>Formula: 
hgt ~ time13 + time13:strl + time13:rem + time13:strl:rem + (time13 |  
-2.73299 -0.51784  0.04508  0.50400  2.91566 

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 plant    (Intercept) 0.294044 0.54226      
          time13      0.001425 0.03775  0.16
 pot      (Intercept) 0.048710 0.22070      
 Residual             0.082045 0.28643      
Number of obs: 413, groups:  plant, 107; pot, 32

Fixed effects:
                 Estimate Std. Error t value
(Intercept)      1.529092   0.071336  21.435
time13           0.091371   0.007745  11.798
time13:strl      0.059670   0.010375   5.751
time13:rem      -0.016489   0.013238  -1.246</code></pre>
<pre><code>Data: leaddata
Models:
modelfl0: hgt ~ time13 + time13:strl + time13:rem + time13:strl:rem + (time13 | 
modelfl0:     plant) + (1 | pot)
modeldl0: hgt ~ time13 + strl + cult + rem + time13:strl + time13:cult + 
modeldl0:     time13:rem + strl:cult + strl:rem + time13:strl:cult + time13:strl:rem + 
modeldl0:     (time13 | plant) + (1 | pot)
         Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(&gt;Chisq)
modelfl0 10 581.20 621.43 -280.60   561.20                         
modeldl0 17 584.05 652.45 -275.02   550.05 11.148      7     0.1323</code></pre>
<p>We mentioned in Section <a href="ch-3level.html#threelevel-paraboot">10.6</a> that we could compare Model F and Model D, which differ only in their fixed effects terms, using the parametric bootstrap approach. In fact, in Section <a href="ch-3level.html#threelevel-paraboot">10.6</a> we suggested that the p-value using the chi-square approximation (.1323) may be a slight under-estimate of the true p-value, but probably in the ballpark. In fact, when we generated 1000 bootstrapped samples of plant heights under Model F, and produced 1000 simulated likelihood ratios comparing Models D and F, we produced a p-value of .201. In Figure <a href="ch-3level.html#fig:parabootDF">10.15</a>, we see that the chi-square distribution has too much area in the peak and too little area in the tails, although in general it approximates the parametric bootstrap distribution of the likelihood ratio pretty nicely.</p>
<div class="figure" style="text-align: center"><span id="fig:parabootDF"></span>
<img src="bookdown-bysh_files/figure-html/parabootDF-1.png" alt="Null distribution of likelihood ratio test statistic derived using parametric bootstrap (histogram) compared to a chi-square distribution with 7 degrees of freedom (smooth curve).  The horizontal line represents the observed likelihood ratio test statistic." width="60%" />
<p class="caption">
Figure 10.15: Null distribution of likelihood ratio test statistic derived using parametric bootstrap (histogram) compared to a chi-square distribution with 7 degrees of freedom (smooth curve). The horizontal line represents the observed likelihood ratio test statistic.
</p>
</div>
<p>The effects of remnant prairie soil and the interaction between remnant soil and sterilization appear to have marginal benefit in Model F, so we remove those two terms to create Model E. A likelihood ratio test comparing Models E and F, however, shows that Model F significantly outperforms Model E (chi-square test statistic = 9.40 on 2 df, p=.0090). Thus, we will use Model F as our “Final Model” for generating inference.</p>
<pre><code>Formula: hgt ~ time13 + time13:strl + (time13 | plant) + (1 | pot)

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 plant    (Intercept) 0.29441  0.54260      
          time13      0.00159  0.03987  0.14
 pot      (Intercept) 0.04712  0.21707      
 Residual             0.08199  0.28634      
Number of obs: 413, groups:  plant, 107; pot, 32

Fixed effects:
            Estimate Std. Error t value
(Intercept) 1.528770   0.070965  21.543
time13      0.085682   0.006524  13.134
time13:strl 0.058645   0.009364   6.263</code></pre>
<pre><code>refitting model(s) with ML (instead of REML)</code></pre>
<pre><code>...
         Df   AIC    BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)   
modelel0  8 586.6 618.78 -285.3    570.6                           
modelfl0 10 581.2 621.43 -280.6    561.2 9.401      2   0.009091 **
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
...</code></pre>
<p>Our final model (Model F), with its constraints on Level Three error terms, can be expressed level-by-level as:</p>
<ul>
<li>Level One:
<span class="math display">\[\begin{equation}
Y_{ijk} = a_{ij}+b_{ij}\textstyle{time}_{ijk}+\epsilon_{ijk}
\end{equation}\]</span></li>
<li>Level Two:
<span class="math display">\[\begin{eqnarray*}
a_{ij} &amp; = &amp; a_{i}+u_{ij} \\
b_{ij} &amp; = &amp; b_{i}+v_{ij}
\end{eqnarray*}\]</span></li>
<li>Level Three:
<span class="math display">\[\begin{eqnarray*}
a_{i} &amp; = &amp; \alpha_{0} + \tilde{u}_{i} \\
b_{i} &amp; = &amp; \beta_{0}+\beta_{1}\textstyle{strl}_{i}+\beta_{2}\textstyle{rem}_{i} + \beta_{3}\textstyle{strl}_{i}\textstyle{rem}_{i}
\end{eqnarray*}\]</span></li>
</ul>
<p>where <span class="math inline">\(\epsilon_{ijk}\sim N(0,\sigma^2)\)</span>, <span class="math display">\[ \left[ \begin{array}{c}
            u_{ij} \\ v_{ij}
          \end{array}  \right] \sim N \left( \left[
          \begin{array}{c}
            0 \\ 0
          \end{array} \right], \left[
          \begin{array}{cc}
            \sigma_{u}^{2} &amp; \\
            \sigma_{uv} &amp; \sigma_{v}^{2}
          \end{array} \right] \right), \]</span> and <span class="math inline">\(\tilde{{u}_{i}}\sim N(0,\sigma_{\tilde{u}}^{2})\)</span>.</p>
<p>In composite form, we have:</p>
<span class="math display">\[\begin{eqnarray*}
Y_{ijk} &amp; = &amp; [\alpha_{0}+ \beta_{0}\textstyle{time}_{ijk} + \beta_{1}\textstyle{strl}_{i}\textstyle{time}_{ijk} + \beta_{2}\textstyle{rem}_{i}\textstyle{time}_{ijk} + \beta_{3}\textstyle{strl}_{i}\textstyle{rem}_{i}\textstyle{time}_{ijk}] + \\
 &amp; &amp; [\tilde{u}_{i}+u_{ij}+\epsilon_{ijk}+v_{ij}\textstyle{time}_{ijk}]
\end{eqnarray*}\]</span>
<p>Estimates of model parameters can be interpreted in the following manner:</p>
<ul>
<li><span class="math inline">\(\hat{\sigma}=.287=\)</span> the standard deviation in within-plant residuals after accounting for time.</li>
<li><span class="math inline">\(\hat{\sigma}_{u}=.543=\)</span> the standard deviation in Day 13 heights between plants from the same pot.</li>
<li><span class="math inline">\(\hat{\sigma}_{v}=.037=\)</span> the standard deviation in rates of change in height between plants from the same pot.</li>
<li><span class="math inline">\(\hat{\rho}_{uv}=.157=\)</span> the correlation in plants’ Day 13 height and their rate of change in height.</li>
<li><span class="math inline">\(\hat{\sigma}_{\tilde{u}}=.206=\)</span> the standard deviation in Day 13 heights between pots.</li>
<li><span class="math inline">\(\hat{\alpha}_{0}=1.529=\)</span> the mean height for leadplants 13 days after planting.</li>
<li><span class="math inline">\(\hat{\beta}_{0}=0.091=\)</span> the mean daily change in height from 13 to 28 days after planting for leadplants from reconstructed prairies or cultivated lands (<code>rem</code>=0) with no sterilization (<code>strl</code>=0) .</li>
<li><span class="math inline">\(\hat{\beta}_{1}=0.060=\)</span> the increase in mean daily change in height for leadplants from using sterilized soil instead of unsterilized soil in reconstructed prairies or cultivated lands. Thus, leadplants grown in sterilized soil from reconstructed prairies or cultivated lands have an estimated daily increase in height of 0.151 mm.</li>
<li><span class="math inline">\(\hat{\beta}_{2}=-0.017=\)</span> the decrease in mean daily change in height for leadplants from using unsterilized soil from remnant prairies, rather than unsterilized soil from reconstructed prairies or cultivated lands. Thus, leadplants grown in unsterilized soil from remnant prairies have an estimated daily increase in height of 0.074 mm.</li>
<li><span class="math inline">\(\hat{\beta}_{3}=-0.039=\)</span> the decrease in mean daily change in height for leadplants from sterilized soil from remnant prairies, compared to the expected daily change based on <span class="math inline">\(\hat{\beta}_{1}\)</span> and <span class="math inline">\(\hat{\beta}_{2}\)</span>. Three-way interactions show that the size of an interaction between two predictors differs depending on the level of a third predictor. Whew! In this case, we might focus on how the interaction between remnant prairies and time differs for unsterilized and sterilized soil. Specifically, the negative effect of remnant prairies on growth rate (compared to reconstructed prairies or cultivated lands) is larger in sterilized soil than unsterilized; in sterilized soil, plants from remnant prairie soil grow .056 mm/day slower on average than plants from other soil types (.095 vs. .151 mm/day), while in unsterilized soil, plants from remnant prairie soil grow just .017 mm/day slower than plants from other soil types (.074 vs. .091 mm/day). Note that the difference between .056 and .017 is our three-way interaction coefficient. Through this three-way interaction term, we also see that leadplants grown in sterilized soil from remnant prairies have an estimated daily increase in height of 0.095 mm.</li>
</ul>
<p>Based on t-values produced by Model F, sterilization has the most significant effect on leadplant growth, while there is some evidence that growth rate is somewhat slower in remnant prairies, and that the effect of sterilization is also somewhat muted in remnant prairies. Sterilization leads to an estimated 66% increase in growth rate of leadplants from Days 13 to 28 in soil from reconstructed prairies and cultivated lands, and an estimated 28% increase in soil from remnant prairies. In unsterilized soil, plants from remnant prairies grow an estimated 19% slower than plants from other soil types.</p>
</div>
<div id="error-3level" class="section level2">
<h2><span class="header-section-number">10.9</span> Covariance structure (Optional)</h2>
<p>As in Chapter <a href="ch-lon.html#ch-lon">9</a>, it is important to be aware of the covariance structure implied by our chosen models (focusing initially on Model B). Our three-level model, through error terms at each level, defines a specific covariance structure at both the plant level (Level Two) and the pot level (Level Three). For example, our standard model implies a certain level of correlation among measurements from the same plant and among plants from the same pot. Although three-level models are noticeably more complex than two-level models, it is still possible to systematically determine the implication of our standard model; by doing this, we can evaluate whether our fitted model agrees with our exploratory analyses, and we can also decide if it’s worth considering alternative covariance structures.</p>
<p>We will first consider Model B with <span class="math inline">\(\tilde{v}_{i}\)</span> at Level Three, and then we will evaluate the resulting covariance structure that results from removing <span class="math inline">\(\tilde{v}_{i}\)</span>, thereby restricting <span class="math inline">\(\sigma_{\tilde{v}}^{2}=\sigma_{\tilde{u}\tilde{v}}=0\)</span>. The composite version of Model B has been previously expressed as:</p>
<span class="math display" id="eq:modbcomp">\[\begin{equation}
Y_{ijk}=[\alpha_{0}+\beta_{0}\textstyle{time}_{ijk}]+
[\tilde{u}_{i}+u_{ij}+\epsilon_{ijk}+(\tilde{v}_{i}+v_{ij})\textstyle{time}_{ijk}]
\tag{10.8}
\end{equation}\]</span>
<p>where <span class="math inline">\(\epsilon_{ijk}\sim N(0,\sigma^2)\)</span>, <span class="math display">\[ \left[ \begin{array}{c}
            u_{ij} \\ v_{ij}
          \end{array}  \right] \sim N \left( \left[
          \begin{array}{c}
            0 \\ 0
          \end{array} \right], \left[
          \begin{array}{cc}
            \sigma_{u}^{2} &amp; \\
            \sigma_{uv} &amp; \sigma_{v}^{2}
          \end{array} \right] \right), \]</span> and <span class="math display">\[ \left[ \begin{array}{c}
            \tilde{u}_{i} \\ \tilde{v}_{i}
          \end{array}  \right] \sim N \left( \left[
          \begin{array}{c}
            0 \\ 0
          \end{array} \right], \left[
          \begin{array}{cc}
            \sigma_{\tilde{u}}^{2} &amp; \\
            \sigma_{\tilde{u}\tilde{v}} &amp; \sigma_{\tilde{v}}^{2}
          \end{array} \right] \right). \]</span></p>
<p>In order to assess the implied covariance structure from our standard model, we must first derive variance and covariance terms for related observations (i.e., same timepoint and same plant, different timepoints but same plant, different plants but same pot). Each derivation will rely on the random effects portion of the composite model, since there is no variability associated with fixed effects. For ease of notation, we will let <span class="math inline">\(t_{k}=\textstyle{time}_{ijk}\)</span>, since all plants were planned to be observed on the same 4 days.</p>
The variance for an individual observation can be expressed as:
<span class="math display" id="eq:var">\[\begin{equation}
Var(Y_{ijk}) = (\sigma^{2} + \sigma_{u}^{2} + \sigma_{\tilde{u}}^{2}) + 2(\sigma_{uv} + \sigma_{\tilde{u}\tilde{v}})t_k + (\sigma_{v}^{2} + \sigma_{\tilde{v}}^{2})t_{k}^{2},
\tag{10.9}
\end{equation}\]</span>
<p>and the covariance between observations taken at different timepoints (<span class="math inline">\(k\)</span> and <span class="math inline">\(k^{&#39;}\)</span>) from the same plant (<span class="math inline">\(j\)</span>) is:</p>
<span class="math display" id="eq:cov1">\[\begin{equation}

Cov(Y_{ijk},Y_{ijk^{&#39;}}) = (\sigma_{u}^{2} + \sigma_{\tilde{u}}^{2}) + (\sigma_{uv} + \sigma_{\tilde{u}\tilde{v}})(t_{k}+t_{k^{&#39;}}) + (\sigma_{v}^{2} + \sigma_{\tilde{v}}^{2})t_{k}t_{k^{&#39;}},
\tag{10.10}
\end{equation}\]</span>
<p>and the covariance between observations taken at potentially different times (<span class="math inline">\(k\)</span> and <span class="math inline">\(k&#39;\)</span>) from different plants (<span class="math inline">\(j\)</span> and <span class="math inline">\(j^{&#39;}\)</span>) from the same pot (<span class="math inline">\(i\)</span>) is:</p>
<span class="math display" id="eq:cov2">\[\begin{equation}
Cov(Y_{ijk},Y_{ij^{&#39;}k^{&#39;}}) = \sigma_{\tilde{u}}^{2} + \sigma_{\tilde{u}\tilde{v}}(t_{k}+t_{k^{&#39;}}) + \sigma_{\tilde{v}}^{2}t_{k}t_{k^{&#39;}}.
\tag{10.11}
\end{equation}\]</span>
<p>Based on these variances and covariances, the covariance matrix for observations over time from the same plant (<span class="math inline">\(j\)</span>) from pot <span class="math inline">\(i\)</span> can be expressed as the following 4x4 matrix:</p>
<p><span class="math display">\[  Cov(\textbf{Y}_{ij}) = \left[
          \begin{array}{cccc}
            \tau_{1}^{2} &amp; &amp; &amp; \\
            \tau_{12} &amp; \tau_{2}^{2} &amp; &amp; \\
            \tau_{13} &amp; \tau_{23} &amp; \tau_{3}^{2} &amp; \\
            \tau_{14} &amp; \tau_{24} &amp; \tau_{34} &amp; \tau_{4}^{2}
          \end{array} \right], \]</span></p>
<p>where <span class="math inline">\(\tau_{k}^{2}=Var(Y_{ijk})\)</span> and <span class="math inline">\(\tau_{kk&#39;}=Cov(Y_{ijk},Y_{ijk&#39;})\)</span>. Note that <span class="math inline">\(\tau_{k}^{2}\)</span> and <span class="math inline">\(\tau_{kk&#39;}\)</span> are both independent of <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> so that <span class="math inline">\(Cov(\textbf{Y}_{ij})\)</span> will be constant for all plants from all pots. That is, every plant from every pot will have the same set of variances over the four timepoints and the same correlations between heights at different timepoints. But, the variances and correlations can change depending on the timepoint under consideration as suggested by the presence of <span class="math inline">\(t_k\)</span> terms in Equations <a href="ch-3level.html#eq:var">(10.9)</a> through <a href="ch-3level.html#eq:cov2">(10.11)</a>.</p>
<p>Similarly, the covariance matrix between observations from plants <span class="math inline">\(j\)</span> and <span class="math inline">\(j&#39;\)</span> from pot <span class="math inline">\(i\)</span> can be expressed as this 4x4 matrix:</p>
<p><span class="math display">\[  Cov(\textbf{Y}_{ij},\textbf{Y}_{ij&#39;}) = \left[
          \begin{array}{cccc}
            \tilde{\tau}_{11} &amp; &amp; &amp; \\
            \tilde{\tau}_{12} &amp; \tilde{\tau}_{22} &amp; &amp; \\
            \tilde{\tau}_{13} &amp; \tilde{\tau}{23} &amp; \tilde{\tau}_{33} &amp; \\
            \tilde{\tau}_{14} &amp; \tilde{\tau}_{24} &amp; \tilde{\tau}_{34} &amp; \tilde{\tau}_{44}
          \end{array} \right], \]</span></p>
<p>where <span class="math inline">\(\tilde{\tau}_{kk}=Cov(Y_{ijk},Y_{ij&#39;k})=\sigma_{\tilde{u}}^{2}+2\sigma_{\tilde{u}\tilde{v}}t_{k}+\sigma_{\tilde{v}}^{2}t_{k}^{2}\)</span> and <span class="math inline">\(\tilde{\tau}_{kk&#39;}=Cov(Y_{ijk},Y_{ij&#39;k&#39;})\)</span> as derived above. As we saw with <span class="math inline">\(Cov(\textbf{Y}_{ij})\)</span>, <span class="math inline">\(\tilde{\tau}_{kk}\)</span> and <span class="math inline">\(\tilde{\tau}_{kk&#39;}\)</span> are both independent of <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> so that <span class="math inline">\(Cov(\textbf{Y}_{ij},\textbf{Y}_{ij&#39;})\)</span> will be constant for all pairs of plants from all pots. That is, any pair of plants from the same pot will have the same correlations between heights at any two timepoints. As with any covariance matrix, we can convert <span class="math inline">\(Cov(\textbf{Y}_{ij},\textbf{Y}_{ij&#39;})\)</span> into a correlation matrix if desired.</p>
<p>Now that we have the general covariance structure implied by the standard multilevel model in place, we can examine the specific structure suggested by the estimates of variance components in Model B. Restricted maximum likelihood (REML) in Section <a href="ch-3level.html#initialmodels-3level">10.4</a> produced the following estimates for variance components: <span class="math inline">\(\hat{\sigma}^2=.0822\)</span>, <span class="math inline">\(\hat{\sigma}_{u}^{2}=.299\)</span>, <span class="math inline">\(\hat{\sigma}_{v}^{2}=.00119\)</span>, <span class="math inline">\(\hat{\sigma}_{uv}=\hat{\rho}_{uv}\sqrt{\hat{\sigma}_{u}^{2}\hat{\sigma}_{v}^{2}}=.00528\)</span>, <span class="math inline">\(\hat{\sigma}_{\tilde{u}}^{2}=.0442\)</span>, <span class="math inline">\(\hat{\sigma}_{\tilde{v}}^{2}=.00126\)</span>, <span class="math inline">\(\hat{\sigma}_{\tilde{u}\tilde{v}}=\hat{\rho}_{\tilde{u}\tilde{v}}\sqrt{\hat{\sigma}_{\tilde{u}}^{2}\hat{\sigma}_{\tilde{v}}^{2}}=-.00455\)</span>. Based on these estimates and the derivations above, the within-plant correlation structure over time is estimated to be:</p>
<p><span class="math display">\[  Corr(\textbf{Y}_{ij}) = \left[
          \begin{array}{cccc}
            1 &amp; &amp; &amp; \\
            .76 &amp; 1 &amp; &amp; \\
            .65 &amp; .82 &amp; 1 &amp; \\
            .54 &amp; .77 &amp; .88 &amp; 1
          \end{array} \right] \]</span></p>
<p>for all plants <span class="math inline">\(j\)</span> and all pots <span class="math inline">\(i\)</span>, and the correlation structure between different plants from the same pot is estimated to be:</p>
<p><span class="math display">\[  Corr(\textbf{Y}_{ij},\textbf{Y}_{ij&#39;}) = \left[
          \begin{array}{cccc}
            .104 &amp; &amp; &amp; \\
            .047 &amp; .061 &amp; &amp; \\
            -.002 &amp; .067 &amp; .116 &amp; \\
            -.037 &amp; .068 &amp; .144 &amp; .191
          \end{array} \right]. \]</span></p>
<p>The within-plant correlation structure suggests that measurements taken closer in time tend to be more highly correlated than those with more separation in time, and later measurements tend to be more highly correlated than earlier measurements. Examination of standard deviation terms by timepoint suggests that variability increases over time within a plant (estimated SDs of .652, .703, .828, and .999 for days 13, 18, 23, and 28, respectively). The correlation structure between plants from the same pot depicts a fairly low level of correlation; even for measurements taken at the same timepoint, the largest correlation between plants from the same pot occurs on Day 28 (r=.191) while the smallest correlation occurs on Day 18 (r=.061).</p>
<p>We can use these results to estimate within-plant and within-pot correlation structure after imposing the same constraints on Model B that we did on Model F (i.e., <span class="math inline">\(\sigma_{\tilde{v}}^{2}=\sigma_{\tilde{u}\tilde{v}}=0\)</span>). Using the same REML variance components estimates as above except that <span class="math inline">\(\hat{\sigma}_{\tilde{v}}^{2}=0\)</span> rather than <span class="math inline">\(.00126\)</span> and <span class="math inline">\(\hat{\sigma}_{\tilde{u}\tilde{v}}=\hat{\rho}_{\tilde{u}\tilde{v}}\sqrt{\hat{\sigma}_{\tilde{u}}^{2}\hat{\sigma}_{\tilde{v}}^{2}}=0\)</span> rather than <span class="math inline">\(-.00455\)</span>, the within-plant correlation structure is estimated to be:</p>
<p><span class="math display">\[  Corr(\textbf{Y}_{ij}) = \left[
          \begin{array}{cccc}
            1 &amp; &amp; &amp; \\
            .80 &amp; 1 &amp; &amp; \\
            .75 &amp; .84 &amp; 1 &amp; \\
            .70 &amp; .82 &amp; .88 &amp; 1
          \end{array} \right] \]</span></p>
<p>for all plants <span class="math inline">\(j\)</span> and all pots <span class="math inline">\(i\)</span>, and the correlation structure between different plants from the same pot is estimated to be:</p>
<p><span class="math display">\[  Corr(\textbf{Y}_{ij},\textbf{Y}_{ij&#39;}) = \left[
          \begin{array}{cccc}
            .104 &amp; &amp; &amp; \\
            .095 &amp; .087 &amp; &amp; \\
            .084 &amp; .077 &amp; .068 &amp; \\
            .073 &amp; .067 &amp; .059 &amp; .052
          \end{array} \right]. \]</span></p>
<p>Our model restrictions produced slightly higher estimated within-plant correlations, especially for observations separated by longer periods of time. Standard deviation terms by timepoint are very similar (estimated SDs of .652, .713, .806, and .923 for days 13, 18, 23, and 28, respectively). In terms of the relationship between heights of different plants from the same pot, our model restrictions produced slightly higher correlation estimates with Day 13 height, but slightly lower correlation estimates associated with heights at Days 23 and 28. For measurements taken at the same timepoint, the largest correlation between plants from the same pot now occurs on Day 13 (r=.104) while the smallest correlation now occurs on Day 28 (r=.052). None of the differences in the covariance structure, however, should have a large impact on final conclusions, especially regarding fixed effects, so our strategy for dealing with boundary constraints appears very reasonable. In addition, the covariance structure implied by our standard 3-level model appears to model the correlation structure we observed in Figure <a href="ch-3level.html#fig:corrstruct">10.12</a> during our exploratory analyses very nicely. Even the variability over time implied by the standard model matches well with the raw observed variability in height by time period (respective standard deviations of .64, .64, .86, and .91). Thus, we feel well justified in fitting models based on the standard covariance structure.</p>
<div id="optionalerror" class="section level3">
<h3><span class="header-section-number">10.9.1</span> Details of covariance structures</h3>
<p>In this section, we present additional details regarding implications of our standard covariance structure for 3-level models. We will focus on Model B; derivations for Model F would proceed in a similar fashion.</p>
<p>The variance for an individual observation can be derived as:</p>
<span class="math display">\[\begin{eqnarray*}
Var(Y_{ijk}) &amp; = &amp; Var(\epsilon_{ijk}+u_{ij}+\tilde{u}_{i}+(v_{ij}+\tilde{v}_{i})\textstyle{time}_{ijk}) \\
 &amp; = &amp; (\sigma^{2} + \sigma_{u}^{2} + \sigma_{\tilde{u}}^{2}) + 2(\sigma_{uv} + \sigma_{\tilde{u}\tilde{v}})t_k + (\sigma_{v}^{2} + \sigma_{\tilde{v}}^{2})t_{k}^{2}
\end{eqnarray*}\]</span>
<p>The covariance between observations taken at different timepoints from the same plant is:</p>
<span class="math display">\[\begin{eqnarray*}
Cov(Y_{ijk},Y_{ijk&#39;}) &amp; = &amp; Cov(\epsilon_{ijk}+u_{ij}+\tilde{u}_{i}+(v_{ij}+\tilde{v}_{i})t_{k}, \epsilon_{ijk&#39;}+u_{ij}+\tilde{u}_{i}+(v_{ij}+\tilde{v}_{i})t_{k&#39;}) \\
 &amp; = &amp; (\sigma_{u}^{2} + \sigma_{\tilde{u}}^{2}) + (\sigma_{uv} + \sigma_{\tilde{u}\tilde{v}})(t_{k}+t_{k&#39;}) + (\sigma_{v}^{2} + \sigma_{\tilde{v}}^{2})t_{k}t_{k&#39;}
\end{eqnarray*}\]</span>
<p>The covariance between observations taken from different plants from the same pot is:</p>
<span class="math display">\[\begin{eqnarray*}
Cov(Y_{ijk},Y_{ij&#39;k&#39;}) &amp; = &amp; Cov(\epsilon_{ijk}+u_{ij}+\tilde{u}_{i}+(v_{ij}+\tilde{v}_{i})t_{k}, \epsilon_{ij&#39;k&#39;}+u_{ij&#39;}+\tilde{u}_{i}+(v_{ij&#39;}+\tilde{v}_{i})t_{k&#39;}) \\
 &amp; = &amp; \sigma_{\tilde{u}}^{2} + \sigma_{\tilde{u}\tilde{v}}(t_{k}+t_{k&#39;}) + \sigma_{\tilde{v}}^{2}t_{k}t_{k&#39;}
\end{eqnarray*}\]</span>
<p>Based on these variances and covariances and the expressions for <span class="math inline">\(Cov(\textbf{Y}_{ij})\)</span> and <span class="math inline">\(Cov(\textbf{Y}_{ij},\textbf{Y}_{ij&#39;})\)</span> in Section <a href="ch-3level.html#error-3level">10.9</a>, the complete covariance matrix for observations from pot <span class="math inline">\(i\)</span> can be expressed as the following 24x24 matrix (assuming 4 observations over time for each of 6 plants):</p>
<p><span class="math display">\[  Cov(\textbf{Y}_{i}) = \left[
          \begin{array}{cccccc}
            Cov(\textbf{Y}_{i1}) &amp; &amp; &amp; &amp; &amp; \\
            Cov(\textbf{Y}_{i1},\textbf{Y}_{i2}) &amp; Cov(\textbf{Y}_{i2}) &amp; &amp; &amp; &amp; \\
            Cov(\textbf{Y}_{i1},\textbf{Y}_{i3}) &amp; Cov(\textbf{Y}_{i2},\textbf{Y}_{i3}) &amp; Cov(\textbf{Y}_{i3}) &amp; &amp; &amp; \\
            Cov(\textbf{Y}_{i1},\textbf{Y}_{i4}) &amp; Cov(\textbf{Y}_{i2},\textbf{Y}_{i4}) &amp; Cov(\textbf{Y}_{i3},\textbf{Y}_{i4}) &amp; Cov(\textbf{Y}_{i4}) &amp; &amp; \\
            Cov(\textbf{Y}_{i1},\textbf{Y}_{i5}) &amp; Cov(\textbf{Y}_{i2},\textbf{Y}_{i5}) &amp; Cov(\textbf{Y}_{i3},\textbf{Y}_{i5}) &amp; Cov(\textbf{Y}_{i4},\textbf{Y}_{i5}) &amp; Cov(\textbf{Y}_{i5}) &amp; \\
            Cov(\textbf{Y}_{i1},\textbf{Y}_{i6}) &amp; Cov(\textbf{Y}_{i2},\textbf{Y}_{i6}) &amp; Cov(\textbf{Y}_{i3},\textbf{Y}_{i6}) &amp; Cov(\textbf{Y}_{i4},\textbf{Y}_{i6}) &amp; Cov(\textbf{Y}_{i5},\textbf{Y}_{i6}) &amp; Cov(\textbf{Y}_{i6})
          \end{array} \right]. \]</span></p>
<p>A covariance matrix for our entire data set, therefore, would be block diagonal, with <span class="math inline">\(Cov(\textbf{Y}_{i})\)</span> matrices along the diagonal reflecting within pot correlation and 0’s off-diagonal reflecting the assumed independence of observations from plants from different pots. As with any covariance matrix, we can convert the <span class="math inline">\(Cov(\textbf{Y}_{ij},\textbf{Y}_{ij&#39;})\)</span> blocks for two different plants from the same pot into correlation matrices by dividing covariance terms by the product of corresponding standard deviations. Specifically, for <span class="math inline">\(Cov(\textbf{Y}_{ij},\textbf{Y}_{ij&#39;})\)</span>, the diagonal terms in a correlation matrix are formed by <span class="math inline">\(Corr(Y_{ijk},Y_{ij&#39;k})=\frac{\tilde{\tau}_{kk}}{\sqrt{Var(Y_{ijk})Var(Y_{ij&#39;k})}}=\frac{\tilde{\tau}_{kk}}{\tau_{k}^{2}}\)</span> and the off-diagonal terms are formed by <span class="math inline">\(Corr(Y_{ijk},Y_{ij&#39;k&#39;})=\frac{\tilde{\tau}_{kk&#39;}}{\sqrt{Var(Y_{ijk})Var(Y_{ij&#39;k&#39;})}}=\frac{\tilde{\tau}_{kk&#39;}}{\tau_{k}\tau_{k&#39;}}\)</span>.</p>
<p>We calculated estimated covariance and correlation matrices within plant and between plants in Section <a href="ch-3level.html#error-3level">10.9</a> based on the standard covariance structure for three-level models. However, it can sometimes be helpful to consider alternative covariance structures and evaluate the robustness of results to changes in assumptions. A couple of natural covariance structures to fit in the Seed Germination case study, given the observed structure in our data, are the heterogeneous compound symmetry and heterogeneous AR(1) models. We fit both structures, along with the toeplitz structure, and compared the resulting models with our standard 3-level model. In all cases, the AIC and BIC from the standard model (615.2 and 651.4, respectively) are considerably lower than the corresponding performance measures from the models with alternative covariance structures. Thus, we feel justified in fitting models based on the standard covariance structure.</p>
</div>
</div>
<div id="usingR3" class="section level2">
<h2><span class="header-section-number">10.10</span> Notes on Using R (Optional)</h2>
<p>The R code below fits Models A-C.1 from Sections <a href="ch-3level.html#initialmodels-3level">10.4</a> and <a href="ch-3level.html#sec:boundary">10.5</a>. Note that, in lmer(), an estimated variance at Level One (<span class="math inline">\(\sigma^{2}\)</span>) comes for “free”, but variance terms at Level Two (<span class="math inline">\(\sigma_{u}^{2}\)</span>) and Level Three (<span class="math inline">\(\sigma_{\tilde{u}}^{2}\)</span>) must be specified separately in Model A through “(1<span class="math inline">\(|\)</span>plant)” and “(1<span class="math inline">\(|\)</span>pot)”. Specifying “(time13<span class="math inline">\(|\)</span>plant)” in Model B is equivalent to specifying “(1+time13<span class="math inline">\(|\)</span>plant)” and produces a total of 3 variance components to estimate: variances for error terms associated with the intercept (<span class="math inline">\(\sigma_{u}^{2}\)</span> comes for “free”) and slope (<span class="math inline">\(\sigma_{v}^{2}\)</span> comes from the <code>time13</code> term) at the plant level, along with a covariance or correlation (<span class="math inline">\(\sigma_{uv}\)</span> or <span class="math inline">\(\rho_{uv}\)</span>) between those two error terms. To restrict <span class="math inline">\(\sigma_{uv} = \rho_{uv} = 0\)</span>, you could specify each error term separately: “(1<span class="math inline">\(|\)</span>plant) + (time13<span class="math inline">\(|\)</span>plant)”.</p>
<p>Also note that to fit Model C.1 in R, the random error components are written as “(time13<span class="math inline">\(|\)</span>plant) + (1<span class="math inline">\(|\)</span>pot)”, indicating you’d like error terms associated with the intercept and slope at the plant level, but only for the intercept term at the pot level. The fixed effects in Model C.1 just reflect all fixed effects in the composite model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lme4)

<span class="co"># Model A - unconditional means</span>
modelal =<span class="st"> </span><span class="kw">lmer</span>(hgt <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>plant) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>pot), <span class="dt">REML=</span>T, <span class="dt">data=</span>leaddata)
<span class="kw">summary</span>(modelal)

<span class="co"># Model B - unconditional growth</span>
modelbl =<span class="st"> </span><span class="kw">lmer</span>(hgt <span class="op">~</span><span class="st"> </span>time13 <span class="op">+</span><span class="st"> </span>(time13<span class="op">|</span>plant) <span class="op">+</span><span class="st"> </span>(time13<span class="op">|</span>pot),
  <span class="dt">REML=</span>T, <span class="dt">data=</span>leaddata)
<span class="kw">summary</span>(modelbl)

<span class="co"># Model C - add covariates at pot level</span>
modelcl =<span class="st"> </span><span class="kw">lmer</span>(hgt <span class="op">~</span><span class="st"> </span>time13 <span class="op">+</span><span class="st"> </span>strl <span class="op">+</span><span class="st"> </span>cult <span class="op">+</span><span class="st"> </span>rem <span class="op">+</span><span class="st"> </span>time13<span class="op">:</span>strl <span class="op">+</span>
<span class="st">  </span>time13<span class="op">:</span>cult <span class="op">+</span><span class="st"> </span>time13<span class="op">:</span>rem <span class="op">+</span><span class="st"> </span>(time13<span class="op">|</span>plant) <span class="op">+</span><span class="st"> </span>(time13<span class="op">|</span>pot),
  <span class="dt">REML=</span>T, <span class="dt">data=</span>leaddata)
<span class="kw">summary</span>(modelcl)   <span class="co"># get corr=-1 at pot level</span>

<span class="co"># Model C.1 - remove two variance components at Level Two from Model C</span>
modelcl0 =<span class="st"> </span><span class="kw">lmer</span>(hgt <span class="op">~</span><span class="st"> </span>time13 <span class="op">+</span><span class="st"> </span>strl <span class="op">+</span><span class="st"> </span>cult <span class="op">+</span><span class="st"> </span>rem <span class="op">+</span><span class="st"> </span>time13<span class="op">:</span>strl <span class="op">+</span>
<span class="st">  </span>time13<span class="op">:</span>cult <span class="op">+</span><span class="st"> </span>time13<span class="op">:</span>rem <span class="op">+</span><span class="st"> </span>(time13<span class="op">|</span>plant) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>pot),
  <span class="dt">REML=</span>T, <span class="dt">data=</span>leaddata)
<span class="kw">summary</span>(modelcl0)</code></pre></div>
<p>In Section <a href="ch-3level.html#threelevel-paraboot">10.6</a> we sought to perform a significance test comparing Models C and C.1, where Model C.1 restricted two variance components from Model C to be 0. Our initial attempt used the anova() function in R, which created two problems: (a) the anova() function uses full maximum likelihood estimates rather than REML estimates of model parameters and performance, which is fine when two models differ in fixed effects but not, as in this case, when two models differ only in random effects; and, (b) the likelihood ratio test statistic is often not well approximated by a chi-square distribution. Therefore, we implemented the parametric bootstrap method to simulate the distribution of the likelihood ratio test statistic and obtain a more reliable p-value, also illustrating that the chi-square distribution would produce an artificially large p-value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(modelcl0,modelcl)   <span class="co"># go with Model C.0 (fewer varcomps)</span>

<span class="co"># run bootstrapAnova function = parametric bootstrap code for lme4-models</span>
<span class="co">#   http://stats.stackexchange.com/questions/4858/</span>
<span class="co">#     longitudinal-data-analysis-by-multilevel-modeling-in-r/4870#4870</span>
<span class="co">#   Posted on Nov 24, 2010, by Fabian Scheipl</span>

<span class="co">#m0 is the lmer model under the null hypothesis (i.e. the smaller model)</span>
<span class="co">#mA is the lmer model under the alternative</span>

bootstrapAnova &lt;-<span class="st"> </span><span class="cf">function</span>(mA, m0, <span class="dt">B=</span><span class="dv">100</span>){
     oneBootstrap &lt;-<span class="st"> </span><span class="cf">function</span>(m0, mA){
         d &lt;-<span class="st"> </span><span class="kw">drop</span>(<span class="kw">simulate</span>(m0))
         m2 &lt;-<span class="kw">refit</span>(mA, <span class="dt">newresp=</span>d)
         m1 &lt;-<span class="kw">refit</span>(m0, <span class="dt">newresp=</span>d)
         <span class="kw">return</span>(<span class="kw">anova</span>(m2,m1)<span class="op">$</span>Chisq[<span class="dv">2</span>])
     }
     nulldist &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, <span class="kw">oneBootstrap</span>(m0, mA))
     ret &lt;-<span class="st"> </span><span class="kw">anova</span>(mA, m0)
     ret<span class="op">$</span><span class="st">&quot;Pr(&gt;Chisq)&quot;</span>[<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">mean</span>(ret<span class="op">$</span>Chisq[<span class="dv">2</span>] <span class="op">&lt;</span><span class="st"> </span>nulldist)
     <span class="kw">names</span>(ret)[<span class="dv">7</span>] &lt;-<span class="st"> &quot;Pr_boot(&gt;Chisq)&quot;</span>
     <span class="kw">attr</span>(ret, <span class="st">&quot;heading&quot;</span>) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">attr</span>(ret, <span class="st">&quot;heading&quot;</span>)[<span class="dv">1</span>],
          <span class="kw">paste</span>(<span class="st">&quot;Parametric bootstrap with&quot;</span>, B,<span class="st">&quot;samples.&quot;</span>),
          <span class="kw">attr</span>(ret, <span class="st">&quot;heading&quot;</span>)[<span class="op">-</span><span class="dv">1</span>])
     <span class="kw">attr</span>(ret, <span class="st">&quot;nulldist&quot;</span>) &lt;-<span class="st"> </span>nulldist
     <span class="kw">return</span>(ret)
}
bRLRT =<span class="st"> </span><span class="kw">bootstrapAnova</span>(<span class="dt">mA=</span>modelcl, <span class="dt">m0=</span>modelcl0)
nullLRT =<span class="st"> </span><span class="kw">attr</span>(bRLRT,<span class="st">&quot;nulldist&quot;</span>)
<span class="kw">hist</span>(nullLRT,<span class="dt">prob=</span>T)
<span class="kw">abline</span>(<span class="dt">v=</span><span class="fl">2.1471</span>,<span class="dt">col=</span><span class="dv">2</span>)  <span class="co"># 2.1471 is the observed LRT statistic</span>
x=<span class="kw">seq</span>(<span class="dv">0</span>,<span class="kw">max</span>(nullLRT),<span class="dt">length=</span><span class="dv">1000</span>)
y=<span class="kw">dchisq</span>(x,<span class="dv">2</span>)
<span class="kw">lines</span>(x,y)</code></pre></div>
</div>
<div id="exercises-8" class="section level2">
<h2><span class="header-section-number">10.11</span> Exercises</h2>
<div id="conceptual-exercises-5" class="section level3">
<h3><span class="header-section-number">10.11.1</span> Conceptual Exercises</h3>
<ol style="list-style-type: decimal">
<li><p><strong>Seed Germination.</strong> In Sections <a href="ch-3level.html#organizedata3">10.3.1</a> and <a href="ch-3level.html#explore3v2">10.3.2</a>, why must we be careful excluding plants with no height data? Why can’t we simply leave those plants in our 3-level analysis with all missing heights set to 0 mm?</p></li>
<li><p>Give an example of a Level Two covariate that might have been recorded in this study.</p></li>
<li><p>In Figure <a href="ch-3level.html#fig:boxbyspec">10.1</a>, would using mean heights by pot be reasonable as well? How about for Figure <a href="ch-3level.html#fig:spagbyspec">10.2</a>?</p></li>
<li><p>Explain how “plant-to-plant variability can be estimated by averaging standard deviations from each pot … while pot-to-pot variability can be estimated by finding the standard deviation of average intercept or slope within pot.”</p></li>
<li><p>Shouldn’t we subtract the mean number of days rather than 13 to calculate centered time? Why does the lower correlation between intercepts and slopes produced by centered time result in a more stable model?</p></li>
<li><p>Explain why an autoregressive error structure is suggested for leadplant data at the end of Section <a href="ch-3level.html#explore3v2">10.3.2</a>.</p></li>
<li><p>The experimental factors of interest in the seed germination study are Level Three covariates, yet the unconditional means model shows only 4.6% of total variability in plant heights to be at Level Three. Does that mean a multilevel model will not be helpful? Would it be better to find the mean height for each pot and just use those 72 values to examine the effects of experimental factors?</p></li>
<li><p>Explain why a likelihood ratio test is appropriate for comparing Models B and C.</p></li>
<li><p>Should we be concerned that <span class="math inline">\(\hat{\sigma}_{0}^{2}\)</span> increased from Model A to B? Why or why not?</p></li>
<li><p>Explain the idea of boundary constraints in your own words. Why can it be a problem in multilevel models?</p></li>
<li><p>In Model C, we initially addressed boundary constraints by removing the Level Three correlation between error terms from our multilevel model. What other model adjustments might we have considered?</p></li>
<li><p>Recall Model C from Chapter <a href="ch-lon.html#ch-lon">9</a>. Describe the steps for performing a parametric bootstrap test on <span class="math inline">\(\sigma_{01} = \sigma_{1}^{2} = 0\)</span>.</p></li>
<li><p>How does Figure <a href="ch-3level.html#fig:paraboot">10.14</a> show that a likelihood ratio test using a chi-square distribution would be biased?</p></li>
<li><p>In Section <a href="ch-3level.html#sec:explodingvarcomps">10.7</a>, a model with 52 parameters is described: (a) illustrate that the model does indeed contain 52 parameters; (b) explain how to minimize the total number of parameters using ideas from Section <a href="ch-3level.html#sec:explodingvarcomps">10.7</a>; (c) what assumptions have you made in your simplification in (b)?</p></li>
<li><p>In Section <a href="ch-3level.html#modelsDEF">10.8</a>, Model F (the null model) is compared to Model D using a parametric bootstrap test. As in Section <a href="ch-3level.html#threelevel-paraboot">10.6</a>, show in detail how bootstrapped data would be generated under Model F for, say, Plant # 1 from Pot # 1. For the random parts, tell what distribution the random pieces are coming from and then select a random value from that distribution. Finally, explain how the parametric bootstrap test would be carried out.</p></li>
<li><p>Section <a href="ch-3level.html#modelsDEF">10.8</a> contains an interpretation for the coefficient of a three-way interaction term, <span class="math inline">\(\hat{\beta}_{3}\)</span>. Provide an alternative interpretation for <span class="math inline">\(\hat{\beta}_{3}\)</span> by focusing on how the sterilization-by-soil type interaction differs over time.</p></li>
<li><p><strong>Collective Efficacy and Violent Crime.</strong> In a 1997 Science article, Sampson, Raudenbush, and Earls studied the effects on violent crime of a neighborhood’s collective efficacy, defined as “social cohesion among neighbors combined with their willingness to intervene on behalf of the common good.” Multiple items related to collective efficacy were collected from 8782 Chicago residents from 343 neighborhood clusters. For this study, give the observational units at Levels One, Two, and Three.</p></li>
<li><p>Table <a href="ch-3level.html#tab:table3chp10">10.3</a> shows Table 3 from Sampson et al. (1997). Provide interpretations of the <strong>bolded</strong> coefficients in context.</p></li>
</ol>
<caption>
<p><span id="tab:table3chp10">Table 10.3: </span> Table 3: Correlates of collective efficacy from Sampson et al. (1997).</p>
<table style="width:89%;">
<colgroup>
<col width="44%" />
<col width="19%" />
<col width="12%" />
<col width="12%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Variable</th>
<th align="center">Coefficient</th>
<th align="center">SE</th>
<th align="center">t ratio</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Intercept</td>
<td align="center">3.523</td>
<td align="center">0.013</td>
<td align="center">263.20</td>
</tr>
<tr class="even">
<td align="center">Person-Level predictors</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">Female</td>
<td align="center">-0.012</td>
<td align="center">0.015</td>
<td align="center">-0.76</td>
</tr>
<tr class="even">
<td align="center">Married</td>
<td align="center">-0.005</td>
<td align="center">0.021</td>
<td align="center">-0.25</td>
</tr>
<tr class="odd">
<td align="center">Separated or divorced</td>
<td align="center">-0.045</td>
<td align="center">0.026</td>
<td align="center">-1.72</td>
</tr>
<tr class="even">
<td align="center">Single</td>
<td align="center">-0.026</td>
<td align="center">0.024</td>
<td align="center">-1.05</td>
</tr>
<tr class="odd">
<td align="center">Homeowner</td>
<td align="center"><strong>0.122</strong></td>
<td align="center">0.020</td>
<td align="center">6.04</td>
</tr>
<tr class="even">
<td align="center">Latino</td>
<td align="center">0.042</td>
<td align="center">0.028</td>
<td align="center">1.52</td>
</tr>
<tr class="odd">
<td align="center">Black</td>
<td align="center">-0.029</td>
<td align="center">0.030</td>
<td align="center">-0.98</td>
</tr>
<tr class="even">
<td align="center">Mobility</td>
<td align="center">-0.025</td>
<td align="center">0.007</td>
<td align="center">-3.71</td>
</tr>
<tr class="odd">
<td align="center">Age</td>
<td align="center"><strong>0.0021</strong></td>
<td align="center">0.0006</td>
<td align="center">3.47</td>
</tr>
<tr class="even">
<td align="center">Years in neighborhood</td>
<td align="center">6e-04</td>
<td align="center">0.0008</td>
<td align="center">0.78</td>
</tr>
<tr class="odd">
<td align="center">SES</td>
<td align="center"><strong>0.035</strong></td>
<td align="center">0.008</td>
<td align="center">4.64</td>
</tr>
<tr class="even">
<td align="center">Neighborhood-level predictors</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">Concentrated disadvantage</td>
<td align="center">-0.172</td>
<td align="center">0.016</td>
<td align="center">-10.74</td>
</tr>
<tr class="even">
<td align="center">Immigrant concentration</td>
<td align="center"><strong>-0.037</strong></td>
<td align="center">0.014</td>
<td align="center">-2.66</td>
</tr>
<tr class="odd">
<td align="center">Residential stability</td>
<td align="center"><strong>0.074</strong></td>
<td align="center">0.013</td>
<td align="center">5.61</td>
</tr>
<tr class="even">
<td align="center">Variance Components</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">Within neighborhoods</td>
<td align="center">0.32</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">Between neighborhoods</td>
<td align="center">0.026</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">Percent of variance explained</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">Within neighborhoods</td>
<td align="center">3.2</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center">Between neighborhoods</td>
<td align="center">70.3</td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<ol start="19" style="list-style-type: decimal">
<li><p>Based on Table <a href="ch-3level.html#tab:table3chp10">10.3</a>, let <span class="math inline">\(Y_{ijk}\)</span> be the response of person <span class="math inline">\(j\)</span> from neighborhood <span class="math inline">\(i\)</span> to item <span class="math inline">\(k\)</span> regarding collective efficacy; these are (difficulty-adjusted) responses to 10 items per person about collective efficacy. Then (a) write out the three-level model that likely produced this table, and (b) write out the corresponding composite model. Assume there was also an unreported variance component estimating item-to-item variability within person.</p></li>
<li><p>Suggest valuable exploratory data analysis plots to complement Table <a href="ch-3level.html#tab:table3chp10">10.3</a>.</p></li>
<li><p>If the model suggested by Table <a href="ch-3level.html#tab:table3chp10">10.3</a> were expanded to include all potential variance components, how many total parameters would need to be estimated? If it were expanded further to include the 3 neighborhood-level covariates as predictors in all Level Three equations, how many total parameters would need to be estimated?</p></li>
<li><p>At the bottom of Table <a href="ch-3level.html#tab:table3chp10">10.3</a>, the percent of variance explained is given within and between neighborhoods. Explain what these values likely represent and how they were calculated.</p></li>
<li><p>Table <a href="ch-3level.html#tab:table4chp10">10.4</a> shows a portion of Table 4 from Sampson et al. (1997). Describe the multilevel model that likely produced this table. State the primary result from this table in context. [Note that collective efficacy is a Level Three covariate in this table, summarized over an entire neighborhood.]</p></li>
</ol>
<table>
<caption>
<span id="tab:table4chp10">Table 10.4: </span>A portion of Table 4: Neighborhood correlates of perceived neighborhood violence from Sampson et al. (1997).
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Model 1:social composition
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Model 2:social composition and collective efficacy
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Variable
</td>
<td style="text-align:left;">
Coefficient
</td>
<td style="text-align:left;">
SE
</td>
<td style="text-align:left;">
t
</td>
<td style="text-align:left;">
Coefficient
</td>
<td style="text-align:left;">
SE
</td>
<td style="text-align:left;">
t
</td>
</tr>
<tr>
<td style="text-align:left;">
Concentrated disadvantage
</td>
<td style="text-align:left;">
0.277
</td>
<td style="text-align:left;">
0.021
</td>
<td style="text-align:left;">
13.30
</td>
<td style="text-align:left;">
0.171
</td>
<td style="text-align:left;">
0.024
</td>
<td style="text-align:left;">
7.24
</td>
</tr>
<tr>
<td style="text-align:left;">
Immigrant concentration
</td>
<td style="text-align:left;">
0.041
</td>
<td style="text-align:left;">
0.017
</td>
<td style="text-align:left;">
2.44
</td>
<td style="text-align:left;">
0.018
</td>
<td style="text-align:left;">
0.016
</td>
<td style="text-align:left;">
1.12
</td>
</tr>
<tr>
<td style="text-align:left;">
Residential stability
</td>
<td style="text-align:left;">
-0.102
</td>
<td style="text-align:left;">
0.015
</td>
<td style="text-align:left;">
-6.95
</td>
<td style="text-align:left;">
-0.056
</td>
<td style="text-align:left;">
0.016
</td>
<td style="text-align:left;">
-3.49
</td>
</tr>
<tr>
<td style="text-align:left;">
Collective efficacy
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
-0.618
</td>
<td style="text-align:left;">
0.104
</td>
<td style="text-align:left;">
-5.95
</td>
</tr>
</tbody>
</table>
<ul>
<li>Estimates of neighborhood-level coefficients control for gender, marital status, homeownership, ethnicity, mobility, age, years in neighborhood, and SES of those interviewed. Model 1 accounts for 70.5% of the variation between neighborhoods in perceived violence, whereas model 2 accounts for 77.8% of the variation.</li>
</ul>
</div>
<div id="guided-exercise-5" class="section level3">
<h3><span class="header-section-number">10.11.2</span> Guided Exercise</h3>
<ol style="list-style-type: decimal">
<li><strong>Kentucky Math Scores.</strong> Data was collected from 48,058 eighth graders from Kentucky who took the California Basic Educational Skills Test (Bickel 2007). These students attended 235 different middle schools from 132 different districts, and the following variables were collected:
<ul>
<li><code>dis_id</code> = District Identifier</li>
<li><code>sch_id</code> = School Identifier</li>
<li><code>stud_nm</code> = Student Identifier</li>
<li><code>female</code> = Coded 1 if Female and 0 if Male</li>
<li><code>nonwhite</code> = Coded 0 if White and 1 otherwise</li>
<li><code>readn</code> = California Test of Basic Skills Reading Score</li>
<li><code>mathn</code> = California Test of Basic Skills Math Score</li>
<li><code>sch_size</code> = School-Level Size (centered natural log)</li>
<li><code>sch_ses</code> = School-Level SES (socio-economic status - centered)</li>
<li><code>dis_size</code> = District-Level Size (centered natural log)</li>
<li><code>dis_ses</code> = District-Level SES (socio-economic status - centered)</li>
</ul></li>
</ol>
<p>The primary research questions are whether or not math scores of eighth graders in Kentucky differ based on gender or ethnicity, and if any gender gap differs by ethnicity, or if any ethnicity gap differs by gender. Researchers wanted to be sure to adjust for important covariates at the school and district levels (e.g. school/district size and socio-economic status).</p>
<ol style="list-style-type: lower-alpha">
<li>Conduct a short exploratory data analysis. Which variables are most strongly related to <code>mathn</code>? Illustrate with summary statistics and plots. [Hints: your plots should accommodate the large number of observations in the data, and your summary statistics will have to handle occasional missing values.]</li>
<li>(Model A) Run an unconditional means model with 3 levels and report the percentage of variability in math scores that can be explained at each level.</li>
<li>(Model B) Add <code>female</code>, <code>nonwhite</code>, and their interaction at Level One.</li>
</ol>
<ul>
<li>Write out the complete three-level model. How many parameters must be estimated?</li>
<li>Run the model (be patient – it may take a few minutes!). Report and interpret a relevant pseudo-Rsquare value. Is there evidence (based on the t-value) of a significant interaction? In layman’s terms, what can you conclude based on the test for interaction?</li>
</ul>
<ol start="4" style="list-style-type: lower-alpha">
<li>(Model C) Subtract the <code>female</code>-by-<code>nonwhite</code> interaction from Model B and add <code>sch_ses</code>, where <code>sch_ses</code> is a predictor in all Level Two equations. How many parameters must be estimated? Break your count down into fixed effects + variance components at Level 1 + varcomps at Level 2 + varcomps at Level 3. (No need to write out the model or run the model unless you want to…)</li>
<li>(Model D) Subtract <code>nonwhite</code> from Model C and add <code>dis_size</code>, where <code>dis_size</code> is a predictor in all Level Three equations.
<ul>
<li>Write out the complete three-level model. Also write out the composite model. How many parameters must be estimated?</li>
<li>Run the model (be patient!), and then re-run it with an error term only on the intercept equation at Level Three. What are the implications of using this error structure? Does it change any conclusions about fixed effects? Which of the two models would you choose and why?</li>
<li>(Optional) Explore the nature of the 3-way interaction between female, sch_ses, and dis_size by finding the predicted math score based on Model D with an error term only on the intercept equation at Level Three in 5 cases. Comment on trends you observe.
<ul>
<li>Female vs. male with average <code>sch_ses</code> and <code>dis_size</code></li>
<li>Female vs. male with <code>sch_ses</code> at Q1 and <code>dis_size</code> at Q1</li>
<li>Female vs. male with <code>sch_ses</code> at Q1 and <code>dis_size</code> at Q3</li>
<li>Female vs. male with <code>sch_ses</code> at Q3 and <code>dis_size</code> at Q1</li>
<li>Female vs. male with <code>sch_ses</code> at Q3 and <code>dis_size</code> at Q3</li>
</ul></li>
<li>(Optional) Create two scatterplots to illustrate the 3-way interaction between <code>female</code>, <code>sch_ses</code>, and <code>dis_size</code>.</li>
</ul></li>
</ol>
</div>
<div id="open-ended-exercises-4" class="section level3">
<h3><span class="header-section-number">10.11.3</span> Open-ended Exercises</h3>
<ol style="list-style-type: decimal">
<li><p><strong>Seed Germination: Coneflowers</strong> Repeat the exploratory data analyses and model fitting from this chapter using coneflowers rather than leadplants.</p></li>
<li><p><strong>Mudamalai Leaf Growth</strong> Plant growth is influenced by many environmental factors, among them sunlight and water availability. A study conducted in the Mudamalai Wildlife Sanctuary in India in October of 2008 had as its purpose to “broaden the specific knowledge of certain tree species and climate zones located in the Nilgiri Hills of South India, and to enhance the overall knowledge of the dynamic relationship between plant growth and its environment” (Pray, 2009).</p></li>
</ol>
<p>Study researchers collected 1,960 leaves from 45 different trees (5 trees from each of 3 species within each of 3 climate zone). Within each tree, 3 branches were randomly chosen from each of 3 strata (high, medium, and low), and 5 leaves were randomly selected from each branch. Three different descriptive climatic zones were chosen for analysis—dry thorn, dry deciduous, and moist deciduous—and three different species of trees were analyzed—<em>Cassia fistula</em> (golden shower tree), <em>Anogeissus latifolia</em> (axlewood tree), and <em>Diospyros montana</em> (mountain ebony). Height and girth were measured for each tree, and length was assessed for each branch. Measurements taken on each leaf included length, width, surface area (determined carefully for 25 leaves per species and then by linear regression using length and width as predictors for the rest), pedial length (the length of the stem), pedial width, and percent herbivory (an eyeball estimate of the percent of each leaf that had been removed or eaten by herbivores). In addition, stomata density was measured using a compound scope to examine nail polish impressions of leaves for each strata of each tree (135 measurements).</p>
<p>Here is a description of available variables:</p>
<ul>
<li><code>Species</code> = tree species (Cassia fistula, Anogeissus latifolia, or Diospyros montana)</li>
<li><code>Zone</code> = climate zone (dry thorn, dry deciduous, or moist deciduous)</li>
<li><code>Tree</code> = tree number (1-5) within climate zone</li>
<li><code>Tree.height</code> = tree height (m)</li>
<li><code>Tree.girth</code> = tree girth (cm)</li>
<li><code>Strata</code> = height of branch from ground (high, medium, or low)</li>
<li><code>Branch</code> = branch number (1-3) within tree and strata</li>
<li><code>Branch.length</code> = length of branch (cm)</li>
<li><code>Length</code> = length of leaf (cm)</li>
<li><code>Width</code> = width of leaf (cm)</li>
<li><code>Area</code> = surface area of leaf (sq cm)</li>
<li><code>Pedial.length</code> = length of the leaf stem (mm)</li>
<li><code>Pedial.width</code> = width of the leaf stem (mm)</li>
<li><code>Herbivory</code> = percent of leaf removed or eaten by herbivores</li>
<li><code>Stomata</code> = density of specialized openings that allow for gas exchange on leaves</li>
</ul>
<p>Biology researchers were interested in determining “optimal physical characteristics for growth and survival of these trees in the various areas” to further conservation efforts. Construct a multilevel model to address the researchers’ questions, focusing on leaf area as the response of interest. Defend your final model, and interpret fixed effect and variance component estimates produced by your model.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-lon.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-GLMM.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
