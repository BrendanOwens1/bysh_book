<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Broadening Your Statistical Horizons</title>
  <meta name="description" content="Test.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Broadening Your Statistical Horizons" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Test." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Broadening Your Statistical Horizons" />
  
  <meta name="twitter:description" content="Test." />
  

<meta name="author" content="J. Legler and P. Roback">


<meta name="date" content="2018-02-02">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="ch-distthry.html">
<link rel="next" href="ch-glms.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Broadening Your Statistical Horizons</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html"><i class="fa fa-check"></i><b>1</b> Review of Multiple Linear Regression</a><ul>
<li class="chapter" data-level="1.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="1.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#introduction"><i class="fa fa-check"></i><b>1.2</b> Introduction</a></li>
<li class="chapter" data-level="1.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#ordinary-least-squares-ols-assumptions"><i class="fa fa-check"></i><b>1.3</b> Ordinary Least Squares (OLS) Assumptions</a><ul>
<li class="chapter" data-level="1.3.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#cases-that-do-not-violate-the-ols-assumptions-for-inference"><i class="fa fa-check"></i><b>1.3.1</b> Cases that do not violate the OLS assumptions for inference</a></li>
<li class="chapter" data-level="1.3.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#cases-where-the-ols-assumptions-for-inference-are-violated"><i class="fa fa-check"></i><b>1.3.2</b> Cases where the OLS assumptions for inference are violated</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#cs:derby"><i class="fa fa-check"></i><b>1.4</b> Case Study: Kentucky Derby</a></li>
<li class="chapter" data-level="1.5" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#explore"><i class="fa fa-check"></i><b>1.5</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="1.5.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#data-organization"><i class="fa fa-check"></i><b>1.5.1</b> Data Organization</a></li>
<li class="chapter" data-level="1.5.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#univariate-summaries"><i class="fa fa-check"></i><b>1.5.2</b> Univariate Summaries</a></li>
<li class="chapter" data-level="1.5.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#bivariate-summaries"><i class="fa fa-check"></i><b>1.5.3</b> Bivariate Summaries</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multreg"><i class="fa fa-check"></i><b>1.6</b> Multiple linear regression modeling</a><ul>
<li class="chapter" data-level="1.6.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#SLRcontinuous"><i class="fa fa-check"></i><b>1.6.1</b> Simple linear regression with a continuous predictor</a></li>
<li class="chapter" data-level="1.6.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#simple-linear-regression-with-a-binary-predictor"><i class="fa fa-check"></i><b>1.6.2</b> Simple linear regression with a binary predictor</a></li>
<li class="chapter" data-level="1.6.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multiple-linear-regression-with-two-predictors"><i class="fa fa-check"></i><b>1.6.3</b> Multiple linear regression with two predictors</a></li>
<li class="chapter" data-level="1.6.4" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multreg-inference"><i class="fa fa-check"></i><b>1.6.4</b> Inference in multiple linear regression</a></li>
<li class="chapter" data-level="1.6.5" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multiple-linear-regression-with-an-interaction-term"><i class="fa fa-check"></i><b>1.6.5</b> Multiple linear regression with an interaction term</a></li>
<li class="chapter" data-level="1.6.6" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multreg_build"><i class="fa fa-check"></i><b>1.6.6</b> Building a multiple linear regression model</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#preview"><i class="fa fa-check"></i><b>1.7</b> Preview</a><ul>
<li class="chapter" data-level="1.7.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#soccer"><i class="fa fa-check"></i><b>1.7.1</b> Soccer</a></li>
<li class="chapter" data-level="1.7.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#elephant-mating"><i class="fa fa-check"></i><b>1.7.2</b> Elephant Mating</a></li>
<li class="chapter" data-level="1.7.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#parenting-and-gang-activity"><i class="fa fa-check"></i><b>1.7.3</b> Parenting and Gang Activity</a></li>
<li class="chapter" data-level="1.7.4" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#crime"><i class="fa fa-check"></i><b>1.7.4</b> Crime</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a><ul>
<li class="chapter" data-level="1.8.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#conceptual-exercises"><i class="fa fa-check"></i><b>1.8.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="1.8.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#guided-exercise"><i class="fa fa-check"></i><b>1.8.2</b> Guided Exercise</a></li>
<li class="chapter" data-level="1.8.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#open-ended-exercises"><i class="fa fa-check"></i><b>1.8.3</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html"><i class="fa fa-check"></i><b>2</b> Beyond Least Squares: Using Likelihoods to Fit and Compare Models</a><ul>
<li class="chapter" data-level="2.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#learning-objectives-1"><i class="fa fa-check"></i><b>2.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#case-study-does-sex-run-in-families"><i class="fa fa-check"></i><b>2.2</b> Case Study: Does sex run in families?</a><ul>
<li class="chapter" data-level="2.2.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#research-questions"><i class="fa fa-check"></i><b>2.2.1</b> Research Questions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-0-sex-unconditional-model-equal-probabilities-independence"><i class="fa fa-check"></i><b>2.3</b> Model 0: Sex Unconditional Model (Equal probabilities, Independence)</a></li>
<li class="chapter" data-level="2.4" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#sex_unconditional_model"><i class="fa fa-check"></i><b>2.4</b> Model 1: Sex Unconditional Model (Any Probability, Independence) and the Principle of Maximum Likelihood</a><ul>
<li class="chapter" data-level="2.4.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#what-is-a-likelihood"><i class="fa fa-check"></i><b>2.4.1</b> What is a likelihood?</a></li>
<li class="chapter" data-level="2.4.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#findMLE.sec"><i class="fa fa-check"></i><b>2.4.2</b> Finding MLEs</a></li>
<li class="chapter" data-level="2.4.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#summary"><i class="fa fa-check"></i><b>2.4.3</b> Summary</a></li>
<li class="chapter" data-level="2.4.4" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#is-a-likelihood-a-probability-function-optional"><i class="fa fa-check"></i><b>2.4.4</b> Is a likelihood a probability function? (Optional)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#sex_conditional.sec"><i class="fa fa-check"></i><b>2.5</b> Model 2: A Sex Conditional Model (Sex Bias) and Model Specification</a><ul>
<li class="chapter" data-level="2.5.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-specification"><i class="fa fa-check"></i><b>2.5.1</b> Model Specification</a></li>
<li class="chapter" data-level="2.5.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#application-to-hypothetical-data"><i class="fa fa-check"></i><b>2.5.2</b> Application to Hypothetical Data</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#case-study-analysis-of-the-nlsy-data"><i class="fa fa-check"></i><b>2.6</b> Case Study: Analysis of the NLSY data</a><ul>
<li class="chapter" data-level="2.6.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-building-plan"><i class="fa fa-check"></i><b>2.6.1</b> Model Building Plan</a></li>
<li class="chapter" data-level="2.6.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#EDA.sec"><i class="fa fa-check"></i><b>2.6.2</b> Family Composition of Boys and Girls, NLSY: Exploratory Data Analysis</a></li>
<li class="chapter" data-level="2.6.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#likelihood-for-the-sex-unconditional-model-the-nlsy-data"><i class="fa fa-check"></i><b>2.6.3</b> Likelihood for the Sex Unconditional Model: the NLSY data</a></li>
<li class="chapter" data-level="2.6.4" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#sex_cond_lik.sec"><i class="fa fa-check"></i><b>2.6.4</b> Likelihood for the Sex Conditional Model</a></li>
<li class="chapter" data-level="2.6.5" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#comparing-the-sex-unconditional-to-the-sex-conditional-model"><i class="fa fa-check"></i><b>2.6.5</b> Comparing the Sex Unconditional to the Sex Conditional Model</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-3-stopping-rule-model-waiting-for-a-boy"><i class="fa fa-check"></i><b>2.7</b> Model 3: Stopping Rule Model (Waiting for a boy)</a><ul>
<li class="chapter" data-level="2.7.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#non-nested-models"><i class="fa fa-check"></i><b>2.7.1</b> Non-nested Models</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#summary-of-model-building"><i class="fa fa-check"></i><b>2.8</b> Summary of Model Building</a></li>
<li class="chapter" data-level="2.9" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#likelihood-based-methods"><i class="fa fa-check"></i><b>2.9</b> Likelihood-based Methods</a></li>
<li class="chapter" data-level="2.10" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#likelihoods-and-this-course"><i class="fa fa-check"></i><b>2.10</b> Likelihoods and this Course</a></li>
<li class="chapter" data-level="2.11" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#exercises-1"><i class="fa fa-check"></i><b>2.11</b> Exercises</a><ul>
<li class="chapter" data-level="2.11.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#conceptual-exercises-1"><i class="fa fa-check"></i><b>2.11.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="2.11.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#guided-exercise-1"><i class="fa fa-check"></i><b>2.11.2</b> Guided Exercise</a></li>
<li class="chapter" data-level="2.11.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#open-ended-exercise"><i class="fa fa-check"></i><b>2.11.3</b> Open-ended Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch-distthry.html"><a href="ch-distthry.html"><i class="fa fa-check"></i><b>3</b> Distribution Theory</a><ul>
<li class="chapter" data-level="3.1" data-path="ch-distthry.html"><a href="ch-distthry.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a><ul>
<li class="chapter" data-level="3.1.1" data-path="ch-distthry.html"><a href="ch-distthry.html#characteristics-of-random-variables"><i class="fa fa-check"></i><b>3.1.1</b> Characteristics of Random Variables</a></li>
<li class="chapter" data-level="3.1.2" data-path="ch-distthry.html"><a href="ch-distthry.html#location-scale-and-shape-parameters"><i class="fa fa-check"></i><b>3.1.2</b> Location, scale and shape parameters</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="ch-distthry.html"><a href="ch-distthry.html#modeling-responses"><i class="fa fa-check"></i><b>3.2</b> Modeling Responses</a><ul>
<li class="chapter" data-level="3.2.1" data-path="ch-distthry.html"><a href="ch-distthry.html#discrete-random-variables"><i class="fa fa-check"></i><b>3.2.1</b> Discrete Random Variables</a></li>
<li class="chapter" data-level="3.2.2" data-path="ch-distthry.html"><a href="ch-distthry.html#bernoulli-process"><i class="fa fa-check"></i><b>3.2.2</b> Bernoulli Process</a></li>
<li class="chapter" data-level="3.2.3" data-path="ch-distthry.html"><a href="ch-distthry.html#poisson-process"><i class="fa fa-check"></i><b>3.2.3</b> Poisson Process</a></li>
<li class="chapter" data-level="3.2.4" data-path="ch-distthry.html"><a href="ch-distthry.html#continuous-random-variables"><i class="fa fa-check"></i><b>3.2.4</b> Continuous Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ch-distthry.html"><a href="ch-distthry.html#distributions-used-in-testing"><i class="fa fa-check"></i><b>3.3</b> Distributions used in Testing</a><ul>
<li class="chapter" data-level="3.3.1" data-path="ch-distthry.html"><a href="ch-distthry.html#chi2"><i class="fa fa-check"></i><b>3.3.1</b> <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="3.3.2" data-path="ch-distthry.html"><a href="ch-distthry.html#f"><i class="fa fa-check"></i><b>3.3.2</b> F</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ch-distthry.html"><a href="ch-distthry.html#mixtures"><i class="fa fa-check"></i><b>3.4</b> Mixtures</a><ul>
<li class="chapter" data-level="3.4.1" data-path="ch-distthry.html"><a href="ch-distthry.html#zero-inflated-poisson"><i class="fa fa-check"></i><b>3.4.1</b> Zero-inflated Poisson</a></li>
<li class="chapter" data-level="3.4.2" data-path="ch-distthry.html"><a href="ch-distthry.html#mixture-of-two-normal-distributions"><i class="fa fa-check"></i><b>3.4.2</b> Mixture of Two Normal Distributions</a></li>
<li class="chapter" data-level="3.4.3" data-path="ch-distthry.html"><a href="ch-distthry.html#beta-binomial"><i class="fa fa-check"></i><b>3.4.3</b> Beta-Binomial</a></li>
<li class="chapter" data-level="3.4.4" data-path="ch-distthry.html"><a href="ch-distthry.html#negative-binomial-1"><i class="fa fa-check"></i><b>3.4.4</b> Negative Binomial</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ch-distthry.html"><a href="ch-distthry.html#exercises-2"><i class="fa fa-check"></i><b>3.5</b> Exercises</a><ul>
<li class="chapter" data-level="3.5.1" data-path="ch-distthry.html"><a href="ch-distthry.html#conceptual-exercises-2"><i class="fa fa-check"></i><b>3.5.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="3.5.2" data-path="ch-distthry.html"><a href="ch-distthry.html#guided-exercises"><i class="fa fa-check"></i><b>3.5.2</b> Guided Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html"><i class="fa fa-check"></i><b>4</b> Poisson Regression</a><ul>
<li class="chapter" data-level="4.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#learning-objectives-2"><i class="fa fa-check"></i><b>4.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#preface-1"><i class="fa fa-check"></i><b>4.2</b> Preface</a></li>
<li class="chapter" data-level="4.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#poisintrosec"><i class="fa fa-check"></i><b>4.3</b> Introduction to Poisson Regression</a><ul>
<li class="chapter" data-level="4.3.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#initial-examples"><i class="fa fa-check"></i><b>4.3.1</b> Initial Examples</a></li>
<li class="chapter" data-level="4.3.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-Prop"><i class="fa fa-check"></i><b>4.3.2</b> Poisson Random Variables</a></li>
<li class="chapter" data-level="4.3.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#modeling-with-poisson-variables"><i class="fa fa-check"></i><b>4.3.3</b> Modeling with Poisson variables</a></li>
<li class="chapter" data-level="4.3.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#a-graphical-look-at-poisson-regression"><i class="fa fa-check"></i><b>4.3.4</b> A Graphical Look at Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#case-studies-overview"><i class="fa fa-check"></i><b>4.4</b> Case Studies Overview</a></li>
<li class="chapter" data-level="4.5" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#case-study-household-size-in-haiti"><i class="fa fa-check"></i><b>4.5</b> Case Study: Household Size in Haiti</a><ul>
<li class="chapter" data-level="4.5.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#research-question"><i class="fa fa-check"></i><b>4.5.1</b> Research Question</a></li>
<li class="chapter" data-level="4.5.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#data-collection"><i class="fa fa-check"></i><b>4.5.2</b> Data Collection</a></li>
<li class="chapter" data-level="4.5.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#data-organization-1"><i class="fa fa-check"></i><b>4.5.3</b> Data Organization</a></li>
<li class="chapter" data-level="4.5.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>4.5.4</b> Exploratory Data Analysis</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#likelihood.sec"><i class="fa fa-check"></i><b>4.6</b> Using Likelihoods to fit Poisson Regression Models (Optional)</a></li>
<li class="chapter" data-level="4.7" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#modeling"><i class="fa fa-check"></i><b>4.7</b> Modeling</a><ul>
<li class="chapter" data-level="4.7.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#first-order-model"><i class="fa fa-check"></i><b>4.7.1</b> First Order Model</a></li>
<li class="chapter" data-level="4.7.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-PoisInference"><i class="fa fa-check"></i><b>4.7.2</b> Estimation and Inference</a></li>
<li class="chapter" data-level="4.7.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#using-deviances-to-compare-models"><i class="fa fa-check"></i><b>4.7.3</b> Using Deviances to Compare Models</a></li>
<li class="chapter" data-level="4.7.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#poisson-regression-assumptions-1"><i class="fa fa-check"></i><b>4.7.4</b> Poisson Regression Assumptions</a></li>
<li class="chapter" data-level="4.7.5" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#residual-plot"><i class="fa fa-check"></i><b>4.7.5</b> Residual Plot</a></li>
<li class="chapter" data-level="4.7.6" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#residuals-for-poisson-models-optional"><i class="fa fa-check"></i><b>4.7.6</b> Residuals for Poisson Models (Optional)</a></li>
<li class="chapter" data-level="4.7.7" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#second-order-model"><i class="fa fa-check"></i><b>4.7.7</b> Second Order Model</a></li>
<li class="chapter" data-level="4.7.8" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#finding-the-age-where-the-number-in-the-house-is-a-maximum"><i class="fa fa-check"></i><b>4.7.8</b> Finding the age where the number in the house is a maximum</a></li>
<li class="chapter" data-level="4.7.9" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#adding-a-covariate"><i class="fa fa-check"></i><b>4.7.9</b> Adding a covariate</a></li>
<li class="chapter" data-level="4.7.10" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-PoisGOF"><i class="fa fa-check"></i><b>4.7.10</b> Goodness-of-fit</a></li>
<li class="chapter" data-level="4.7.11" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#least-squares-regression-vs.poisson-regression"><i class="fa fa-check"></i><b>4.7.11</b> Least Squares Regression vs. Poisson Regression</a></li>
<li class="chapter" data-level="4.7.12" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#optional-topics-to-be-developed"><i class="fa fa-check"></i><b>4.7.12</b> Optional topics to be developed</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#case-study-campus-crime"><i class="fa fa-check"></i><b>4.8</b> Case Study: Campus Crime</a></li>
<li class="chapter" data-level="4.9" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#analysis-for-crime-data"><i class="fa fa-check"></i><b>4.9</b> Analysis for crime data</a><ul>
<li class="chapter" data-level="4.9.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#research-question-1"><i class="fa fa-check"></i><b>4.9.1</b> Research Question</a></li>
<li class="chapter" data-level="4.9.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#data-organization-2"><i class="fa fa-check"></i><b>4.9.2</b> Data Organization</a></li>
<li class="chapter" data-level="4.9.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exploratory-data-analysis-1"><i class="fa fa-check"></i><b>4.9.3</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="4.9.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#accounting-for-enrollment"><i class="fa fa-check"></i><b>4.9.4</b> Accounting for Enrollment</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#checking-assumptions"><i class="fa fa-check"></i><b>4.10</b> Checking Assumptions</a><ul>
<li class="chapter" data-level="4.10.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#is-the-mean-equal-to-the-variance"><i class="fa fa-check"></i><b>4.10.1</b> Is the Mean equal to the Variance?</a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#modeling-1"><i class="fa fa-check"></i><b>4.11</b> Modeling</a></li>
<li class="chapter" data-level="4.12" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-overdispPois"><i class="fa fa-check"></i><b>4.12</b> Overdispersion</a><ul>
<li class="chapter" data-level="4.12.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#dispersion-parameter-adjustment"><i class="fa fa-check"></i><b>4.12.1</b> Dispersion parameter adjustment</a></li>
<li class="chapter" data-level="4.12.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#negative-binomial-modeling"><i class="fa fa-check"></i><b>4.12.2</b> Negative binomial modeling</a></li>
</ul></li>
<li class="chapter" data-level="4.13" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#case-study-weekend-drinking-csdrinking"><i class="fa fa-check"></i><b>4.13</b> Case Study: Weekend drinking {cs:drinking}</a><ul>
<li class="chapter" data-level="4.13.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#research-question-2"><i class="fa fa-check"></i><b>4.13.1</b> Research Question</a></li>
<li class="chapter" data-level="4.13.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#data-organization-3"><i class="fa fa-check"></i><b>4.13.2</b> Data Organization</a></li>
<li class="chapter" data-level="4.13.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exploratory-data-analysis-2"><i class="fa fa-check"></i><b>4.13.3</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="4.13.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#modeling-2"><i class="fa fa-check"></i><b>4.13.4</b> Modeling</a></li>
<li class="chapter" data-level="4.13.5" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#fitting-a-zip-model"><i class="fa fa-check"></i><b>4.13.5</b> Fitting a ZIP Model</a></li>
<li class="chapter" data-level="4.13.6" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#comparing-the-ordinary-poisson-regression-model-to-the-zip-model"><i class="fa fa-check"></i><b>4.13.6</b> Comparing the ordinary Poisson regression model to the ZIP model</a></li>
<li class="chapter" data-level="4.13.7" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#residual-plot-1"><i class="fa fa-check"></i><b>4.13.7</b> Residual Plot</a></li>
<li class="chapter" data-level="4.13.8" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#caveats-and-extensions"><i class="fa fa-check"></i><b>4.13.8</b> Caveats and Extensions</a></li>
</ul></li>
<li class="chapter" data-level="4.14" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#references"><i class="fa fa-check"></i><b>4.14</b> References</a></li>
<li class="chapter" data-level="4.15" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exercises-3"><i class="fa fa-check"></i><b>4.15</b> Exercises</a><ul>
<li class="chapter" data-level="4.15.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exer:concept"><i class="fa fa-check"></i><b>4.15.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="4.15.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#guided-exercise-2"><i class="fa fa-check"></i><b>4.15.2</b> Guided Exercise</a></li>
<li class="chapter" data-level="4.15.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#open-ended"><i class="fa fa-check"></i><b>4.15.3</b> Open-ended</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-glms.html"><a href="ch-glms.html"><i class="fa fa-check"></i><b>5</b> Generalized Linear Models (GLMs): A Unifying Theory</a><ul>
<li class="chapter" data-level="5.1" data-path="ch-glms.html"><a href="ch-glms.html#learning-objectives-3"><i class="fa fa-check"></i><b>5.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="ch-glms.html"><a href="ch-glms.html#one-parameter-exponential-families"><i class="fa fa-check"></i><b>5.2</b> One parameter exponential families</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ch-glms.html"><a href="ch-glms.html#one-parameter-exponential-family-possion"><i class="fa fa-check"></i><b>5.2.1</b> One Parameter Exponential Family: Possion</a></li>
<li class="chapter" data-level="5.2.2" data-path="ch-glms.html"><a href="ch-glms.html#one-parameter-exponential-family-normal"><i class="fa fa-check"></i><b>5.2.2</b> One parameter exponential family: Normal</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ch-glms.html"><a href="ch-glms.html#generalized-linear-modeling"><i class="fa fa-check"></i><b>5.3</b> Generalized Linear Modeling</a></li>
<li class="chapter" data-level="5.4" data-path="ch-glms.html"><a href="ch-glms.html#exercises-4"><i class="fa fa-check"></i><b>5.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch-logreg.html"><a href="ch-logreg.html"><i class="fa fa-check"></i><b>6</b> Logistic Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="ch-logreg.html"><a href="ch-logreg.html#learning-objectives-4"><i class="fa fa-check"></i><b>6.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="ch-logreg.html"><a href="ch-logreg.html#introduction-2"><i class="fa fa-check"></i><b>6.2</b> Introduction</a><ul>
<li class="chapter" data-level="6.2.1" data-path="ch-logreg.html"><a href="ch-logreg.html#binary-responses"><i class="fa fa-check"></i><b>6.2.1</b> Binary Responses</a></li>
<li class="chapter" data-level="6.2.2" data-path="ch-logreg.html"><a href="ch-logreg.html#binomial-responses-sums-of-binary-responses"><i class="fa fa-check"></i><b>6.2.2</b> Binomial Responses: sums of binary responses</a></li>
<li class="chapter" data-level="6.2.3" data-path="ch-logreg.html"><a href="ch-logreg.html#an-example-binge-drinking"><i class="fa fa-check"></i><b>6.2.3</b> An Example: Binge Drinking</a></li>
<li class="chapter" data-level="6.2.4" data-path="ch-logreg.html"><a href="ch-logreg.html#a-graphical-look-at-binomial-regression"><i class="fa fa-check"></i><b>6.2.4</b> A Graphical Look at Binomial Regression</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ch-logreg.html"><a href="ch-logreg.html#sec-modelframework"><i class="fa fa-check"></i><b>6.3</b> A Modeling Framework</a></li>
<li class="chapter" data-level="6.4" data-path="ch-logreg.html"><a href="ch-logreg.html#case-studies-overview-1"><i class="fa fa-check"></i><b>6.4</b> Case Studies Overview</a></li>
<li class="chapter" data-level="6.5" data-path="ch-logreg.html"><a href="ch-logreg.html#glm-theory-for-binomial-outcomes"><i class="fa fa-check"></i><b>6.5</b> GLM Theory for Binomial Outcomes</a><ul>
<li class="chapter" data-level="6.5.1" data-path="ch-logreg.html"><a href="ch-logreg.html#case-study-soccer-goalkeeper-saves"><i class="fa fa-check"></i><b>6.5.1</b> Case Study: Soccer Goalkeeper Saves</a></li>
<li class="chapter" data-level="6.5.2" data-path="ch-logreg.html"><a href="ch-logreg.html#research-question-3"><i class="fa fa-check"></i><b>6.5.2</b> Research Question</a></li>
<li class="chapter" data-level="6.5.3" data-path="ch-logreg.html"><a href="ch-logreg.html#data-organization-4"><i class="fa fa-check"></i><b>6.5.3</b> Data Organization</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="ch-logreg.html"><a href="ch-logreg.html#case-study-reconstructing-alabama"><i class="fa fa-check"></i><b>6.6</b> Case Study: Reconstructing Alabama</a><ul>
<li class="chapter" data-level="6.6.1" data-path="ch-logreg.html"><a href="ch-logreg.html#research-question-4"><i class="fa fa-check"></i><b>6.6.1</b> Research Question</a></li>
<li class="chapter" data-level="6.6.2" data-path="ch-logreg.html"><a href="ch-logreg.html#data-organization-5"><i class="fa fa-check"></i><b>6.6.2</b> Data Organization</a></li>
<li class="chapter" data-level="6.6.3" data-path="ch-logreg.html"><a href="ch-logreg.html#exploratory-data-analysis-3"><i class="fa fa-check"></i><b>6.6.3</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="6.6.4" data-path="ch-logreg.html"><a href="ch-logreg.html#modeling-overview"><i class="fa fa-check"></i><b>6.6.4</b> Modeling Overview</a></li>
<li class="chapter" data-level="6.6.5" data-path="ch-logreg.html"><a href="ch-logreg.html#results"><i class="fa fa-check"></i><b>6.6.5</b> Results</a></li>
<li class="chapter" data-level="6.6.6" data-path="ch-logreg.html"><a href="ch-logreg.html#least-squares-regression-vs.logistic-regression"><i class="fa fa-check"></i><b>6.6.6</b> Least Squares Regression vs. Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="ch-logreg.html"><a href="ch-logreg.html#case-study-who-wants-to-lose-weight-sex-media-sports-and-bmi."><i class="fa fa-check"></i><b>6.7</b> Case Study: Who wants to lose weight? Sex, Media, Sports, and BMI.</a><ul>
<li class="chapter" data-level="6.7.1" data-path="ch-logreg.html"><a href="ch-logreg.html#background"><i class="fa fa-check"></i><b>6.7.1</b> Background</a></li>
<li class="chapter" data-level="6.7.2" data-path="ch-logreg.html"><a href="ch-logreg.html#research-questions-1"><i class="fa fa-check"></i><b>6.7.2</b> Research Questions</a></li>
<li class="chapter" data-level="6.7.3" data-path="ch-logreg.html"><a href="ch-logreg.html#data-collection-1"><i class="fa fa-check"></i><b>6.7.3</b> Data Collection</a></li>
<li class="chapter" data-level="6.7.4" data-path="ch-logreg.html"><a href="ch-logreg.html#data-organization-6"><i class="fa fa-check"></i><b>6.7.4</b> Data Organization</a></li>
<li class="chapter" data-level="6.7.5" data-path="ch-logreg.html"><a href="ch-logreg.html#exploratory-data-analysis-4"><i class="fa fa-check"></i><b>6.7.5</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="6.7.6" data-path="ch-logreg.html"><a href="ch-logreg.html#modeling-3"><i class="fa fa-check"></i><b>6.7.6</b> Modeling</a></li>
<li class="chapter" data-level="6.7.7" data-path="ch-logreg.html"><a href="ch-logreg.html#discussion"><i class="fa fa-check"></i><b>6.7.7</b> Discussion</a></li>
<li class="chapter" data-level="6.7.8" data-path="ch-logreg.html"><a href="ch-logreg.html#optional-topics-to-be-developed-1"><i class="fa fa-check"></i><b>6.7.8</b> Optional topics to be developed</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="ch-logreg.html"><a href="ch-logreg.html#references-1"><i class="fa fa-check"></i><b>6.8</b> References</a></li>
<li class="chapter" data-level="6.9" data-path="ch-logreg.html"><a href="ch-logreg.html#exercises-5"><i class="fa fa-check"></i><b>6.9</b> Exercises</a><ul>
<li class="chapter" data-level="6.9.1" data-path="ch-logreg.html"><a href="ch-logreg.html#interpret-article-abstracts"><i class="fa fa-check"></i><b>6.9.1</b> Interpret article abstracts</a></li>
<li class="chapter" data-level="6.9.2" data-path="ch-logreg.html"><a href="ch-logreg.html#guided-exercises-1"><i class="fa fa-check"></i><b>6.9.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="6.9.3" data-path="ch-logreg.html"><a href="ch-logreg.html#open-ended-exercises-1"><i class="fa fa-check"></i><b>6.9.3</b> Open-ended Exercises</a></li>
<li class="chapter" data-level="6.9.4" data-path="ch-logreg.html"><a href="ch-logreg.html#project-ideas"><i class="fa fa-check"></i><b>6.9.4</b> Project Ideas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch-corrdata.html"><a href="ch-corrdata.html"><i class="fa fa-check"></i><b>7</b> Correlated Data</a><ul>
<li class="chapter" data-level="7.1" data-path="ch-corrdata.html"><a href="ch-corrdata.html#learning-objectives-5"><i class="fa fa-check"></i><b>7.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="7.2" data-path="ch-corrdata.html"><a href="ch-corrdata.html#recognizing-correlation"><i class="fa fa-check"></i><b>7.2</b> Recognizing correlation</a></li>
<li class="chapter" data-level="7.3" data-path="ch-corrdata.html"><a href="ch-corrdata.html#case-study-dams-and-pups-correlated-binary-outcomes"><i class="fa fa-check"></i><b>7.3</b> Case Study: Dams and pups, Correlated Binary Outcomes</a><ul>
<li class="chapter" data-level="7.3.1" data-path="ch-corrdata.html"><a href="ch-corrdata.html#sources-of-variability"><i class="fa fa-check"></i><b>7.3.1</b> Sources of Variability</a></li>
<li class="chapter" data-level="7.3.2" data-path="ch-corrdata.html"><a href="ch-corrdata.html#analyzing-a-control-group"><i class="fa fa-check"></i><b>7.3.2</b> Analyzing a control group</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ch-corrdata.html"><a href="ch-corrdata.html#under-construction"><i class="fa fa-check"></i><b>7.4</b> Under Construction…</a><ul>
<li class="chapter" data-level="7.4.1" data-path="ch-corrdata.html"><a href="ch-corrdata.html#correlated-data-simulation"><i class="fa fa-check"></i><b>7.4.1</b> Correlated Data Simulation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html"><i class="fa fa-check"></i><b>8</b> Introduction to Multilevel Models</a><ul>
<li class="chapter" data-level="8.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#learning-objectives-6"><i class="fa fa-check"></i><b>8.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="8.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#cs:music"><i class="fa fa-check"></i><b>8.2</b> Case Study: Music Performance Anxiety</a></li>
<li class="chapter" data-level="8.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#explore"><i class="fa fa-check"></i><b>8.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="8.3.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#organizedata1"><i class="fa fa-check"></i><b>8.3.1</b> Data Organization</a></li>
<li class="chapter" data-level="8.3.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#explore1"><i class="fa fa-check"></i><b>8.3.2</b> Exploratory Analyses: Univariate Summaries</a></li>
<li class="chapter" data-level="8.3.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#explore2"><i class="fa fa-check"></i><b>8.3.3</b> Exploratory Analyses: Bivariate Summaries</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#twolevelmodeling"><i class="fa fa-check"></i><b>8.4</b> Two level modeling: preliminary considerations</a><ul>
<li class="chapter" data-level="8.4.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#multregr"><i class="fa fa-check"></i><b>8.4.1</b> Ignoring the two level structure (not recommended)</a></li>
<li class="chapter" data-level="8.4.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#twostage"><i class="fa fa-check"></i><b>8.4.2</b> A two-stage modeling approach (better but imperfect)</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#twolevelmodelingunified"><i class="fa fa-check"></i><b>8.5</b> Two level modeling: a unified approach</a><ul>
<li class="chapter" data-level="8.5.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#ourframework"><i class="fa fa-check"></i><b>8.5.1</b> Our framework</a></li>
<li class="chapter" data-level="8.5.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#random-vs.fixed-effects"><i class="fa fa-check"></i><b>8.5.2</b> Random vs. fixed effects</a></li>
<li class="chapter" data-level="8.5.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#MVN"><i class="fa fa-check"></i><b>8.5.3</b> Distribution of errors: the multivariate normal distribution</a></li>
<li class="chapter" data-level="8.5.4" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#multileveltechnical"><i class="fa fa-check"></i><b>8.5.4</b> Technical issues when estimating and testing parameters (Optional)</a></li>
<li class="chapter" data-level="8.5.5" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#initialmodel"><i class="fa fa-check"></i><b>8.5.5</b> An initial model with parameter interpretations</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#sec:buildmodel"><i class="fa fa-check"></i><b>8.6</b> Building a multilevel model</a><ul>
<li class="chapter" data-level="8.6.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#buildstrategy"><i class="fa fa-check"></i><b>8.6.1</b> Model building strategy</a></li>
<li class="chapter" data-level="8.6.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modela"><i class="fa fa-check"></i><b>8.6.2</b> An initial model: unconditional means or random intercepts</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modelb"><i class="fa fa-check"></i><b>8.7</b> Binary covariates at Level One and Level Two</a><ul>
<li class="chapter" data-level="8.7.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#randomslopeandint"><i class="fa fa-check"></i><b>8.7.1</b> Random slopes and intercepts model</a></li>
<li class="chapter" data-level="8.7.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#pseudoR2"><i class="fa fa-check"></i><b>8.7.2</b> Pseudo <span class="math inline">\(R^2\)</span> values</a></li>
<li class="chapter" data-level="8.7.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modelc"><i class="fa fa-check"></i><b>8.7.3</b> Adding a covariate at Level Two</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#sec:modeld"><i class="fa fa-check"></i><b>8.8</b> Additional covariates: model comparison and interpretability</a><ul>
<li class="chapter" data-level="8.8.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#interp:modeld"><i class="fa fa-check"></i><b>8.8.1</b> Interpretation of parameter estimates</a></li>
<li class="chapter" data-level="8.8.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#compare:modeld"><i class="fa fa-check"></i><b>8.8.2</b> Model comparisons</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#sec:modele"><i class="fa fa-check"></i><b>8.9</b> Center covariates</a></li>
<li class="chapter" data-level="8.10" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modelf"><i class="fa fa-check"></i><b>8.10</b> A potential final model for music performance anxiety</a></li>
<li class="chapter" data-level="8.11" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#multinecessary"><i class="fa fa-check"></i><b>8.11</b> Modeling the multilevel structure: is it really necessary?</a></li>
<li class="chapter" data-level="8.12" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#notesr8"><i class="fa fa-check"></i><b>8.12</b> Notes on Using R (Optional)</a></li>
<li class="chapter" data-level="8.13" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#exercises-6"><i class="fa fa-check"></i><b>8.13</b> Exercises</a><ul>
<li class="chapter" data-level="8.13.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#conceptual-exercises-3"><i class="fa fa-check"></i><b>8.13.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="8.13.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#guided-exercise-3"><i class="fa fa-check"></i><b>8.13.2</b> Guided Exercise</a></li>
<li class="chapter" data-level="8.13.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#open-ended-exercises-2"><i class="fa fa-check"></i><b>8.13.3</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-lon.html"><a href="ch-lon.html"><i class="fa fa-check"></i><b>9</b> Two Level Longitudinal Data</a><ul>
<li class="chapter" data-level="9.1" data-path="ch-lon.html"><a href="ch-lon.html#learning-objectives-7"><i class="fa fa-check"></i><b>9.1</b> Learning objectives</a></li>
<li class="chapter" data-level="9.2" data-path="ch-lon.html"><a href="ch-lon.html#cs:charter"><i class="fa fa-check"></i><b>9.2</b> Case study: Charter schools</a></li>
<li class="chapter" data-level="9.3" data-path="ch-lon.html"><a href="ch-lon.html#exploratoryanalysis"><i class="fa fa-check"></i><b>9.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="9.3.1" data-path="ch-lon.html"><a href="ch-lon.html#data"><i class="fa fa-check"></i><b>9.3.1</b> Data organization</a></li>
<li class="chapter" data-level="9.3.2" data-path="ch-lon.html"><a href="ch-lon.html#missing"><i class="fa fa-check"></i><b>9.3.2</b> Missing data</a></li>
<li class="chapter" data-level="9.3.3" data-path="ch-lon.html"><a href="ch-lon.html#generalanalyses"><i class="fa fa-check"></i><b>9.3.3</b> Exploratory analyses for general multilevel models</a></li>
<li class="chapter" data-level="9.3.4" data-path="ch-lon.html"><a href="ch-lon.html#longitudinalanalyses"><i class="fa fa-check"></i><b>9.3.4</b> Exploratory analyses for longitudinal data</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="ch-lon.html"><a href="ch-lon.html#twostage9"><i class="fa fa-check"></i><b>9.4</b> Preliminary two-stage modeling</a><ul>
<li class="chapter" data-level="9.4.1" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostage"><i class="fa fa-check"></i><b>9.4.1</b> Linear trends within schools</a></li>
<li class="chapter" data-level="9.4.2" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostageL2effects"><i class="fa fa-check"></i><b>9.4.2</b> Effects of level two covariates on linear time trends</a></li>
<li class="chapter" data-level="9.4.3" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostageerror"><i class="fa fa-check"></i><b>9.4.3</b> Error structure within schools</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostageerror"><i class="fa fa-check"></i><b>9.5</b> Initial models</a><ul>
<li class="chapter" data-level="9.5.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modela"><i class="fa fa-check"></i><b>9.5.1</b> Unconditional means model</a></li>
<li class="chapter" data-level="9.5.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modelb"><i class="fa fa-check"></i><b>9.5.2</b> Unconditional growth model</a></li>
<li class="chapter" data-level="9.5.3" data-path="ch-lon.html"><a href="ch-lon.html#othertimetrends"><i class="fa fa-check"></i><b>9.5.3</b> Modeling other trends over time</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="ch-lon.html"><a href="ch-lon.html#finalmodel"><i class="fa fa-check"></i><b>9.6</b> Building to a final model</a><ul>
<li class="chapter" data-level="9.6.1" data-path="ch-lon.html"><a href="ch-lon.html#modelc9"><i class="fa fa-check"></i><b>9.6.1</b> Uncontrolled effects of school type</a></li>
<li class="chapter" data-level="9.6.2" data-path="ch-lon.html"><a href="ch-lon.html#modeld"><i class="fa fa-check"></i><b>9.6.2</b> Add percent free and reduced lunch as a covariate</a></li>
<li class="chapter" data-level="9.6.3" data-path="ch-lon.html"><a href="ch-lon.html#modelf9"><i class="fa fa-check"></i><b>9.6.3</b> A potential final model with three Level Two covariates</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="ch-lon.html"><a href="ch-lon.html#errorcovariance"><i class="fa fa-check"></i><b>9.7</b> Covariance structure among observations</a><ul>
<li class="chapter" data-level="9.7.1" data-path="ch-lon.html"><a href="ch-lon.html#standarderror"><i class="fa fa-check"></i><b>9.7.1</b> Standard covariance structure</a></li>
<li class="chapter" data-level="9.7.2" data-path="ch-lon.html"><a href="ch-lon.html#alternateerror"><i class="fa fa-check"></i><b>9.7.2</b> Alternative covariance structures</a></li>
<li class="chapter" data-level="9.7.3" data-path="ch-lon.html"><a href="ch-lon.html#covariance-structure-in-non-longitudinal-multilevel-models"><i class="fa fa-check"></i><b>9.7.3</b> Covariance structure in non-longitudinal multilevel models</a></li>
<li class="chapter" data-level="9.7.4" data-path="ch-lon.html"><a href="ch-lon.html#final-thoughts-regarding-covariance-structures"><i class="fa fa-check"></i><b>9.7.4</b> Final thoughts regarding covariance structures</a></li>
<li class="chapter" data-level="9.7.5" data-path="ch-lon.html"><a href="ch-lon.html#optionalcov"><i class="fa fa-check"></i><b>9.7.5</b> Details of covariance structures (Optional)</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="ch-lon.html"><a href="ch-lon.html#notesr9"><i class="fa fa-check"></i><b>9.8</b> Notes on Using R (Optional)</a></li>
<li class="chapter" data-level="9.9" data-path="ch-lon.html"><a href="ch-lon.html#exercises-7"><i class="fa fa-check"></i><b>9.9</b> Exercises</a><ul>
<li class="chapter" data-level="9.9.1" data-path="ch-lon.html"><a href="ch-lon.html#conceptual-exercises-4"><i class="fa fa-check"></i><b>9.9.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="9.9.2" data-path="ch-lon.html"><a href="ch-lon.html#guided-exercise-4"><i class="fa fa-check"></i><b>9.9.2</b> Guided Exercise</a></li>
<li class="chapter" data-level="9.9.3" data-path="ch-lon.html"><a href="ch-lon.html#open-ended-exercises-3"><i class="fa fa-check"></i><b>9.9.3</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch-3level.html"><a href="ch-3level.html"><i class="fa fa-check"></i><b>10</b> Multilevel Data With More Than Two Levels</a><ul>
<li class="chapter" data-level="10.1" data-path="ch-3level.html"><a href="ch-3level.html#learning-objectives-8"><i class="fa fa-check"></i><b>10.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="10.2" data-path="ch-3level.html"><a href="ch-3level.html#cs:seeds"><i class="fa fa-check"></i><b>10.2</b> Case Studies: Seed Germination</a></li>
<li class="chapter" data-level="10.3" data-path="ch-3level.html"><a href="ch-3level.html#explore3"><i class="fa fa-check"></i><b>10.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="10.3.1" data-path="ch-3level.html"><a href="ch-3level.html#organizedata3"><i class="fa fa-check"></i><b>10.3.1</b> Data Organization</a></li>
<li class="chapter" data-level="10.3.2" data-path="ch-3level.html"><a href="ch-3level.html#explore3v2"><i class="fa fa-check"></i><b>10.3.2</b> Exploratory Analyses</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="ch-3level.html"><a href="ch-3level.html#initialmodels-3level"><i class="fa fa-check"></i><b>10.4</b> Initial models: unconditional means and unconditional growth</a></li>
<li class="chapter" data-level="10.5" data-path="ch-3level.html"><a href="ch-3level.html#sec:boundary"><i class="fa fa-check"></i><b>10.5</b> Encountering boundary constraints</a></li>
<li class="chapter" data-level="10.6" data-path="ch-3level.html"><a href="ch-3level.html#threelevel-paraboot"><i class="fa fa-check"></i><b>10.6</b> Parametric bootstrap testing</a></li>
<li class="chapter" data-level="10.7" data-path="ch-3level.html"><a href="ch-3level.html#sec:explodingvarcomps"><i class="fa fa-check"></i><b>10.7</b> Exploding variance components</a></li>
<li class="chapter" data-level="10.8" data-path="ch-3level.html"><a href="ch-3level.html#modelsDEF"><i class="fa fa-check"></i><b>10.8</b> Building to a final model</a></li>
<li class="chapter" data-level="10.9" data-path="ch-3level.html"><a href="ch-3level.html#error-3level"><i class="fa fa-check"></i><b>10.9</b> Covariance structure (Optional)</a><ul>
<li class="chapter" data-level="10.9.1" data-path="ch-3level.html"><a href="ch-3level.html#optionalerror"><i class="fa fa-check"></i><b>10.9.1</b> Details of covariance structures</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="ch-3level.html"><a href="ch-3level.html#usingR3"><i class="fa fa-check"></i><b>10.10</b> Notes on Using R (Optional)</a></li>
<li class="chapter" data-level="10.11" data-path="ch-3level.html"><a href="ch-3level.html#exercises-8"><i class="fa fa-check"></i><b>10.11</b> Exercises</a><ul>
<li class="chapter" data-level="10.11.1" data-path="ch-3level.html"><a href="ch-3level.html#conceptual-exercises-5"><i class="fa fa-check"></i><b>10.11.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="10.11.2" data-path="ch-3level.html"><a href="ch-3level.html#guided-exercise-5"><i class="fa fa-check"></i><b>10.11.2</b> Guided Exercise</a></li>
<li class="chapter" data-level="10.11.3" data-path="ch-3level.html"><a href="ch-3level.html#open-ended-exercises-4"><i class="fa fa-check"></i><b>10.11.3</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-GLMM.html"><a href="ch-GLMM.html"><i class="fa fa-check"></i><b>11</b> Generalized Linear Multilevel Models</a><ul>
<li class="chapter" data-level="11.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#objectives"><i class="fa fa-check"></i><b>11.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="11.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#cs:refs"><i class="fa fa-check"></i><b>11.2</b> Case Study: College Basketball Referees</a></li>
<li class="chapter" data-level="11.3" data-path="ch-GLMM.html"><a href="ch-GLMM.html#explore-glmm"><i class="fa fa-check"></i><b>11.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="11.3.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#data-organization-7"><i class="fa fa-check"></i><b>11.3.1</b> Data organization</a></li>
<li class="chapter" data-level="11.3.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#glmm-eda"><i class="fa fa-check"></i><b>11.3.2</b> Exploratory analyses</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ch-GLMM.html"><a href="ch-GLMM.html#twolevelmodeling-glmm"><i class="fa fa-check"></i><b>11.4</b> Two level Modeling with a Generalized Response</a><ul>
<li class="chapter" data-level="11.4.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#multregr-glmm"><i class="fa fa-check"></i><b>11.4.1</b> A multiple generalized linear model approach (correlation not accounted for)</a></li>
<li class="chapter" data-level="11.4.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#twostage-glmm"><i class="fa fa-check"></i><b>11.4.2</b> A two-stage modeling approach (provides the basic idea for multilevel modeling)</a></li>
<li class="chapter" data-level="11.4.3" data-path="ch-GLMM.html"><a href="ch-GLMM.html#unified-glmm"><i class="fa fa-check"></i><b>11.4.3</b> A unified multilevel approach (the framework we’ll use)</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="ch-GLMM.html"><a href="ch-GLMM.html#crossedre"><i class="fa fa-check"></i><b>11.5</b> Crossed Random Effects</a></li>
<li class="chapter" data-level="11.6" data-path="ch-GLMM.html"><a href="ch-GLMM.html#glmm-paraboot"><i class="fa fa-check"></i><b>11.6</b> Model Comparisons Using the Parametric Bootstrap</a></li>
<li class="chapter" data-level="11.7" data-path="ch-GLMM.html"><a href="ch-GLMM.html#sec:finalmodel-glmm"><i class="fa fa-check"></i><b>11.7</b> A Potential Final Model for Examining Referee Bias</a></li>
<li class="chapter" data-level="11.8" data-path="ch-GLMM.html"><a href="ch-GLMM.html#estimatedRE"><i class="fa fa-check"></i><b>11.8</b> Estimated Random Effects</a></li>
<li class="chapter" data-level="11.9" data-path="ch-GLMM.html"><a href="ch-GLMM.html#usingR-glmm"><i class="fa fa-check"></i><b>11.9</b> Notes on Using R (Optional)</a></li>
<li class="chapter" data-level="11.10" data-path="ch-GLMM.html"><a href="ch-GLMM.html#exercises-9"><i class="fa fa-check"></i><b>11.10</b> Exercises</a></li>
<li class="chapter" data-level="11.11" data-path="ch-GLMM.html"><a href="ch-GLMM.html#conceptual-exercises-6"><i class="fa fa-check"></i><b>11.11</b> Conceptual Exercises</a><ul>
<li class="chapter" data-level="11.11.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#guided-exercise-6"><i class="fa fa-check"></i><b>11.11.1</b> Guided Exercise</a></li>
<li class="chapter" data-level="11.11.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#open-ended-exercises-5"><i class="fa fa-check"></i><b>11.11.2</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Broadening Your Statistical Horizons</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-poissonreg" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Poisson Regression</h1>
<div id="learning-objectives-2" class="section level2">
<h2><span class="header-section-number">4.1</span> Learning Objectives</h2>
<p>After finishing this chapter, you should be able to:</p>
<ul>
<li>Describe a Poisson process and a corresponding Poisson random variable.</li>
<li>Describe why simple linear regression is not ideal for Poisson data.</li>
<li>Write out a Poisson regression model and identify the assumptions for inference.</li>
<li>Write out the likelihood for a Poisson regression and describe how it could be used to estimate coefficients for a model.</li>
<li>Interpret estimated coefficients from a Poisson regression and construct confidence intervals for them.</li>
<li>Use deviances for Poisson regression models to compare and assess models.</li>
<li>Use an offset to account for varying effort in data collection.</li>
<li>Fit and use a zero-inflated Poisson (ZIP) model.</li>
</ul>
</div>
<div id="preface-1" class="section level2">
<h2><span class="header-section-number">4.2</span> Preface</h2>
<p>This chapter introduces themes and approaches to modeling that you will use throughout <em>Broaden Your Statistical Horizons</em>. Major ideas you will see again and again include:</p>
<ol style="list-style-type: decimal">
<li><strong>Response</strong>: Explicitly define your response. This will be very helpful in choosing a modeling approach.</li>
<li><strong>Research question</strong>: The research question will be your road map as you proceed through your analysis, so do your best to articulate it.</li>
<li><strong>EDA</strong>: Tailor your exploratory data analysis to your research question(s). What kinds of graphs and numerical summaries will help you understand your research question?</li>
<li><strong>Modeling</strong>
<ol style="list-style-type: decimal">
<li>Fitting a model involves estimating coefficients using likelihoods, not least squares.</li>
<li>Checking assumptions for models using graphs and numerical summaries.</li>
<li>Comparing models using deviances.</li>
</ol></li>
</ol>
</div>
<div id="poisintrosec" class="section level2">
<h2><span class="header-section-number">4.3</span> Introduction to Poisson Regression</h2>
<div id="initial-examples" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Initial Examples</h3>
<p>Are the number of motorcycle deaths in a given year related to a state’s helmet laws? Does the number of rapes on a campus during a year differ for public and private colleges? Does the daily number of asthma-related visits to an Emergency Room differ depending on air pollution indices? Has the number of deformed fish in randomly selected Minnesota lakes been affected by changes in trace minerals in the water over the last decade? Each example involves predicting a <strong>response</strong> using one or more <strong>explanatory variables</strong>, although these examples have response variables that are counts per some unit of time or space. We can explicitly define responses for these examples and the corresponding explanatory variables in the following way:</p>
<p>Example 1:</p>
<ul>
<li>Y = number of motorcycle deaths in a given year by state</li>
<li>X = helmet law indicator</li>
</ul>
<p>Example 2:</p>
<ul>
<li>Y = number of rapes on a college campus in a school year</li>
<li>X = private or private school indicator</li>
</ul>
<p>Example 3:</p>
<ul>
<li>Y = number of daily asthma-related visits to an Emergency Room</li>
<li>X = an air pollution index</li>
</ul>
<p>Example 4:</p>
<ul>
<li>Y = number of deformed fish in a randomly selected square meter of a Minnesota lake</li>
<li>X = trace mineral measurements</li>
</ul>
</div>
<div id="sec-Prop" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Poisson Random Variables</h3>
<p>A Poisson random variable is often used to model counts. A description of key features of Poisson random variable follows.</p>
<p align="center">
<strong>Properties of a Poisson random variable</strong>
</p>
<ol style="list-style-type: decimal">
<li>Y= number of events per unit (time or space)</li>
<li>Possible values: 0, 1, 2, <span class="math inline">\(\ldots \infty\)</span></li>
<li>Mean = <span class="math inline">\(\lambda\)</span></li>
<li>Variance = <span class="math inline">\(\lambda\)</span> which implies standard deviation = <span class="math inline">\(\sqrt{\lambda}\)</span></li>
<li><span class="math inline">\(P(Y=y)=\frac{e^{-\lambda}\lambda^y}{y!}\)</span></li>
<li>The sum of Poisson variables is also Poisson.</li>
</ol>
<p>The parameter of interest in Poisson modeling is <span class="math inline">\(\lambda\)</span>, the rate of events per unit of time or space. The observed count, <span class="math inline">\(Y\)</span>, is made over those units of time (e.g., year, hour) or space (e.g., acre, cubic foot). The unit for the first example is calendar year, the second is school year, the third is a day, and the last is a square meter of a Minnesota lake. Define the unit so the rate, <span class="math inline">\(\lambda\)</span>, is meaningful.</p>
<div id="an-example-calculating-poisson-probabilities" class="section level4">
<h4><span class="header-section-number">4.3.2.1</span> An example calculating Poisson probabilities</h4>
<p>Let Y = the number of soccer goals scored in a game by DC United. Suppose that it is known that on average DC United scores 1.02 goals per game (<span class="math inline">\(\lambda\)</span>=1.02). How frequently would exactly two goals be scored by DC United during a game? With Property 5 and the information that <span class="math inline">\(\lambda\)</span>=1.02 goals per game, we can calculate the probability for <em>any</em> number of goals per game using: <span class="math display">\[
P(Y=y)=\frac{e^{-1.02}{1.02}^y}{y!}
\]</span></p>
<p>For our example, we expect to see exactly 2 goals in a game 18.8% of the time: <span class="math display">\[P(Y=2)=\frac{e^{-1.02}{1.02}^2}{2!} = 0.188
\]</span> Using the laws of probability it is also straightforward to calculate the chance of any events of interest such as seeing more than 2 goals in a game or at least one goal in a game. Conversely, in statistical applications you will have data such as Y=2, and your aim will be to use your data to estimate <span class="math inline">\(\lambda\)</span>.</p>
</div>
</div>
<div id="modeling-with-poisson-variables" class="section level3">
<h3><span class="header-section-number">4.3.3</span> Modeling with Poisson variables</h3>
<p>A Poisson random variable is a count, so its minimum value is zero and, in theory, the maximum is unbounded. We’d like to model the parameter <span class="math inline">\(\lambda\)</span>, the average count per unit, as a function of one or more covariates. For an OLS linear regression model, the parameter of interest is the average response, <span class="math inline">\(\mu_i\)</span>, for subject <span class="math inline">\(i\)</span>, and <span class="math inline">\(\mu_i\)</span> is modeled as a line in the case of one explanatory variable. By analogy, it might seem reasonable to try to model the Poisson parameter <span class="math inline">\(\lambda\)</span> as a linear function of an explanatory variable but there are some problems with this approach. In fact, a model like <span class="math inline">\(\lambda_i=\beta_0+\beta_1x_i\)</span> doesn’t work well for Poisson data. A line is certain to yield negative values for certain <span class="math inline">\(x_i\)</span>, but <span class="math inline">\(\lambda_i\)</span> can only take on values from 0 to <span class="math inline">\(\infty\)</span>. In addition, the equal variance assumption in linear regression is violated because as the mean rate for a Poisson variable increases the variance also increases (recall <span class="math inline">\(E(Y)=Var(Y)=\lambda\)</span>).</p>
<p>One way to avoid these problems is to model log(<span class="math inline">\(\lambda_i\)</span>) instead of <span class="math inline">\(\lambda_i\)</span> as a function of the covariates. The log(<span class="math inline">\(\lambda_i\)</span>) takes on values from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(\infty\)</span>. We can also take into account the increase in the variance using this approach. (Note that throughout <em>Broaden Your Statistical Horizons</em> we use log to represent the natural logarithm.) Thus, we will consider the <strong>Poisson regression</strong> model:</p>
<span class="math display" id="eq:poisReg">\[\begin{equation}
log(\lambda_i)=\beta_0+\beta_1x_i
\tag{4.1}
\end{equation}\]</span>
<p>where the observed values <span class="math inline">\(Y_i \sim\)</span> Poisson with <span class="math inline">\(\lambda=\lambda_i\)</span> for a given <span class="math inline">\(x_i\)</span>.</p>
<div id="poisson-regression-assumptions" class="section level4">
<h4><span class="header-section-number">4.3.3.1</span> Poisson Regression Assumptions</h4>
<p>Much like OLS, using Poisson regression to make inferences requires model assumptions.</p>
<ol style="list-style-type: decimal">
<li><strong>Linearity</strong> The log of the mean rate, log(<span class="math inline">\(\lambda\)</span>), must be a linear function of x.</li>
<li><strong>Mean=Variance</strong> By definition, the mean of a Poisson random variable must be equal to its variance.</li>
<li><strong>Independence</strong> The observations must be independent of one another.</li>
</ol>
</div>
</div>
<div id="a-graphical-look-at-poisson-regression" class="section level3">
<h3><span class="header-section-number">4.3.4</span> A Graphical Look at Poisson Regression</h3>
<div class="figure" style="text-align: center"><span id="fig:OLSpois"></span>
<img src="bookdown-bysh_files/figure-html/OLSpois-1.png" alt="Regession Models: Linear Regression (left) and Poisson Regression (right)" width="60%" />
<p class="caption">
Figure 4.1: Regession Models: Linear Regression (left) and Poisson Regression (right)
</p>
</div>
<p>Figure <a href="ch-poissonreg.html#fig:OLSpois">4.1</a> illustrates a comparison of the OLS model for inference to Poisson regression using a log function of <span class="math inline">\(\lambda\)</span>.</p>
<ol style="list-style-type: decimal">
<li>The graphic displaying the ordinary least squares (OLS) inferential model appears in the left panel of Figure <a href="ch-poissonreg.html#fig:OLSpois">4.1</a>. It shows that for each level of X, the responses appear to be approximately normal. The panel on the right side of Figure <a href="ch-poissonreg.html#fig:OLSpois">4.1</a> depicts what a Poisson regression model looks like. For each level of X, the responses follow a Poisson distribution. For Poisson regression small values of <span class="math inline">\(\lambda\)</span> are associated with a distribution that is noticeably skewed with lots of small values and only a few larger ones. As <span class="math inline">\(\lambda\)</span> increases the distribution of the responses begins to look more and more like a normal distribution.</li>
<li>In the case of OLS, the mean responses for each level of X, <span class="math inline">\(\mu_{Y|X}\)</span>, fall on a line. In the case of the Poisson model, the mean values of <span class="math inline">\(Y\)</span> at each level of <span class="math inline">\(X\)</span>, <span class="math inline">\(\lambda_{Y|X}\)</span>, fall on a curve, not a line.</li>
<li>In the OLS regression model, the variation in <span class="math inline">\(Y\)</span> at each level of X, <span class="math inline">\(\sigma^2\)</span>, is the same. For Poisson regression the responses at each level of X become more variable with increasing means.</li>
</ol>
<div id="poisson-models" class="section level4">
<h4><span class="header-section-number">4.3.4.1</span> Poisson Models</h4>
<p>That single parameter, <span class="math inline">\(\lambda\)</span>, specifies both the mean and variance of the distribution of counts. Thus as the mean increases the variance does as well. This is in contrast to OLS assumptions for inference which require the variance to be constant for all mean values of <span class="math inline">\(Y\)</span>. While relaxing the assumption of equal variances is convenient, specifying that the variance be equal to the mean is rather restrictive. It would be nice to be able to uncouple the specification of the mean and variance instead of having them be exactly equal to one another. You will see later in this chapter that there are ways in which to modify the Poisson model to allow for more flexibility. These modifications reflect a principle for <em>Broadening Your Statistical Horizons</em>: modeling can be flexible. When modeling, you are not restricted to only a few options.</p>
</div>
<div id="poisson-process-optional" class="section level4">
<h4><span class="header-section-number">4.3.4.2</span> Poisson Process (Optional)</h4>
<p>A Poisson model for counts can be thought of as being generated from a Poisson process. A time period or space can be broken into very small, equal size units. The probability of an event within a given unit is very small and independent of other units. For example, the probability of a rape within a very short period of time is very small. A Poisson model implies that the probability of a rape occurring during another very small, equal length time period is the same and independent of a rape occurring within another time period of equal length. Two related facts are worth noting. First, observations are independent. Second events occur during this process at a constant rate. Therefore, a Poisson process can be seen as the limiting case of a binomial distribution as <span class="math inline">\(n \rightarrow \infty\)</span> and <span class="math inline">\(p \rightarrow 0\)</span>. A Poisson process can also be generated by using exponentially distributed waiting times between events.</p>
</div>
</div>
</div>
<div id="case-studies-overview" class="section level2">
<h2><span class="header-section-number">4.4</span> Case Studies Overview</h2>
<p>We take a look at the Poisson regression model in the context of three case studies. Each case study illustrates different concepts encountered in Poisson regression. They are based on real data and real questions. Modeling the household size in Haiti introduces the idea of regression with a Poisson response along with its assumptions. A quadratic term is added to a model to determine an optimal size per household, and methods of model comparison are introduced. The campus crime case study introduces two big ideas in Poisson regression modeling: offsets, to account for sampling effort, and overdispersion, when actual variability exceeds what is expected by the model. Finally, the weekend drinking example uses a modification of a Poisson model to account for more zeros than would be expected for a Poisson random variable. These three case studies also provide context for some of the familiar concepts related to modeling such as exploratory data analysis, estimation, and residual plots. An optional section demonstrates the use of likelihoods to fit Poisson models.</p>
</div>
<div id="case-study-household-size-in-haiti" class="section level2">
<h2><span class="header-section-number">4.5</span> Case Study: Household Size in Haiti</h2>
<p>How many other people live with you in your home? The number of people sharing a house differs from country to country and often from village to village. International agencies use household size when determining needs of populations. Household sizes determine the magnitude of the household needs. Much of the work for maintaining a household falls to the female head of the household. At what age can a female head of a household expect to be caring for the largest number of people?</p>
<p>The 2010 Census enumerated 308.7 million people in the United States, a 9.7 percent increase from 281.4 million in Census 2000. Of the total population in 2010, 300.8 million lived in 116.7 million households for an average of 2.58 people per household. <a href="https://www.census.gov/prod/cen2010/briefs/c2010br-14.pdf">Households and Families: 2010 - Census Bureau</a> <span class="citation">[@census2010]</span></p>
<p>In a 2010 Census in Haiti, there was an average of 4.9 persons per household headed by women with a maximum of 15. The typical house in Haiti, however, differs markedly from one in the US. Of the 560 households in our data, there are anywhere from 1 to 13 people in the house and over 30% of these households have a thatched roof.</p>
<p>This first case study introduces a number of key ideas. Here is a preview:</p>
<ol style="list-style-type: decimal">
<li><strong>Modeling</strong>: coefficients are estimated using likelihoods.</li>
<li><strong>Interpretation</strong>: Exponentiate coefficients for better interpretation.</li>
<li><strong>Assumptions</strong>: Check the Poisson assumptions and the fit of the model.
<ul>
<li><strong>Linearity</strong>: look at the log of mean responses vs. X</li>
<li><strong>Mean=Variance</strong>: look at the mean and variance of responses at different levels of X</li>
<li><strong>Outliers</strong>: look at residual plots</li>
</ul></li>
<li><strong>Drop-in-Deviance Tests:</strong> Compare models using deviances.</li>
<li><strong>Overdispersion:</strong> When a model is correctly specified and outliers considered, adjust for overdispersion if necessary.</li>
</ol>
<div id="research-question" class="section level3">
<h3><span class="header-section-number">4.5.1</span> Research Question</h3>
<p>At what age are women in Haiti most likely to find the largest number of people in their household? Is this association similar for poorer households (measured by the presence of a thatched roof)? We begin by explicitly defining our response, <span class="math inline">\(Y=\)</span> number of people other than the female head of the household, and the explanatory variables: age of the female head of the household, type of roof (thatched, cement or tile), and location (Chouquette, Laferme, Maurace, Roche Jabouin, Rousseau). Our response is a count so we consider a Poisson regression where the parameter of interest is <span class="math inline">\(\lambda\)</span>, the average number of people per household. We will primarily examine the relationship between household size and age of the female head of household controlling for location.</p>
</div>
<div id="data-collection" class="section level3">
<h3><span class="header-section-number">4.5.2</span> Data Collection</h3>
<p>In the summer of 2010, 320 households in the region of Port Salut, Haiti, were included in a public health survey to ascertain the health needs of the population. Trained community members completed 320 household surveys in an eight week period. A systematic sampling method was used in which every third (or fourth) house in a village was included in the survey sample.The survey was administered by Dr. Therese Zink of the University of Minnesota.</p>
</div>
<div id="data-organization-1" class="section level3">
<h3><span class="header-section-number">4.5.3</span> Data Organization</h3>
<p>Each line of the data file refers to a household at the time of the survey:</p>
<ul>
<li><code>age</code> = the age of the female head of household</li>
<li><code>numLT5</code> = the number in the household under 5 years of age</li>
<li><code>numHouse</code> = the number in the household (including the female head)</li>
<li><code>Roof</code> = the type of roof in the household (thatched or iron/cement)</li>
<li><code>Location</code> = where the house is located (Chouquette, Laferme, Maurace, Roche Jabouin, or Rousseau)</li>
</ul>
<pre><code>    Location age numLT5 numHouse        Roof
1 Chouquette  32      1        4    thatched
2 Chouquette  31      0        6    thatched
3 Chouquette  45      1        9    thatched
4 Chouquette  26      3        5 iron/cement
5 Chouquette  35      0        4    thatched
6 Chouquette  31      2        4 iron/cement</code></pre>
</div>
<div id="exploratory-data-analysis" class="section level3">
<h3><span class="header-section-number">4.5.4</span> Exploratory Data Analysis</h3>
<p>Poisson random variables typically can have responses of no events (zeros). However, as constructed, the response of <code>numHouse</code> does not include any zeros because the female head of the household is also included. We can create a variable more appropriate for Poisson regression by subtracting one from the total in the household thereby describing the number in the household <em>in addition to</em> the female head of household.</p>
<p>There are 320 households included in this analysis. For households with female heads, the mean number in the household in addition to the female head of the househhold (HH) is 4.4 (SD=2.5, Var=6.4). The mean number for houses with thatched roofs is 4.77 (SD=2.34, Var=5.5), whereas houses with iron or cement roofs average only 4.28 (SD=2.60, Var=6.8). Of the various locations, Rousseau has the largest households, on average, with a mean of 6.39 in the household, and Chouquette has the smallest with a mean of 3.42.</p>
<div class="figure" style="text-align: center"><span id="fig:nhouse"></span>
<img src="bookdown-bysh_files/figure-html/nhouse-1.png" alt="Haiti: Distribution of household size" width="60%" />
<p class="caption">
Figure 4.2: Haiti: Distribution of household size
</p>
</div>
<p>Figure <a href="ch-poissonreg.html#fig:nhouse">4.2</a> reveals a fair amount of variability in the number in each house; responses range from 0 to 13 with many of the respondents reporting between 2 and 7 people in the house in addition to the female head of household. Like many Poisson distributions, this graph is right skewed. It clearly does not suggest that the number of people in a household is a normally distributed response.</p>
<p>For the remainder of the analysis, we’ll proceed in the following way.</p>
<p><strong>Fit a linear model in age (using likelihoods).</strong></p>
<ul>
<li>Interpret the estimated coefficient for the age term and test its significance using a Wald-type test and a drop-in-deviance test..</li>
<li>Assess the assumptions of the linear model.
<ul>
<li>Linearity</li>
<li>Independence</li>
<li>Mean=Variance</li>
<li>A residual plot with no trends or outliers</li>
</ul></li>
</ul>
<p><strong>Fit a quadratic model.</strong></p>
<ul>
<li>Test the significance of the coefficient of the age<span class="math inline">\(^2\)</span> term using a Wald-type test.</li>
<li>Add the factor <code>Location</code> to the quadratic model to control for differences by village.</li>
<li>Introduce the <strong>drop-in-deviance</strong> test as a way of comparing models
<ul>
<li>Compare the linear to the quadratic model.</li>
<li>Compare the quadratic model with and without the <code>Location</code> variable.</li>
</ul></li>
<li>Examine residual plots for the final model.</li>
<li>Use calculus to determine the age at which there is the maximum number of people.</li>
</ul>
<p><strong>Adjust for overdispersion.</strong></p>
<ul>
<li>Make adjustments, if necessary, if the variance exceeds the mean.</li>
</ul>
</div>
</div>
<div id="likelihood.sec" class="section level2">
<h2><span class="header-section-number">4.6</span> Using Likelihoods to fit Poisson Regression Models (Optional)</h2>
<p>Before we have a statistical package produce estimated regression coefficients for our Poisson regression model, let’s look under the hood to see how the model is fit. The least squares approach requires a linear relationship between the parameter, <span class="math inline">\(\mu_i\)</span> (the expected or mean response for observation <span class="math inline">\(i\)</span>), and <span class="math inline">\(x_i\)</span>. However, it is log<span class="math inline">\((\lambda_i)\)</span>, not <span class="math inline">\(\lambda_i\)</span>, that is linearly related to X with the Poisson model. As noted, the assumptions of equal variance and normality also do not hold for Poisson regression. So the method of least squares will not be helpful here. Instead of OLS, we employ the likelihood principle to find estimates of our model coefficients. We look for those coefficient estimates for which the likelihood of our data is maximized; these are the <strong>maximum likelihood estimates</strong>.</p>
The likelihood for n <em>independent</em> observations is the product of the probabilities. For example, if we observe five households with <code>numHouse</code> = <span class="math inline">\((4,2,8,6,1)\)</span> the likelihood is: <span class="math display">\[ Likelihood = P(Y_1=4)*P(Y_2=2)*P(Y_3=8)*P(Y_4=6)*P(Y_5=1)\]</span> Recall that the probability of a Poisson response can be written <span class="math display">\[P(Y=y)=\frac{e^{-\lambda}\lambda^y}{y!}\]</span> So the likelihood can be written as
<span class="math display">\[\begin{eqnarray*}
 Likelihood&amp;= &amp;\frac{ e^{-\lambda}\lambda^4 }{ 4! }*
 \frac{ e^{-\lambda}\lambda^2 }{ 2! } *\frac{e^{-\lambda}\lambda^8}{8!}*
 \frac{e^{-\lambda}\lambda^6}{6!}*\frac{e^{-\lambda}\lambda^1}{1!}\\
 \end{eqnarray*}\]</span>
<p>As in the earlier likelihood chapter, it will be easier to find a maximum if we take the log of the likelihood and ignore the constant term resulting from the sum of the factorials:</p>
<span class="math display" id="eq:poisLoglik">\[\begin{eqnarray}
 -logL&amp; \propto&amp; \lambda_{X=4}-4log(\lambda_{X=4})+\lambda_{X=2}-2log(\lambda_{X=2}) \\
 &amp; &amp;+\lambda_{X=8}-8log(\lambda_{X=8})+\lambda_{X=6}-6log(\lambda_{X=6})\\
 &amp; &amp;+\lambda_{X=1}-log(\lambda_{X=1})
 \tag{4.2}
\end{eqnarray}\]</span>
<p>Now if we had the age of the female head of the household for each house (X), we consider the Poisson regression model: <span class="math display">\[
log(\lambda_i)=\beta_0+\beta_1x_i
 \]</span> This implies that <span class="math inline">\(\lambda\)</span> differs for each age and can be determined using <span class="math display">\[\lambda_i=e^{\beta_0+\beta_1x_i.}\]</span></p>
<p>If the ages are <span class="math inline">\(X=(22,21,25,24,22)\)</span> years, our loglikelihood can be written:</p>
<span class="math display" id="eq:poisLoglik2">\[\begin{eqnarray}
 logL &amp;= &amp;[-e^{\beta_0+\beta_122}+4({\beta_0+\beta_122})]+
[-e^{\beta_0+\beta_121}+2({\beta_0+\beta_121})]+\\ 
&amp; &amp; [-e^{\beta_0+\beta_125}+8({\beta_0+\beta_125})]+
[-e^{\beta_0+\beta_124}+6({\beta_0+\beta_124})]+ \\
  &amp; &amp; [-e^{\beta_0+\beta_122}+({\beta_0+\beta_122})]
\tag{4.3}
\end{eqnarray}\]</span>
<p>To see this, match the terms in Equation <a href="ch-poissonreg.html#eq:poisLoglik">(4.2)</a> with those in Equation <a href="ch-poissonreg.html#eq:poisLoglik2">(4.3)</a> noting that <span class="math inline">\(\lambda_i\)</span> has been replaced with <span class="math inline">\(e^{\beta_0+\beta_1x_i}\)</span>. It is Equation <a href="ch-poissonreg.html#eq:poisLoglik2">(4.3)</a> that will be used to estimate the coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. Although this looks a little more complicated than the loglikelihoods we saw in Chapter <a href="ch-beyondmost.html#ch-beyondmost">2</a>, the fundamental ideas are the same. In theory, we try out different possible values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> until we find the two for which the loglikelihood is largest. Most statistical software packages have automated search algorithms to find those values for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> that maximize the loglikelihood.</p>
</div>
<div id="modeling" class="section level2">
<h2><span class="header-section-number">4.7</span> Modeling</h2>
<p>We first consider a model for which log(<span class="math inline">\(\lambda\)</span>) is linear in age. We check the Poisson assumptions to determine whether a model with a quadratic term in age provides a significant improvement.</p>
<div id="first-order-model" class="section level3">
<h3><span class="header-section-number">4.7.1</span> First Order Model</h3>
<p>Although we intend to fit a quadratic model, we’ll start with a linear model. Output for the linear model appears below.</p>
<pre><code>glm(formula = numHouse_1 ~ age, family = poisson, data = fHH1)

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) 0.624526   0.103838   6.014  1.8e-09 ***
age         0.027403   0.003075   8.912  &lt; 2e-16 ***
---
(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 473.56  on 319  degrees of freedom
Residual deviance: 392.79  on 318  degrees of freedom
AIC: 1412.6</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># CI for betas using profile likelihood</span>
<span class="kw">confint</span>(modela)</code></pre></div>
<pre><code>##                  2.5 %     97.5 %
## (Intercept) 0.41924146 0.82633118
## age         0.02139044 0.03344555</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">confint</span>(modela))</code></pre></div>
<pre><code>##                2.5 %   97.5 %
## (Intercept) 1.520808 2.284920
## age         1.021621 1.034011</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Wald type CI by hand</span>
beta1hat &lt;-<span class="st"> </span><span class="kw">summary</span>(modela)<span class="op">$</span>coefficients[<span class="dv">2</span>,<span class="dv">1</span>]
beta1se &lt;-<span class="st"> </span><span class="kw">summary</span>(modela)<span class="op">$</span>coefficients[<span class="dv">2</span>,<span class="dv">2</span>]
beta1hat <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>beta1se   <span class="co"># lower bound </span></code></pre></div>
<pre><code>## [1] 0.02137664</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beta1hat <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>beta1se   <span class="co"># upper bound </span></code></pre></div>
<pre><code>## [1] 0.03343023</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># p-value for test comparing the null and first order models</span>
drop.in.dev &lt;-<span class="st"> </span>modela<span class="op">$</span>null.deviance <span class="op">-</span><span class="st"> </span>modela<span class="op">$</span>deviance
drop.in.dev</code></pre></div>
<pre><code>## [1] 80.77206</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">diff.in.df &lt;-<span class="st"> </span>modela<span class="op">$</span>df.null <span class="op">-</span><span class="st"> </span>modela<span class="op">$</span>df.residual
diff.in.df</code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(drop.in.dev, diff.in.df)</code></pre></div>
<pre><code>## [1] 0</code></pre>
</div>
<div id="sec-PoisInference" class="section level3">
<h3><span class="header-section-number">4.7.2</span> Estimation and Inference</h3>
Most software packages report the estimated coefficients so that the estimated regression equation for the previous model is: <span class="math display">\[
\widehat{log(\lambda)} = 0.625 + 0.0274 (age)
\]</span> How can the coefficient estimates be interpreted in terms of this application? As done when interpreting slopes in the OLS models, we consider how the estimated mean number in the house, <span class="math inline">\(\lambda\)</span>, changes as the age of the household head increases by an additional year. But in place of looking at change in the mean number in the house, with a Poisson regression we consider the log of the mean number in the house and then convert back to original units.
<span class="math display" id="eq:rateRatio">\[\begin{eqnarray}
log(\lambda_X) &amp;=&amp; \beta_0 + \beta_1X \\
log(\lambda_{X+1}) &amp;=&amp; \beta_0 + \beta_1(X+1) \\
log(\lambda_{X+1})-log(\lambda_X) &amp;= &amp; \beta_1 \\
log \left(\frac{\lambda_{X+1}}{\lambda_X}\right)   &amp;= &amp;\beta_1\\
\frac{\lambda_{X+1}}{\lambda_X} &amp;=&amp; e^{\beta_1}
\tag{4.4}
\end{eqnarray}\]</span>
<p>These results suggest that by exponentiating the coefficient on age we obtain the multiplicative factor by which the mean count changes. In this case, the mean number in the house changes by a factor of <span class="math inline">\(e^{.0274}=1.028\)</span> or increases by a factor of 2.8% with each additional year older the household head is. The quantity on the left hand side of Equation <a href="ch-poissonreg.html#eq:rateRatio">(4.4)</a> is referred to as a <strong>rate ratio</strong> or <strong>relative risk</strong>, and it represents a percent change in the response for unit changes in X. In fact, for regression models in general, whenever a variable (response or explanatory) is logged, we make interpretations about multiplicative effects on that variable, while with unlogged variables we can reach our usual interpretations about additive effects.</p>
<p>Typically the standard errors for the estimated coefficients are included in Poisson regression output. Here the standard error for the estimated coefficient for age is 0.003075 so we can construct a confidence interval for <span class="math inline">\(\beta_1\)</span>. A 95% CI provides a range of plausible values for the <code>age</code> coefficient and can be constructed: <span class="math display">\[0.0274-1.96*0.0031, 0.0274+1.96*0.0031\]</span> <span class="math display">\[ (.0214, .0334).
 \]</span> Exponentiating the endpoints yields a confidence interval for the relative risk, i.e., the percent change in household size for each additional year older. Thus <span class="math inline">\((e^.0214,e^.0334)=(1.022,1.034)\)</span> suggests that we are 95% confident that the mean number in the house increases between 2.2% and 3.4% for each additional year older the head of household is. It is best to construct a CI for the coefficient and then exponentiate the endpoints because the estimated coefficients are closer to normal than the exponentiated coefficients. There are other approaches to constructing intervals in these circumstances, including profile likelihood, the delta method, and bootstrapping, but we do not discuss them here.</p>
<p>If the null model were true, there is no change in household size for each additional year, so that <span class="math inline">\(\lambda_X\)</span> is equal to <span class="math inline">\(\lambda_{X+1}\)</span> and the ratio <span class="math inline">\(\lambda_{X+1}/\lambda_X\)</span> is 1. Note that our interval for <span class="math inline">\(e^{\beta_1}\)</span>, (1.022, 1.034), does not include 1, so the model with age is preferred to a model without age; i.e., age is significantly associated with household size. Note that we could have similarly confirmed that our interval for <span class="math inline">\(\beta_1\)</span>, (.0214, .0334), does not include 0 to show the significance of age as a predictor of household size.</p>
<p>One way to test the significance of the age term is to calculate a <strong>Wald-type statistic</strong>. A Wald-type test statistic is the estimated coefficient divided by its standard error. When the true coefficient is 0, this test statistic follows a standard normal distribution for sufficiently large <span class="math inline">\(n\)</span>. The estimated coefficient associated with the linear term in age is <span class="math inline">\({\hat{\beta_1}}=0.0274\)</span> with standard error <span class="math inline">\(SE(\hat{\beta_1})=0.003075\)</span>. The value for the Wald test statistic is then <span class="math inline">\(Z=\hat{\beta_1}/SE(\hat{\beta_1})=8.912\)</span>, whose two-sided p-value based on the normal distribution for testing <span class="math inline">\(H_O:\beta_1=0\)</span> is tiny (“&lt;2e-16”). In conclusion, we have statistically significant evidence (Z = 8.91, p &lt; .001) that average household size increases as age of the female head of household increases.</p>
<p>Another way in which to assess the contribution of the age term is to perform a <strong>drop-in-deviance test</strong>.</p>
</div>
<div id="using-deviances-to-compare-models" class="section level3">
<h3><span class="header-section-number">4.7.3</span> Using Deviances to Compare Models</h3>
<p>There is another way in which to assess how useful age is in the model. A <strong>deviance</strong> is a way in which to measure how the observed data deviates from the model predictions (it will be defined more precisely later). Keeping in mind that the deviance describes the remaining unexplained variation, we calculate the <strong>drop-in-deviance</strong> when adding age to the model with no covariates (the <strong>null model</strong>). The deviances for the null model and the model with age can be found on the model output. A residual deviance for the model with age is reported as 392.79 with 318 df. The output also includes the deviance and df for the null model (473.56 with 319 df). The drop-in-deviance is (473.56 - 392.79 = 80.77) with a difference of only 1 df. Theory (not covered here) tells us that if the null model is true, we would expect the drop-in-deviance to follow a <span class="math inline">\(\chi^2\)</span> distribution with 1 df. Therefore the p-value for comparing the null model to the model with age is found by determining the probability that the value for <span class="math inline">\(\chi^2\)</span> with one df exceeds 80.77, which is essentially 0. Once again, we can conclude that we have statistically significant evidence (<span class="math inline">\(\chi^2=80.77\)</span>, <span class="math inline">\(p &lt; .001\)</span>) that average household size increases as age of the female head of household increases.</p>
<p>In order to use the drop-in-deviance test, the models being compared must be nested; i.e., all the terms in the smaller model must appear in the larger model. Here the smaller model is the null model with the single term <span class="math inline">\(\beta_0\)</span> and the larger model has <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, so the two models are indeed nested. For nested models, we can compare the models’ residual deviances to determine whether the larger model provides a significantly improvement.</p>
<p>Here, then, is a summary of these two approaches to hypothesis testing about terms in Poisson regression models:</p>
<p align="center">
<strong>Drop-in-deviance test to compare models</strong>
</p>
<ul>
<li>Compute the deviance for each model, then calculate: drop-in-deviance = residual deviance for reduced model - residual deviance for the larger model.</li>
<li>When the reduced model is true, the drop-in-deviance <span class="math inline">\(\sim \chi^2_d\)</span> where d= the difference in the degrees of freedom associated with the two models (that is, the difference in the number of terms / coefficients).</li>
<li>A large drop-in-deviance favors the larger model.</li>
</ul>
<p align="center">
<strong>Wald test for a single coefficient</strong>
</p>
<ul>
<li>Wald-type statistic = estimated coefficient / standard error</li>
<li>When the true coefficient is 0, for sufficiently large <span class="math inline">\(n\)</span>, the test statistic <span class="math inline">\(\sim\)</span> N(0,1).</li>
<li>If the magnitude of the test statistic is large, there is evidence that the true coefficient is not 0.</li>
</ul>
<p>The drop-in-deviance and the Wald-type tests usually provide consistent results; however, if there is a discrepancy the drop-in-deviance is preferred. Not only does the drop-in-deviance test perform better in more cases, but it’s also more flexible. If two models differ by one term, then the drop-in-deviance test essentially tests if a single coefficient is 0 like the Wald test does, while if two models differ by more than one term, the Wald test is no longer appropriate.</p>
<p>In this case, the Wald-type test and the drop-in-deviance test both suggest that a linear term in age is useful. But are the model assumptions satisfied?</p>
</div>
<div id="poisson-regression-assumptions-1" class="section level3">
<h3><span class="header-section-number">4.7.4</span> Poisson Regression Assumptions</h3>
<div id="linearity" class="section level4">
<h4><span class="header-section-number">4.7.4.1</span> Linearity</h4>
<div class="figure" style="text-align: center"><span id="fig:ageXnhouse"></span>
<img src="bookdown-bysh_files/figure-html/ageXnhouse-1.png" alt="The log of the mean number in each household by grouped age of the female head of household, with loess smoother." width="60%" />
<p class="caption">
Figure 4.3: The log of the mean number in each household by grouped age of the female head of household, with loess smoother.
</p>
</div>
<p>Recall that the Poisson regression model implies that log(<span class="math inline">\(\lambda_i\)</span>), not the mean <span class="math inline">\(\lambda_i\)</span>, is a linear function of <span class="math inline">\(x_i\)</span>. Therefore, to check the linearity assumption for Poisson regression we would like to plot log(<span class="math inline">\(\lambda_i\)</span>) by age,<span class="math inline">\(x_i\)</span>. Unfortunately, <span class="math inline">\(\lambda_i\)</span> is unknown. Our best guess of <span class="math inline">\(\lambda_i\)</span> is the observed mean number in the household for each age (level of <span class="math inline">\(X\)</span>). Because these means are computed for observed data, they are referred to as <strong>empirical</strong> means. Taking the logs of the empirical means and plotting by age provides a way to assess the linearity assumption. The smoothed curve added to Figure <a href="ch-poissonreg.html#fig:ageXnhouse">4.3</a> suggests that there is a curvilinear relationship between age and the log of the mean household size implying that adding a quadratic term should be considered. This finding is consistent with the researchers’ hypothesis that there is an age at which a maximum household size occurs. It is worth noting that we are not modeling the log of the empirical means, rather it is the log of the <em>true</em> rate that is modeled. Looking at empirical means, however, does provide an idea of the form of the relationship between log(<span class="math inline">\(\lambda)\)</span> and <span class="math inline">\(x_i\)</span>.</p>
</div>
<div id="mean-variance" class="section level4">
<h4><span class="header-section-number">4.7.4.2</span> Mean = Variance</h4>
<p>For Poisson random variables, the variance of <span class="math inline">\(Y\)</span> (i.e., the square of the standard deviation of <span class="math inline">\(Y\)</span>), is equal to its mean, where <span class="math inline">\(Y\)</span> represents the size of an individual household. As the mean increases, the variance increases. So, if the response is a count and the mean and variance are approximately equal for each group of <span class="math inline">\(X\)</span>, a Poisson regression model may be a good choice. In Table <a href="ch-poissonreg.html#tab:table1chp4">4.1</a> we display only a portion of the age groups to check to see if the empirical means and variances of the number in the house are approximately equal for each age group. This provides us one way in which to check the Poisson assumption.</p>
<table>
<caption><span id="tab:table1chp4">Table 4.1: </span>Compare mean and variance of household size within each age group</caption>
<thead>
<tr class="header">
<th align="left">Age Groups</th>
<th align="right">Mean</th>
<th align="right">Variance</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(15,20]</td>
<td align="right">3.720930</td>
<td align="right">2.348837</td>
<td align="right">43</td>
</tr>
<tr class="even">
<td align="left">(20,25]</td>
<td align="right">4.648148</td>
<td align="right">3.553110</td>
<td align="right">54</td>
</tr>
<tr class="odd">
<td align="left">(25,30]</td>
<td align="right">4.769231</td>
<td align="right">3.828054</td>
<td align="right">52</td>
</tr>
<tr class="even">
<td align="left">(30,35]</td>
<td align="right">6.058823</td>
<td align="right">5.160667</td>
<td align="right">68</td>
</tr>
<tr class="odd">
<td align="left">(35,40]</td>
<td align="right">6.642857</td>
<td align="right">6.722996</td>
<td align="right">42</td>
</tr>
<tr class="even">
<td align="left">(40,45]</td>
<td align="right">6.574074</td>
<td align="right">10.135919</td>
<td align="right">54</td>
</tr>
<tr class="odd">
<td align="left">(45,50]</td>
<td align="right">9.000000</td>
<td align="right">0.000000</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="left">(50,55]</td>
<td align="right">5.000000</td>
<td align="right">NA</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">NA</td>
<td align="right">3.250000</td>
<td align="right">1.583333</td>
<td align="right">4</td>
</tr>
</tbody>
</table>
<p>If there is a problem with this assumption most often we see variances much larger than means. Here we see that, for the most part, variances that are smaller than the means. Thus, there is no compelling evidence of a problem with the mean=variance assumption, although we should be aware of high variability among older heads of households.</p>
</div>
<div id="independence" class="section level4">
<h4><span class="header-section-number">4.7.4.3</span> Independence</h4>
<p>The independence assumption can be assessed using knowledge of the study design and the data collection process. In this case, we do not have enough information to assess the independence assumption with the information we are given. If selections of groups of households were made from different villages with differing customs about living arrangements, the independence assumption would be violated. If this were the case, we could use a multilevel model like those discussed in later chapters with a village term.</p>
</div>
</div>
<div id="residual-plot" class="section level3">
<h3><span class="header-section-number">4.7.5</span> Residual Plot</h3>
<p>A residual plot can be of limited use when assessing Poisson regression model assumptions. It may provide some insight into linearity and outliers, although the plots are not quite as useful here as they are for OLS. There are a couple of options for computing residuals and predicted values. Residuals may have the form of residuals for OLS models or the form of deviance residuals (defined in the next section) which, when squared, sum to the total deviance for the model. Predicted values can be estimates of the counts, <span class="math inline">\(e^{\beta_0+\beta_1X}\)</span>, or estimates of the log of the count, <span class="math inline">\(\beta_0+\beta_1X\)</span>. We choose to use the deviance residuals and predicted counts. More detail follows.</p>
</div>
<div id="residuals-for-poisson-models-optional" class="section level3">
<h3><span class="header-section-number">4.7.6</span> Residuals for Poisson Models (Optional)</h3>
Residuals for OLS are useful for comparing models. The residuals for OLS in simple linear regression have the form:
<span class="math display" id="eq:OLSresid">\[\begin{eqnarray}
 OLS\hspace{2mm}residual_i  &amp;= &amp;obs_i - fit_i \\
&amp;=&amp;{Y_i-\hat{\mu_i}} \\
 &amp;= &amp;Y_i-(\hat{\beta_0} +\hat{\beta_1}X_i)
\tag{4.5}
 \end{eqnarray}\]</span>
Residual sum of squares (RSS) are formed by squaring and adding these residuals, and we generally seek to minimize RSS in model building. We have several options for creating residuals for Poisson regression models. One is to create residuals in much the same way as we do in OLS. For Poisson residuals, the predicted values are denoted by <span class="math inline">\(\hat{\lambda}_i\)</span> (in place of <span class="math inline">\(\hat{\mu_i}\)</span> in Equation <a href="ch-poissonreg.html#eq:OLSresid">(4.5)</a>; they are then standardized by dividing by the standard error, <span class="math inline">\(\sqrt{\lambda_i}\)</span>. These kinds of residuals are referred to as <strong>Pearson residuals</strong> and are used with Poisson regression.
<span class="math display" id="eq:pearson">\[\begin{equation}
\textrm{Pearson residual}_i = \frac{Y_i-\hat{\lambda}_i}{\sqrt{\hat{\lambda}_i}}
\tag{4.6}
\end{equation}\]</span>
Pearson residuals have the advantage that you are probably familiar with their meaning and the kinds of values you would expect. For example, after standardizing we expect most residuals to fall between -2 and 2. However, <strong>deviance residuals</strong> have some useful properties that make them a better choice for Poisson regression. First, we define a <strong>deviance residual</strong> for an observation from a Poisson regression,
<span class="math display" id="eq:deviance">\[\begin{equation}
\textrm{deviance residual}_i = sign(Y_i-\hat{\lambda}_i)
\sqrt{
2 \left[Y_i log\left(\frac{Y_i}{\hat{\lambda}_i}\right)
-(Y_i - \hat{\lambda}_i) \right]}
\tag{4.7}
\end{equation}\]</span>
<p>As its name implies, a deviance residual describes how the observed data deviates from the fitted model. Squaring and summing the deviances for the observations produces the <strong>residual deviance</strong> <span class="math inline">\(=\sum \textrm{deviance residual}_i\)</span>. Relatively speaking, observations for good fitting models will have small deviances; that is, the predicted values will deviate little from the observed. However, you can see that the deviance for an observation does not easily translate to a difference in observed and predicted responses as is the case with OLS models.</p>
<p>A careful inspection of the deviance formula reveals several places where the deviance compares <span class="math inline">\(Y\)</span> to <span class="math inline">\(\hat{\lambda}\)</span>: the sign of the deviance is based on the difference between <span class="math inline">\(Y\)</span> and <span class="math inline">\(\hat{\lambda}\)</span>, and under the radical sign we see the ratio <span class="math inline">\(Y/\hat{\lambda}\)</span> and the difference <span class="math inline">\(Y -\hat{\lambda}\)</span>. When <span class="math inline">\(Y = \hat{\lambda}\)</span>, that is, when the model fits perfectly, the difference will be 0 and the ratio will be 1 (so that its log will be 0). So like the residuals in OLS, an observation that fits perfectly will not contribute to the sum of the squared deviances. This definition of a deviance depends on the likelihood for Poisson models. Other models will have different forms for the deviance depending on their likelihood.</p>
<div class="figure" style="text-align: center"><span id="fig:resid1"></span>
<img src="bookdown-bysh_files/figure-html/resid1-1.png" alt="Residual plot for the Poisson model of number in the household besides the female HH by age of the female HH" width="60%" />
<p class="caption">
Figure 4.4: Residual plot for the Poisson model of number in the household besides the female HH by age of the female HH
</p>
</div>
<p>A plot (Figure <a href="ch-poissonreg.html#fig:resid1">4.4</a>) of the deviance residuals versus predicted responses for the first order model exhibits curvature indicating that the model may be improved by adding a quadratic term. Other details related to residual plots can be found in a variety of sources including <span class="citation">[@McCullagh1989]</span>.</p>
<p>Our analysis thus far suggests that a quadratic term in age might be useful to add to the model.</p>
</div>
<div id="second-order-model" class="section level3">
<h3><span class="header-section-number">4.7.7</span> Second Order Model</h3>
<p>As stated from the outset, our intention is to examine a quadratic model to see if there exists an age where the number in the house is, on average, a maximum. The output for a quadratic model appears below.</p>
<pre><code>glm(formula = numHouse_1 ~ age + age2, family = poisson, data = fHH1)

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)   
(Intercept) -0.1029160  0.3664001  -0.281  0.77880   
age          0.0773529  0.0242037   3.196  0.00139 **
age2        -0.0007935  0.0003809  -2.083  0.03723 * 
---
(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 473.56  on 319  degrees of freedom
Residual deviance: 388.37  on 317  degrees of freedom
AIC: 1410.2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># p-value for test comparing the null and first order models</span>
drop.in.dev &lt;-<span class="st"> </span>modela<span class="op">$</span>deviance <span class="op">-</span><span class="st"> </span>modela2<span class="op">$</span>deviance
drop.in.dev</code></pre></div>
<pre><code>## [1] 4.42515</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">diff.in.df &lt;-<span class="st"> </span>modela<span class="op">$</span>df.residual <span class="op">-</span><span class="st"> </span>modela2<span class="op">$</span>df.residual
diff.in.df</code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(drop.in.dev, diff.in.df)</code></pre></div>
<pre><code>## [1] 0.03541299</code></pre>
<p>We can assess the importance of the quadratic term in two ways. The p-value for the Wald-type statistic for age<span class="math inline">\(^2\)</span> is statistically significant (Z = -2.083, p = .037). Another approach is to perform a drop-in-deviance test.</p>
<p><span class="math inline">\(H_0\)</span>: log(<span class="math inline">\(\lambda\)</span>)=<span class="math inline">\(\beta_0+\beta_1age\)</span> (reduced model)</p>
<p><span class="math inline">\(H_1:\)</span> log(<span class="math inline">\(\lambda\)</span>)=<span class="math inline">\(\beta_0+\beta_1age + \beta_2age^2\)</span> (larger model)</p>
<p>The first order model has a residual deviance = 392.79 with 318 df and the second order model, the quadratic model, has a residual deviance= 388.37 with 317 df. The drop-in-deviance by adding the quadratic term to the linear model is 392.79 - 388.37 = 4.43 which can be compared to a <span class="math inline">\(\chi^2_{1df}\)</span>. The p-value is .035, so the observed drop of 4.42 again provides significant support for including the quadratic term.</p>
<p>Some statistical packages will summarize the drop-in-deviance tests in tabular form. The first drop-in-deviance test below (<span class="math inline">\(\chi^2=80.77, p&lt;2*10^{-16}\)</span>) compares the first-order model to a model with no predictors, while the second drop-in-deviance test (<span class="math inline">\(\chi^2=4.43, p=.035\)</span>) compares the second-order model to the first-order model.</p>
<pre><code>Analysis of Deviance Table

Model 1: numHouse_1 ~ 1
Model 2: numHouse_1 ~ age
Model 3: numHouse_1 ~ age + age2
  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)    
1       319     473.56                         
2       318     392.79  1   80.772  &lt; 2e-16 ***
3       317     388.37  1    4.425  0.03541 *  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="finding-the-age-where-the-number-in-the-house-is-a-maximum" class="section level3">
<h3><span class="header-section-number">4.7.8</span> Finding the age where the number in the house is a maximum</h3>
<p>We now have an equation in age which yields the estimated log(mean number in the house).<br />
<span class="math display">\[
\textrm{log(mean numHouse)} =  -0.1303 + 0.077(age) - 0.00079 (age^2)
\]</span></p>
<p>With a little calculus, we determine that the maximum estimated additional number in the house is <span class="math inline">\(e^{1.746} = 5.73\)</span> when the head of the household is 48.7 years old. This is consistent with our observations from the graphs.</p>
</div>
<div id="adding-a-covariate" class="section level3">
<h3><span class="header-section-number">4.7.9</span> Adding a covariate</h3>
<p>Location may account for differences in the size of the household. Assessing the utility of including the covariate <code>Location</code> is, in essence, comparing two nested models; here the quadratic model is compared to the quadratic model plus terms for <em>Location</em>. Results from the fitted model appears below.</p>
<pre><code>glm(formula = numHouse_1 ~ age + age2 + Location, family = poisson, 
    data = fHH1)

Coefficients:
                        Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)           -0.4076599  0.3826581  -1.065 0.286723    
age                    0.0840507  0.0246012   3.417 0.000634 ***
age2                  -0.0009552  0.0003882  -2.461 0.013868 *  
LocationLaferme        0.3825454  0.1074149   3.561 0.000369 ***
LocationMaurace        0.1254272  0.0943147   1.330 0.183558    
LocationRoche Jabouin  0.2605722  0.1072576   2.429 0.015124 *  
LocationRousseau       0.5866752  0.0982018   5.974 2.31e-09 ***
---
(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 473.56  on 319  degrees of freedom
Residual deviance: 331.86  on 313  degrees of freedom
AIC: 1361.7</code></pre>
<pre><code>Analysis of Deviance Table

Model 1: numHouse_1 ~ age + age2
Model 2: numHouse_1 ~ age + age2 + Location
  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)    
1       317     388.37                         
2       313     331.86  4   56.507 1.57e-11 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># p-value for test comparing the null and first order models</span>
drop.in.dev &lt;-<span class="st"> </span>modela2<span class="op">$</span>deviance <span class="op">-</span><span class="st"> </span>modela2L<span class="op">$</span>deviance
drop.in.dev</code></pre></div>
<pre><code>## [1] 56.5066</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">diff.in.df &lt;-<span class="st"> </span>modela2<span class="op">$</span>df.residual <span class="op">-</span><span class="st"> </span>modela2L<span class="op">$</span>df.residual
diff.in.df</code></pre></div>
<pre><code>## [1] 4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(drop.in.dev, diff.in.df)</code></pre></div>
<pre><code>## [1] 1.570089e-11</code></pre>
<p>Our Poisson regression model now looks like: <span class="math display">\[
\textrm{log(mean numHouse)} =  -0.408 + 0.084*\textrm{age} - 0.00096*\textrm{age}^2 + \\
.383*\textrm{Laferme} + .125*\textrm{Maurace} + 
.261*\textrm{Roche Jabouin} + .587*\textrm{Rousseau}
\]</span> Notice that because there are 5 different locations, we must represent the effects of different locations through 4 indicator variables. For example, <span class="math inline">\(\hat{\beta_3}=.382\)</span> indicates that, after controlling for age of the female head of household, log mean household size is .382 higher for households in Laferme than for households in the reference location of Chouquette, or, in more interpretable terms, mean household size is <span class="math inline">\(e^.382=1.47\)</span> times higher (i.e., 47% higher) in Laferme than in Chouquette, holding age constant.</p>
<p>To test if the mean number of people in a household significantly differs by location, we must use a drop-in-deviance test because four terms, not one, are added when including the <code>Location</code> variable. By the Analysis of Deviance table above, adding the four terms corresponding to location to the quadratic model with age is statistically significant <span class="math inline">\((\chi^2=56.51,p&lt;0.001)\)</span>; there is significant evidence that mean household size differs by location, even after controlling for age of the female head of household.</p>
</div>
<div id="sec-PoisGOF" class="section level3">
<h3><span class="header-section-number">4.7.10</span> Goodness-of-fit</h3>
<p>The model residual deviance can be used to assess the degree to which the predicted values differ from the observed. When a model is true, we can expect the residual deviance to be distributed as a <span class="math inline">\(\chi^2\)</span> with the degrees of freedom equal to the model’s residual degrees of freedom. Here, our model thus far, the quadratic plus indicators for location, has a residual deviance of 331.86 with 313 df. The probability of observing this deviance if the model fit is 0.222, providing no evidence of lack-of-fit.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(modela2L<span class="op">$</span>deviance, modela2L<span class="op">$</span>df.residual)  <span class="co"># GOF test</span></code></pre></div>
<pre><code>[1] 0.2219461</code></pre>
<p>There are several reasons why lack-of-fit may be observed in certain cases. We may be missing important covariates; a more comprehensive data set may allow us to examine this possibility. There may be extreme observations that may cause the deviance to be larger than expected; however, our residual plots did not reveal any unusual points. Lastly, there may be a problem with the Poisson model. In particular, the Poisson model has only a single parameter, <span class="math inline">\(\lambda\)</span>, for each combination of the levels of the predictors which must describe both the mean and the variance. This limitation can become manifest when the variance appears to be larger than the corresponding means. In that case, the response is more variable than the Poisson model would imply, and the response is considered to be overdispered.</p>
</div>
<div id="least-squares-regression-vs.poisson-regression" class="section level3">
<h3><span class="header-section-number">4.7.11</span> Least Squares Regression vs. Poisson Regression</h3>
<p><span class="math display">\[
\underline{\textrm{Response}} \\
\mathbf{OLS:}\textrm{ Normal} \\
\mathbf{Poisson Regression:}\textrm{ counts} \\
\textrm{ } \\
\underline{\textrm{Variance}} \\
\mathbf{OLS:}\textrm{ Equal for each level of X} \\
\mathbf{Poisson Regression:}\textrm{ Equal to the mean for each level of X} \\
\textrm{ } \\
\underline{\textrm{Model Fitting}} \\
\mathbf{OLS:}\mu=\beta_0+\beta_1x \textrm{ using Least Squares}\\
\mathbf{Poisson Regression:}log(\lambda)=\beta_0+\beta_1x \textrm{ using Maximum Likelihood}\\
\textrm{ } \\
\underline{\textrm{EDA}} \\
\mathbf{OLS:}\textrm{ plot X vs. Y; add line} \\
\mathbf{Poisson Regression:}\textrm{ find }log(\bar{y})\textrm{ for several subgroups; plot vs. X} \\
\textrm{ } \\
\underline{\textrm{Comparing Models}} \\
\mathbf{OLS:}\textrm{ extra sum of squares F-tests; AIC/BIC} \\
\mathbf{Poisson Regression:}\textrm{ Drop in Deviance tests; AIC/BIC} \\
\textrm{ } \\
\underline{\textrm{Interpreting Coefficients}} \\
\mathbf{OLS:}\beta_1=\textrm{ change in }\mu_y\textrm{ for unit change in X} \\
\mathbf{Poisson Regression:}e^{\beta_1}=\textrm{ percent change in }\lambda\textrm{ for unit change in X} 
\]</span></p>
</div>
<div id="optional-topics-to-be-developed" class="section level3">
<h3><span class="header-section-number">4.7.12</span> Optional topics to be developed</h3>
<ul>
<li>Plots of predicted values by groups</li>
<li>Robust Standard Errors</li>
</ul>
</div>
</div>
<div id="case-study-campus-crime" class="section level2">
<h2><span class="header-section-number">4.8</span> Case Study: Campus Crime</h2>
</div>
<div id="analysis-for-crime-data" class="section level2">
<h2><span class="header-section-number">4.9</span> Analysis for crime data</h2>
<p>Students like to feel safe and secure when attending a college or university. In response to legislation, the US Department of Education seeks to provide data and reassurances to students and parents alike. All postsecondary institutions that participate in federal student aid programs are required by the Jeanne Clery Disclosure of Campus Security Policy and Campus Crime Statistics Act and the Higher Education Opportunity Act to collect and report data on crime occurring on campus to the Department of Education. In turn, this data is publicly available on the website of the Office of Postsecondary Education.</p>
<div id="research-question-1" class="section level3">
<h3><span class="header-section-number">4.9.1</span> Research Question</h3>
<p>Are there regional differences in violent crime on campus controlling for differences in the type of school?</p>
</div>
<div id="data-organization-2" class="section level3">
<h3><span class="header-section-number">4.9.2</span> Data Organization</h3>
<p>Each row of this data set contains crime information from a post secondary institution, either a college or university. The variables include:</p>
<ul>
<li><code>type</code> = college (C) or university (U)</li>
<li><code>region</code> = region of the country (C = Central, MW = Midwest, NE = Northeast, SE = Southeast, SW = Southwest, and W = West)</li>
<li><code>nv</code> = the number of violent crimes for that institution for the given year</li>
<li><code>Enrollment</code> = enrollment at the school</li>
<li><code>enroll1000</code> = enrollment at the school, in thousands (to obviate problems with computing)</li>
<li><code>nvrate</code> = number of violent crimes per 1000 students</li>
</ul>
<pre><code>   Enrollment type nv     nvrate enroll1000 region
1        5590    U 30 5.36672630      5.590     SE
2         540    C  0 0.00000000      0.540     SE
3       35747    U 23 0.64341064     35.747      W
4       28176    C  1 0.03549120     28.176      W
5       10568    U  1 0.09462528     10.568     SW
6        3127    U  0 0.00000000      3.127     SW
7       20675    U  7 0.33857316     20.675      W
8       12548    C  0 0.00000000     12.548      W
9       30063    U 19 0.63200612     30.063      C
10       4429    C  4 0.90313841      4.429      C</code></pre>
</div>
<div id="exploratory-data-analysis-1" class="section level3">
<h3><span class="header-section-number">4.9.3</span> Exploratory Data Analysis</h3>
<div class="figure" style="text-align: center"><span id="fig:nviolent"></span>
<img src="bookdown-bysh_files/figure-html/nviolent-1.png" alt="Histogram of number of violent crimes by institution" width="60%" />
<p class="caption">
Figure 4.5: Histogram of number of violent crimes by institution
</p>
</div>
<p>A graph of the number of violent crimes, Figure <a href="ch-poissonreg.html#fig:nviolent">4.5</a> reveals the pattern often found with distributions of counts of rare events. Many schools reported no violent crimes or very few crimes. A few schools have a large number of crimes making for a distribution that appears to be far from normal. A Poisson regression may be helpful here.</p>
<p>Let’s take a look at the covariates of interest for these schools, type of institution and region. In our data, the majority of institutions are universities, 65% of the 81 schools, only 35% are colleges. Interest centers on whether the different regions tend to have different crime rates. Table <a href="ch-poissonreg.html#tab:regions">4.2</a> contains the name of each region and the percentages of the number of schools from that region by institution type in the data set. Each column represents the percentage of schools in that region which are colleges or universities.</p>
<table>
<caption><span id="tab:regions">Table 4.2: </span>Proportion of colleges and universities within region in the campus crime data set</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">C</th>
<th align="right">MW</th>
<th align="right">NE</th>
<th align="right">SE</th>
<th align="right">SW</th>
<th align="right">W</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>C</td>
<td align="right">0.294</td>
<td align="right">0.3</td>
<td align="right">0.381</td>
<td align="right">0.4</td>
<td align="right">0.2</td>
<td align="right">0.5</td>
</tr>
<tr class="even">
<td>U</td>
<td align="right">0.706</td>
<td align="right">0.7</td>
<td align="right">0.619</td>
<td align="right">0.6</td>
<td align="right">0.8</td>
<td align="right">0.5</td>
</tr>
</tbody>
</table>
<p>A Poisson regression model is likely to be useful because the responses are counts per thousand students. It is important to note that the counts are not directly comparable because they come from different size schools. We cannot compare the 30 violent crimes from the first school in the data set to no violent crimes for the second school when their enrollments are vastly different; 5,590 for school 1 versus 540 for school 2. We take the differences in enrollments into account by including an <strong>offset</strong> in our model which we will discuss when we get to modeling. For the remainder of the EDA, we examine the violent crime counts in terms of the rate per 1,000 enrolled, that is the (number of violent crimes)/(number enrolled) *1,000.</p>
<p>There is a noticeable outlier for a Southeastern school (5.4 violent crimes per 1000 students), and there is an observed rate of 0 for the Southwestern colleges which can lead to some computational issues. Therefore, we combine the SW and SE to form a single category of the South, and we also remove the extreme observation from the data set. The table and boxplot below display mean violent crime rates that are generally lower rates at the colleges with the exception of the Northeast. In addition, the regional pattern of rates at universities appears to differ from that of the colleges.</p>
<table>
<caption><span id="tab:table4ch4">Table 4.3: </span>The mean and variance of the violent crime rate by region and type of institution</caption>
<thead>
<tr class="header">
<th align="left">region</th>
<th align="left">type</th>
<th align="right">MeanCount</th>
<th align="right">VarCount</th>
<th align="right">MeanRate</th>
<th align="right">VarRate</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">C</td>
<td align="left">C</td>
<td align="right">1.6000000</td>
<td align="right">3.3000000</td>
<td align="right">0.3979518</td>
<td align="right">0.2780913</td>
<td align="right">5</td>
</tr>
<tr class="even">
<td align="left">C</td>
<td align="left">U</td>
<td align="right">4.7500000</td>
<td align="right">30.9318182</td>
<td align="right">0.2219441</td>
<td align="right">0.0349266</td>
<td align="right">12</td>
</tr>
<tr class="odd">
<td align="left">MW</td>
<td align="left">C</td>
<td align="right">0.3333333</td>
<td align="right">0.3333333</td>
<td align="right">0.0162633</td>
<td align="right">0.0007935</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">MW</td>
<td align="left">U</td>
<td align="right">8.7142857</td>
<td align="right">30.9047619</td>
<td align="right">0.4019003</td>
<td align="right">0.0620748</td>
<td align="right">7</td>
</tr>
<tr class="odd">
<td align="left">NE</td>
<td align="left">C</td>
<td align="right">6.0000000</td>
<td align="right">32.8571429</td>
<td align="right">1.1249885</td>
<td align="right">1.1821000</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="left">NE</td>
<td align="left">U</td>
<td align="right">5.9230769</td>
<td align="right">79.2435897</td>
<td align="right">0.4359273</td>
<td align="right">0.3850333</td>
<td align="right">13</td>
</tr>
<tr class="odd">
<td align="left">S</td>
<td align="left">C</td>
<td align="right">1.1250000</td>
<td align="right">5.8392857</td>
<td align="right">0.1865996</td>
<td align="right">0.1047178</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="left">S</td>
<td align="left">U</td>
<td align="right">8.6250000</td>
<td align="right">68.2500000</td>
<td align="right">0.5713162</td>
<td align="right">0.2778065</td>
<td align="right">16</td>
</tr>
<tr class="odd">
<td align="left">W</td>
<td align="left">C</td>
<td align="right">0.5000000</td>
<td align="right">0.3333333</td>
<td align="right">0.0680164</td>
<td align="right">0.0129074</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="left">W</td>
<td align="left">U</td>
<td align="right">12.5000000</td>
<td align="right">57.0000000</td>
<td align="right">0.4679478</td>
<td align="right">0.0246670</td>
<td align="right">4</td>
</tr>
</tbody>
</table>
<div class="figure" style="text-align: center"><span id="fig:boxtyperegion"></span>
<img src="bookdown-bysh_files/figure-html/boxtyperegion-1.png" alt="." width="60%" />
<p class="caption">
Figure 4.6: .
</p>
</div>
</div>
<div id="accounting-for-enrollment" class="section level3">
<h3><span class="header-section-number">4.9.4</span> Accounting for Enrollment</h3>
<p>Although working with the observed rates is useful during the exploratory data analysis, it is not the rates that go into the model; the counts are the responses when modeling. So we must take into account the enrollment in another way. Our approach is to include a term on the right side of the model called an <strong>offset</strong> which equals the log of the enrollment, in thousands. If we were using a Poisson regression to model the average count per 1,000, <span class="math inline">\(\lambda\)</span>, for schools which all had the same enrollment, it may look like: <span class="math display">\[
log(\lambda) = \beta_0 + \beta_1(\textrm{SchoolType})
\]</span> This model doesn’t account for the enrollment, so we’ll add the offset to the right side. <span class="math display">\[
log(\lambda) = \beta_0 + \beta_1(\textrm{SchoolType})+ log(\textrm{enroll1000})
\]</span> The offset has the unusual feature that the coefficient is fixed at 1.0. No estimated coefficient for <code>enroll1000</code> will appear on the output. There is an intuitive heuristic for the form of the offset. If we think of <span class="math inline">\(\lambda\)</span> as the rate per 1,000 and then subtract log(<code>enroll1000</code>) from each side, the count associated with a particular enrollment will be adjusted to be comparable to all of the other counts in the data set.</p>
<span class="math display">\[\begin{eqnarray} \nonumber
log(\lambda)-log(\textrm{enroll1000}) = \beta_0 + \beta_1(\textrm{type})\\ \nonumber
log(\frac{\lambda}{\textrm{enroll1000}} )= \beta_0 + \beta_1(\textrm{type})
\end{eqnarray}\]</span>
<p>While this heuristic is helpful, it is important to note that it is <em>not</em> <span class="math inline">\(\lambda / \textrm{enroll1000}\)</span> that we are modeling.</p>
</div>
</div>
<div id="checking-assumptions" class="section level2">
<h2><span class="header-section-number">4.10</span> Checking Assumptions</h2>
<div id="is-the-mean-equal-to-the-variance" class="section level3">
<h3><span class="header-section-number">4.10.1</span> Is the Mean equal to the Variance?</h3>
<p>The mean of a Poisson random variable is also its variance. Consequently we should find that the mean count is approximately equal to its variance for combinations of our covariates. In Table <a href="ch-poissonreg.html#tab:table4ch4">4.3</a>, we see that the variances are greatly higher than the mean counts in almost every group. Thus, we have reason to question this assumption and will have to return to this issue after some initial modeling. The fact that the variance of the rate of violent crimes per 1000 students tends to be on the same scale as the mean tells us that adjusting for enrollment may provide some help, although that may not completely solve our issues with excessive variance.</p>
<p>The remaining assumption is the independence of the observations. In this case, it is not possible to assess independence without knowing how the schools were selected.</p>
</div>
</div>
<div id="modeling-1" class="section level2">
<h2><span class="header-section-number">4.11</span> Modeling</h2>
<p>We are interested primarily in differences in violent crime between institutional types controlling for difference in regions, so we fit a model with both region and type including log(<code>enroll1000</code>) as an offset.</p>
<pre><code>glm(formula = nv ~ type + region, family = poisson, data = c.data, 
    offset = log(enroll1000))

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.54780    0.17114  -9.044  &lt; 2e-16 ***
typeU        0.27956    0.13314   2.100   0.0358 *  
regionMW     0.09912    0.17752   0.558   0.5766    
regionNE     0.77813    0.15307   5.084 3.70e-07 ***
regionS      0.58238    0.14896   3.910 9.24e-05 ***
regionW      0.26275    0.18753   1.401   0.1612    
---
(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 392.76  on 79  degrees of freedom
Residual deviance: 348.68  on 74  degrees of freedom
AIC: 573.32</code></pre>
<p>The Region coefficients each compare the mean rate for that region to the Central region. According to the p-values, the Northeast and the South differ significantly from the Central region. The estimated coefficient of 0.77813 translates to the violent crime rate per 1,000 in the Northeast being nearly 2.2 times that of the Central region controlling for the type of school. A confidence interval for this factor can be constructed by first calculating a CI for the coefficient (0.77813 <span class="math inline">\(\pm\)</span> 1.96*0.15314) and then exponentiating. A 95% CI ranges from 1.61 to 2.94. Comparisons to regions other than the Central region can be accomplished by changing the reference region. If many comparisons are made, it would be best to use a multiple comparisons method such as Bonferroni’s, where the p-value is divided by the number of comparisons to be made, or Tukey’s Honestly Significant Differences described elsewhere.</p>
<pre><code>Multiple Comparisons of Means: Tukey Contrasts

Linear Hypotheses:
             Estimate Std. Error z value Pr(&gt;|z|)    
MW - C == 0   0.09912    0.17752   0.558   0.9804    
NE - C == 0   0.77813    0.15307   5.084   &lt;0.001 ***
S - C == 0    0.58238    0.14896   3.910   &lt;0.001 ***
W - C == 0    0.26275    0.18753   1.401   0.6209    
NE - MW == 0  0.67901    0.15545   4.368   &lt;0.001 ***
S - MW == 0   0.48327    0.15143   3.191   0.0120 *  
W - MW == 0   0.16364    0.18942   0.864   0.9079    
S - NE == 0  -0.19574    0.12182  -1.607   0.4863    
W - NE == 0  -0.51537    0.16587  -3.107   0.0157 *  
W - S == 0   -0.31963    0.16296  -1.961   0.2795    
---
(Adjusted p values reported -- single-step method)</code></pre>
<p>With Tukey’s Honestly Significant Differences, we find that the Northeast differs significantly from the Central, Midwest, and Western regions while the South differs significantly from the Central and the Midwest controlling for the type of institution. An indicator of the type of institution is also included in the model. The University indicator is significant and after exponentiating the coefficient can be interpreted as an approximately (<span class="math inline">\(e^{0.27956}\)</span>) 32% increase in violent crime rate over Colleges after controlling for region.</p>
<p>These results certainly suggests significant differences in regions and type of institution. However, the EDA findings suggest the effect of the type of institution may vary depending upon the region, so we consider a model with an interaction between region and type.</p>
<pre><code>glm(formula = nv ~ type + region + region:type, family = poisson, 
    data = c.data, offset = log(enroll1000))

Coefficients:
               Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)     -1.4741     0.3536  -4.169 3.05e-05 ***
typeU            0.1959     0.3775   0.519  0.60377    
regionMW        -1.9765     1.0607  -1.863  0.06239 .  
regionNE         1.5529     0.3819   4.066 4.77e-05 ***
regionS         -0.1562     0.4859  -0.322  0.74779    
regionW         -1.8337     0.7906  -2.319  0.02037 *  
typeU:regionMW   2.1965     1.0765   2.040  0.04132 *  
typeU:regionNE  -1.0698     0.4200  -2.547  0.01086 *  
typeU:regionS    0.8121     0.5108   1.590  0.11185    
typeU:regionW    2.4106     0.8140   2.962  0.00306 ** 
---
(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 392.76  on 79  degrees of freedom
Residual deviance: 276.70  on 70  degrees of freedom
AIC: 509.33</code></pre>
<p>These results provide convincing evidence of an interaction between the effect of region and the type of institution. A drop-in-deviance test like the one we carried out in the previous section confirms the significance of the contribution of the interaction to this model. We have statistically significant evidence (<span class="math inline">\(\chi^2=71.98, p&lt;.001\)</span>) that the difference between colleges and universities in violent crime rate differs by region. For example, our model estimates that violent crime rates are 13.6 (<span class="math inline">\(e^{.1959+2.4106}\)</span>) times higher in universities in the West compared to colleges, while in the Northest we estimate that violent crime rates are 2.4 (<span class="math inline">\(1/e^{.1959-1.0698}\)</span>) times higher in colleges.</p>
<pre><code>Analysis of Deviance Table

Model 1: nv ~ type + region
Model 2: nv ~ type + region + region:type
  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
1        74     348.68                          
2        70     276.70  4   71.981 8.664e-15 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The residual deviance (276.70 with 70 df) suggests that the interaction model does not fit well. One possibility is that there are other important covariates that could be used to describe the differences in the violent crime rates. Without additional covariates to consider, we look for extreme observations, but we have already eliminated the most extreme of the observations.</p>
<p>In the absence of other covariates or extreme observations, we consider overdispersion as a possible explanation of the significant lack-of-fit.</p>
</div>
<div id="sec-overdispPois" class="section level2">
<h2><span class="header-section-number">4.12</span> Overdispersion</h2>
<div id="dispersion-parameter-adjustment" class="section level3">
<h3><span class="header-section-number">4.12.1</span> Dispersion parameter adjustment</h3>
<p><strong>Overdispersion</strong> suggests that there is more variation in the response than the model implies. Under a Poisson model, we would expect the means and variances of the response to be about the same in various groups. Without adjusting for overdispersion, we use incorrect, artifically small standard errors and/or end up with overly complex models.</p>
<p>We can take overdispersion into account in several different ways. The simplest is to use an estimated dispersion factor to inflate standard errors. Another way is to use a negative-binomial regression model. We begin with using the estimate of the dispersion parameter.</p>
<p>We can estimate a dispersion parameter, <span class="math inline">\(\phi\)</span>, by dividing the model deviance by its corresponding degrees of freedom; i.e., <span class="math inline">\(\hat\phi=\frac{\sum(\textrm{Pearson residuals})^2}{n-p}\)</span> where <span class="math inline">\(p\)</span> is the number of model parameters. It follows from what we know about the <span class="math inline">\(\chi^2\)</span> distribution that if there is no overdispersion, this estimate should be close to one. It will be larger than one in the presence of overdispersion. We inflate the standard errors by multiplying the variance by <span class="math inline">\(\phi\)</span> so that the standard errors are larger than the likelihood approach would imply; i.e., <span class="math inline">\(SE_Q(\hat\beta)=\sqrt{\hat\phi}*SE(\hat\beta)\)</span>. If we choose to use a dispersion parameter with our model, we refer to the approach as quasilikelihood. The following output illustrates a quasipoisson approach to our most recent model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Assessing the goodness of fit of the interaction model </span>
gof &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">-</span><span class="kw">pchisq</span>(modeli<span class="op">$</span>deviance, modeli<span class="op">$</span>df.residual)
gof </code></pre></div>
<pre><code>[1] 0</code></pre>
<pre><code>glm(formula = nv ~ type + region + region:type, family = quasipoisson, 
    data = c.data, offset = log(enroll1000))

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept)     -1.4741     0.7455  -1.977   0.0520 .
typeU            0.1959     0.7961   0.246   0.8063  
regionMW        -1.9765     2.2366  -0.884   0.3799  
regionNE         1.5529     0.8053   1.928   0.0579 .
regionS         -0.1562     1.0246  -0.152   0.8792  
regionW         -1.8337     1.6671  -1.100   0.2751  
typeU:regionMW   2.1965     2.2701   0.968   0.3366  
typeU:regionNE  -1.0698     0.8856  -1.208   0.2311  
typeU:regionS    0.8121     1.0771   0.754   0.4534  
typeU:regionW    2.4106     1.7164   1.404   0.1646  
---
(Dispersion parameter for quasipoisson family taken to be 4.446556)

    Null deviance: 392.76  on 79  degrees of freedom
Residual deviance: 276.70  on 70  degrees of freedom
AIC: NA</code></pre>
<p>In the absence of overdispersion, we expect the dispersion parameter estimate to be 1.0. The estimated dispersion parameter here is much larger than 1.0 (4.447) indicating overdispersion (extra variance) that should be accounted for. The larger estimated standard errors in the quasipoisson model reflect the adjustment. For example, the standard error for the West region term from a likelihood based approach is 0.7906, whereas the quasilikelihood standard error is <span class="math inline">\(\sqrt{4.47}*0.7906\)</span> or 1.6671. This term is no longer significant under the quasipoisson model. In fact, after adjusting for overdispersion (extra variation), none of the model coefficients in the quasipoisson model are significant at the .05 level! This is because standard errors were all increased by a factor of 2.1 (<span class="math inline">\(\sqrt{\hat\phi}=\sqrt{4.447}=2.1\)</span>).</p>
<p>Note that tests for individual parameters are now based on the t-distribution rather than a standard normal distribution, with test statistic <span class="math inline">\(t=\frac{\hat\beta}{SE_Q(\hat\beta)}\)</span> following an (approximate) t-distribution with <span class="math inline">\(n-p\)</span> degrees of freedom if the null hypothesis is true. Drop-in-deviance tests can be similarly adjusted for overdispersion in the quasipoisson model. In this case, you can divide the test statistic by the estimated dispersion parameter and compare the result to an F-distribution with the difference in the model degrees of freedom for the numerator and the degrees of freedom for the larger model in the denominator. That is, <span class="math inline">\(F=\frac{\textrm{drop in deviance}}{\hat\phi}\)</span> follows an (approximate) F-distribution when the null hypothesis is true. The output below then tests for an interaction between region and type of institution after adjusting for overdispersion (extra variance):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">phi &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">resid</span>(modeli, <span class="dt">type=</span><span class="st">&#39;pearson&#39;</span>)<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>modeli<span class="op">$</span>df.residual
drop.in.dev &lt;-<span class="st"> </span>modeltr<span class="op">$</span>deviance <span class="op">-</span><span class="st"> </span>modeli<span class="op">$</span>deviance
diff.in.df &lt;-<span class="st"> </span>modeltr<span class="op">$</span>df.residual <span class="op">-</span><span class="st"> </span>modeli<span class="op">$</span>df.residual
Fstat &lt;-<span class="st"> </span>drop.in.dev <span class="op">/</span><span class="st"> </span><span class="kw">summary</span>(modeliq)<span class="op">$</span>dispersion
Fstat</code></pre></div>
<pre><code>[1] 16.18795</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span><span class="op">-</span><span class="kw">pf</span>(Fstat, diff.in.df, modeli<span class="op">$</span>df.residual)</code></pre></div>
<pre><code>[1] 1.975114e-09</code></pre>
<p>Here, even after adjusting for overdispersion, we still have statistically significant evidence (<span class="math inline">\(F=16.19, p&lt;.001\)</span>) that the difference between colleges and universities in violent crime rate differs by region.</p>
<p align="center">
<strong>Summary: Accounting for Overdispersion</strong>
</p>
<ul>
<li>Use the dispersion parameter <span class="math inline">\(\hat\phi=\frac{\sum(\textrm{Pearson residuals})^2}{n-p}\)</span> to inflate standard errors of model coefficients</li>
<li>Wald test statistics: multiply the standard errors by <span class="math inline">\(\sqrt{\hat{\phi}}\)</span> so that <span class="math inline">\(SE_Q(\hat\beta)=\sqrt{\hat\phi}*SE(\hat\beta)\)</span> and conduct tests using the t-distribution</li>
<li>CIs which use the adjusted standard errors and are thereby wider <span class="math inline">\(\hat\beta \pm t_{n-p}*SE_Q(\hat\beta)\)</span></li>
<li>Drop-in-deviance test statistic comparing Model 1 (larger model with <span class="math inline">\(p\)</span> parameters) to Model 2 (smaller model with <span class="math inline">\(q&lt;p\)</span> parameters) =
<span class="math display" id="eq:drop12">\[\begin{equation}
 F=\frac{1}{\hat\phi} \frac{D_2 - D_1}{p-q}
 \tag{4.8}
 \end{equation}\]</span>
where <span class="math inline">\(D_1\)</span> and <span class="math inline">\(D_2\)</span> are the residual deviances for models 1 and 2 respectively and <span class="math inline">\(p-q\)</span> is the difference in the number of parameters for the two models. Note that both <span class="math inline">\(D_2-D_1\)</span> and <span class="math inline">\(p-q\)</span> are positive. This test statistic is compared to an F-distribution with <span class="math inline">\(p-q\)</span> and <span class="math inline">\((n-p)\)</span> degrees of freedom.</li>
</ul>
<p>Note that it was important to obtain the correct model prior to considering adjustment for overdispersion.</p>
</div>
<div id="negative-binomial-modeling" class="section level3">
<h3><span class="header-section-number">4.12.2</span> Negative binomial modeling</h3>
<p>Another approach to dealing with overdispersion is to model the response using a negative binomial instead of Poisson. An advantage of this approach is that it introduces another parameter in addition to <span class="math inline">\(\lambda\)</span> which gives the model a little more flexibility and, as opposed to the quasipoisson model, the negative binomial model assumes an explicit likelihood model. You may recall that negative binomial random variables take on nonnegative integer values which is consistent with modeling counts. This model posits selecting a <span class="math inline">\(\lambda\)</span> for each institution and then generating a count using a Poisson random variable with the selected <span class="math inline">\(\lambda\)</span>. With this approach, the counts will be more dispersed than would be expected for observations based on a single Poisson variable with rate <span class="math inline">\(\lambda\)</span>.</p>
<p>Mathematically, you can think of the negative binomial model as a Poisson model where <span class="math inline">\(\lambda\)</span> is also random, following a gamma distribution. Specifically, if <span class="math inline">\(Y|\lambda \textrm{~ Poisson}(\lambda)\)</span> and <span class="math inline">\(\lambda \textrm{~ gamma}(\theta,\frac{1-p}{p})\)</span>, then <span class="math inline">\(Y \textrm{~ NegBinom}(\theta,p)\)</span> where <span class="math inline">\(E(Y)=\frac{p\theta}{1-p}=\mu\)</span> and <span class="math inline">\(Var(Y)=\frac{p\theta}{(1-p)^2}=\mu+\frac{\mu^2}{\theta}\)</span>. The overdispersion in this case is given by <span class="math inline">\(\frac{\mu^2}{\theta}\)</span>, which approaches 0 as <span class="math inline">\(\theta\)</span> increases (so smaller values of <span class="math inline">\(\theta\)</span> indicate greater overdispersion).</p>
<p>Here is what happens if we apply the negative binomial model to the interaction model, which we’ve already established suffers from overdispersion issues under regular Poisson regression:</p>
<pre><code>glm.nb(formula = nv ~ type + region + region:type, data = c.data2, 
    weights = offset(log(enroll1000)), init.theta = 1.312886384, 
    link = log)

Coefficients:
               Estimate Std. Error z value Pr(&gt;|z|)   
(Intercept)      0.4904     0.4281   1.145  0.25201   
typeU            1.2174     0.4608   2.642  0.00824 **
regionMW        -1.0953     0.8075  -1.356  0.17500   
regionNE         1.3966     0.5053   2.764  0.00571 **
regionS          0.1461     0.5559   0.263  0.79275   
regionW         -1.1858     0.6870  -1.726  0.08435 . 
typeU:regionMW   1.6342     0.8498   1.923  0.05447 . 
typeU:regionNE  -1.1259     0.5601  -2.010  0.04441 * 
typeU:regionS    0.4513     0.5995   0.753  0.45164   
typeU:regionW    2.0387     0.7527   2.709  0.00676 **
---
(Dispersion parameter for Negative Binomial(1.3129) family taken to be 1)

    Null deviance: 282.43  on 78  degrees of freedom
Residual deviance: 199.57  on 69  degrees of freedom</code></pre>
<p>These results differ from the quasipoisson model. Several effects are now statistically significant at the .05 level: the effect of type of institution for the Central region (<span class="math inline">\(Z=2.64, p=.008\)</span>), the difference between Northeast and Central regions for colleges (<span class="math inline">\(Z=2.76, p=.006\)</span>), the difference between Northeast and Central regions in type effect (<span class="math inline">\(Z=-2.01, p=.044\)</span>), and the difference between West and Central regions in type effect (<span class="math inline">\(Z=2.71, p=.007\)</span>). Compared to the quasipoisson model, negative binomial coefficient estimates are generally in the same direction and similar in size, but negative binomial standard errors are smaller.</p>
<p>In summary, we explored the possibility of regional differences in the violent crime rate controlling for the type of institution (or vice versa). Our initial efforts seemed to suggest that there are indeed regional differences and the pattern of those differences depend upon the type of institution. However, this model exhibited significant lack-of-fit which remained after the removal of an extreme observation. In the absence of additional covariates, we accounted for the lack-of-fit by using a quasilikelihood approach and a negative binomial regression, which provided slightly different conclusions. We may want to look for additional covariates and or more data.</p>
</div>
</div>
<div id="case-study-weekend-drinking-csdrinking" class="section level2">
<h2><span class="header-section-number">4.13</span> Case Study: Weekend drinking {cs:drinking}</h2>
<p>Sometimes when analyzing Poisson data, you may see many more zeros in your data set than you would expect for a Poisson random variable. For example, an informal survey of students in an introductory statistics course included the question, “How many alcoholic drinks did you consume last weekend?” This survey was conducted on a dry campus where no alcohol is officially allowed, even among students of drinking age, so we expect that some portion of the respondents never drink. The non-drinkers would thus always report zero drinks. However, there will also be students who are drinkers reporting zero drinks because they just did not happen to drink during the past weekend. Our zeros, then, are a mixture of responses from non-drinkers and drinkers who abstained. Ideally, we’d like to sort out the non-drinkers and drinkers when performing our analysis.</p>
<div id="research-question-2" class="section level3">
<h3><span class="header-section-number">4.13.1</span> Research Question</h3>
<p>The purpose of this survey is to explore factors related to drinking behavior on a dry campus. What proportion of students on this dry campus never drink? What factors, such as off campus living and sex, are related to whether students drink? Among those who do drink, to what extent is moving off campus associated with the number of drinks in a weekend? It is commonly assumed that males’ alcohol consumption is greater than females’; is this true on this campus? Answering these questions would be a simple matter if we knew who was and was not a drinker in our sample. Unfortunately, the non-drinkers did not identify themselves as such, so we will need to use the data available with a model that allows us to estimate the proportion of drinkers and non-drinkers.</p>
</div>
<div id="data-organization-3" class="section level3">
<h3><span class="header-section-number">4.13.2</span> Data Organization</h3>
<p>Each line of this file contains data provided by a student in an introductory statistics course. In this analysis, the response of interest is the respondent’s report of the number of alcoholic <code>drinks</code> they consumed the previous weekend, whether the student lives <code>off.campus</code>, and <code>sex</code>. We will also consider whether a student is likely a <code>firstYear</code> student based on the <code>dorm</code> he or she lives in. Here is a sample of observations from this dataset:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(zip.data[<span class="dv">2</span><span class="op">:</span><span class="dv">4</span>])</code></pre></div>
<pre><code>  drinks sex off.campus
1      0   f          0
2      5   f          0
3     10   m          0
4      0   f          0
5      0   m          0
6      3   f          0</code></pre>
</div>
<div id="exploratory-data-analysis-2" class="section level3">
<h3><span class="header-section-number">4.13.3</span> Exploratory Data Analysis</h3>
<p>As always we take stock of the amount of data; here there are 77 observations. Large sample sizes are preferred for the type of model we consider, and n=77 is on the small side. We proceed with that in mind.</p>
<p>A premise of this analysis is that we believe that those responding zero drinks are coming from a mixture of non-drinkers and drinkers who abstained the weekend of the survey.</p>
<ul>
<li><strong>Non-drinkers</strong>: respondents who never drink and would always reply with zero</li>
<li><strong>Drinkers</strong>: obviously this includes those responding with one or more drinks, but it also includes people who are drinkers but did not happen to imbibe the past weekend. These people reply zero but are not considered non-drinkers.</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:obsVmodel"></span>
<img src="bookdown-bysh_files/figure-html/obsVmodel-1.png" alt="Observed (a) versus Modeled (b) Number of Drinks" width="60%" />
<p class="caption">
Figure 4.7: Observed (a) versus Modeled (b) Number of Drinks
</p>
</div>
<p>Beginning the EDA with the response, number of drinks, we find that over 46% of the students reported no drinks during the past weekend. Figure <a href="ch-poissonreg.html#fig:obsVmodel">4.7</a>a portrays the observed number of drinks reported by the students. The mean number of drinks reported the past weekend is 2.013. Our sample consists of 74% females and 26% males, only 9% of whom live off campus.</p>
<p>Because our response is a count it is natural to consider a Poisson regression model. You may recall that a Poisson distribution has only one parameter, <span class="math inline">\(\lambda\)</span>, for its mean and variance. Here we will include an additional parameter, <span class="math inline">\(\alpha\)</span>. We define <span class="math inline">\(\alpha\)</span> to be the true proportion of non-drinkers in the population.</p>
<p>The next step in the EDA is especially helpful if you suspect your data contains excess zeros. Figure <a href="ch-poissonreg.html#fig:obsVmodel">4.7</a>b is what we might expect to see under a Poisson model. Bars represent the probabilities for a Poisson distribution (using the Poisson probability formula) with <span class="math inline">\(\lambda\)</span> equal to the mean observed number of drinks, 2.013 drinks per weekend. Comparing this Poisson distribution to what we observed (Figure <a href="ch-poissonreg.html#fig:obsVmodel">4.7</a>a), it is clear that many more zeros have been reported by the students than you would expect to see if the survey observations were coming from a Poisson distribution. This doesn’t surprise us because we had expected a subset of the survey respondents to be non-drinkers; i.e., they would not be included in this Poisson process. This circumstance actually arises in many Poisson regression settings. We can model both <span class="math inline">\(\lambda\)</span>, the mean number of drinks among those who drink, and <span class="math inline">\(\alpha\)</span>, the proportion of non-drinkers (“true zeros”), as well as determine the effects of covariates like sex and off-campus residence on both parameters. This type of model is referred to as a <strong>zero-inflated Poisson model</strong> or <strong>ZIP model</strong>.</p>
</div>
<div id="modeling-2" class="section level3">
<h3><span class="header-section-number">4.13.4</span> Modeling</h3>
<p>We first fit a simple Poisson model with the covariates <code>off.campus</code> and <code>sex</code>.</p>
<pre><code>glm(formula = drinks ~ off.campus + sex, family = poisson, data = zip.data)

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   0.1293     0.1241   1.041    0.298    
off.campus    0.8976     0.2008   4.470 7.83e-06 ***
sexm          1.1154     0.1611   6.925 4.36e-12 ***
---
(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 294.54  on 76  degrees of freedom
Residual deviance: 230.54  on 74  degrees of freedom
AIC: 357.09</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Exponentiated coefficients</span>
<span class="kw">exp</span>(<span class="kw">coef</span>(pois.m1))</code></pre></div>
<pre><code>## (Intercept)  off.campus        sexm 
##    1.137996    2.453819    3.050707</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Goodness-of-fit test</span>
gof.ts =<span class="st"> </span>pois.m1<span class="op">$</span>deviance
gof.pvalue =<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(gof.ts, pois.m1<span class="op">$</span>df.residual)
gof.pvalue</code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>Both covariates are statistically significant, but a goodness-of-fit test reveals that there remains significant lack-of-fit (residual deviance: 230.54 with only 74 df; p&lt;.001 based on <span class="math inline">\(\chi^2\)</span> test with 74 df). In the absence of important missing covariates or extreme observations, this lack-of-fit may be explained by the presence of a group of non-drinkers.</p>
<p>A zero-inflated Poisson regression model to take non-drinkers into account consists of two parts:</p>
<ul>
<li>One part models the association among drinkers of the number of drinks with predictors sex and off campus residence.</li>
<li>The other part uses the predictors for sex and off campus residence to obtain an estimate of the proportion of non-drinkers based on the reported zeros.</li>
</ul>
<p>The form for each part of the model follows. The first part looks like an ordinary Poisson regression model: <span class="math display">\[
log(\lambda)=\beta_0+\beta_1(\textrm{off.campus})+ \beta_2(\textrm{sex})
\]</span> where <span class="math inline">\(\lambda\)</span> is the mean number of drinks in a weekend <em>among those who drink</em>. The second part has the form <span class="math display">\[
logit(\alpha)=\beta_0+\beta_1(\textrm{firstYear}))
\]</span> where <span class="math inline">\(\alpha\)</span> is the probability of being in the non-drinkers group and <span class="math inline">\(logit(\alpha) = log( \alpha/(1-\alpha))\)</span>. We’ll provide more detail on the logit in the Logistic Regression chapter. There are many ways in which to structure this model; here we use different predictors in the two pieces, athough it would have been perfectly fine to use the same predictors for both pieces, or even no predictors for one of the pieces.</p>
</div>
<div id="fitting-a-zip-model" class="section level3">
<h3><span class="header-section-number">4.13.5</span> Fitting a ZIP Model</h3>
<p>How is it possible to fit such a model? We cannot observe whether a respondent is a drinker or not (which probably would’ve been good to ask). The ZIP model is a special case of a more general type of statistical model referred to as a <strong>latent variable model</strong>. More specifically, it is a type of a <strong>mixture model</strong> where observations for one or more groups occur together and the group membership is unknown. Zero-inflated models are a particularly common example of a mixture model, but the response does not need to follow a Poisson distribution. Likelihood methods are at the core of this methodology, but fitting is an iterative process where it is necessary to start out with some guesses (or starting values). In general, it is important to know that models like ZIP exist, although we’ll only explore interpretations and fitting options for a single case study here.</p>
<p>Here is the general idea of how ZIP models are fit. Imagine that the graph of the Poisson distribution Figure <a href="ch-poissonreg.html#fig:obsVmodel">4.7</a>b is removed from the observed data distribution in Figure <a href="ch-poissonreg.html#fig:obsVmodel">4.7</a>a. Some zero responses will remain. These would correspond to non-drinkers, and the proportion of all observations these zeros constitute might make a reasonable estimate for <span class="math inline">\(\alpha\)</span>, the proportion of non-drinkers. The likelihood is used and some iterating in the fitting process is involved because the Poisson distribution in (Figure <a href="ch-poissonreg.html#fig:obsVmodel">4.7</a>b is based on the mean of the observed data, which means it is the average among all students, not only among drinkers. Furthermore, the likelihood incorporates the predictors, <code>sex</code> and <code>off.campus</code>. So there is a little more to it than computing the proportion of zeros, but this heuristic should provide you a general idea of how these kinds of models are fit. Fortunately, various software packages will fit these kinds of models. For example, the software package <code>R</code> along with the <code>library(pscl)</code> will fit a ZIP model for us using the function <code>zeroinfl</code>.</p>
<pre><code>zeroinfl(formula = drinks ~ off.campus + sex | firstYear, data = zip.data)

Count model coefficients (poisson with log link):
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   0.7543     0.1440   5.238 1.62e-07 ***
off.campus    0.4159     0.2059   2.021   0.0433 *  
sexm          1.0209     0.1752   5.827 5.63e-09 ***

Zero-inflation model coefficients (binomial with logit link):
              Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)    -0.6036     0.3114  -1.938   0.0526 .
firstYearTRUE   1.1364     0.6095   1.864   0.0623 .
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coef</span>(zip.m2))   <span class="co"># exponentiated coefficients</span></code></pre></div>
<pre><code>##  count_(Intercept)   count_off.campus         count_sexm 
##          2.1260689          1.5157979          2.7756924 
##   zero_(Intercept) zero_firstYearTRUE 
##          0.5468312          3.1154949</code></pre>
<p>Our model uses <code>firstYear</code> to distinguish drinkers and non-drinkers (“Zero-inflation model coefficients”) and <code>off.campus</code> and <code>sex</code> to help explain the differences in the number of drinks among drinkers (“Count model coefficients”). Again, we could have used the same covariates for the two pieces of a ZIP model, but neither <code>off.campus</code> or <code>sex</code> proved to be a useful predictor of drinkers vs. non-drinkers.</p>
<p>We’ll first consider the “Count model coefficients,” which provide information on how the sex and off-campus status of a student who is a drinker are related to the number of drinks reported by that student over a weekend. As we have done with previous Poisson regression models, we exponentiate each coefficient for ease of interpretation. Thus, for those who drink, the average number of drinks for males is <span class="math inline">\(e^{1.0209}\)</span> or 2.76 times the number for females (Z = 5.827, p &lt; 0.001) given that you are comparing people who live in comparable settings, i.e., either both on or both off campus. Among drinkers, the mean number of drinks for those living off campus is <span class="math inline">\(e^{0.4159}=1.52\)</span> times that of those living on campus for those of the same sex (Z = 2.021, p = 0.0433).</p>
<p>The “Zero-inflation model coefficients” refer to separating drinkers from non-drinkers. An important consideration is separating drinkers from non-drinkers may be whether this is their first year, where <code>firstYear</code> is a 0/1 indicator variable.</p>
<p>We have <span class="math display">\[ 
log(\alpha/(1-\alpha)) =-0.6036+1.1364(\textrm{firstYear})
 \]</span></p>
<p>However we are interested in <span class="math inline">\(\alpha\)</span>, the proportion of non-drinkers. Exponentiating the coefficient for the first year term for this model yields 3.12. Here it is interpreted as the odds that a first year is a non-drinker is 3.12 times the odds that an upper class student is a non-drinker. Furthermore, with a little algebra (solving the equation with <span class="math inline">\(log(\alpha/(1-\alpha)\)</span>) for <span class="math inline">\(\alpha\)</span>), we have <span class="math display">\[
 \hat{\alpha} =
 \frac{exp^ {-0.6036+1.1364(\textrm{firstYear})}}
 {1+e^{
 -0.6036+1.1364(\textrm{firstYear})
 }
 }.
 \]</span> The estimated chance that a first year student is a non-drinker is <span class="math display">\[
\frac{e^{0.533}}{1+e^{0.533}} = 0.630
\]</span> or 63.0%, while for non-first years, the estimated probability of being a non-drinker in 0.354. If you have seen logistic regression, you’ll recognize that this transformation is what is used to estimate a probability. More on this in the logistic regression chapter.</p>
</div>
<div id="comparing-the-ordinary-poisson-regression-model-to-the-zip-model" class="section level3">
<h3><span class="header-section-number">4.13.6</span> Comparing the ordinary Poisson regression model to the ZIP model</h3>
<p>Moving from ordinary Poisson to zero-inflated Poisson has helped us address additional research questions: What proportion of students are non-drinkers and what factors are associated with whether or not a student is a non-drinker? While a ZIP model seems more faithful to the nature and structure of this data, can we quantitatively show that a zero-inflated Poisson is better than an ordinary Poisson model?</p>
<p>We cannot use the drop-in-deviance test we discussed earlier because these two models are not nested within one another. Vuong (1989) devised a test to make this comparison for the special case of comparing a zero-inflated model and ordinary regression model.</p>
<pre><code>Vuong Non-Nested Hypothesis Test-Statistic: 
(test-statistic is asymptotically distributed N(0,1) under the
 null that the models are indistinguishible)
-------------------------------------------------------------
              Vuong z-statistic             H_A   p-value
Raw                   -2.688691 model2 &gt; model1 0.0035866
AIC-corrected         -2.534095 model2 &gt; model1 0.0056369
BIC-corrected         -2.352922 model2 &gt; model1 0.0093133</code></pre>
<p>Here, we have structured the Vuong Test to compare Model 1: Ordinary Poisson Model to Model 2: Zero-inflation Model. If the two models do not differ, the test statistic for Vuong would be asymptotically standard Normal and the p-value would be relatively large. Here the first line of the output table indicates that the zero-inflation model is better (<span class="math inline">\(Z=-2.69,p=.0036\)</span>). Note that the test depends upon sufficiently large n for the Normal approximation, so since our sample size (n=77) is somewhat small, we need to interpret this result with caution. More research is underway to address statistical issues related to these comparisons.</p>
</div>
<div id="residual-plot-1" class="section level3">
<h3><span class="header-section-number">4.13.7</span> Residual Plot</h3>
<p>Fitted values (<span class="math inline">\(\hat{y}\)</span>) and residuals (<span class="math inline">\(y-\hat{y}\)</span>) can be computed for zero-inflation models and plotted. Figure <a href="ch-poissonreg.html#fig:poisRes">4.8</a> reveals that one observation appears to be extreme (Y=22 drinks during the past weekend). Is this a legitimate observation or was there a transcribing error? Without the original respondents we cannot settle this question. It might be worthwhile to get a sense of how influential this extreme observation is when fitting the model. Removing Y=22 and refitting the model can provide some idea about this.</p>
<div class="figure" style="text-align: center"><span id="fig:poisRes"></span>
<img src="bookdown-bysh_files/figure-html/poisRes-1.png" alt="Residuals by fitted counts model." width="60%" />
<p class="caption">
Figure 4.8: Residuals by fitted counts model.
</p>
</div>
</div>
<div id="caveats-and-extensions" class="section level3">
<h3><span class="header-section-number">4.13.8</span> Caveats and Extensions</h3>
<p>Given that you have progressed this far in your statistical education, the weekend drinking survey question should raise some red flags. What time period constitutes the “weekend”? Will some students be thinking of only Saturday night while others include Friday night or possibly Sunday evening? What constitutes a drink—a bottle of beer? How many drinks will a respondent report for a bottle of wine? Precise definitions would vastly improve the quality of this data. There is also an issue related to confidentiality. If the data is collected in class, will the teacher be able to identify the respondent? Will respondents worry that a particular response will affect their grade in the class or lead to repercussions on a dry campus?</p>
<p>In addition to these concerns, there are a number of other caveats that should be noted here. Following the concern of whether this data represents a random sample of any population (it doesn’t), we also must be concerned with the size of this data set. ZIP models are not appropriate for small samples and this data set is not impressively large.</p>
<p>At times, a mixture of zeros occurs naturally. It may not come about because of neglecting to ask a critical question on a survey, but the information about the subpopulation may simply not be ascertainable. For example, visitors from a state park were asked as they departed how many fish they caught, but those who report 0 could be either non-fishers or fishers who had bad luck. These kinds of circumstances occur often enough that ZIP models are becoming increasingly common.</p>
<p>Actually there are many fewer ordinary Poisson regression applications in contrast to ZIPs and other Poisson modeling approaches such as hurdle models and quasi-Poisson applications. So it is worth taking a look at these variations of Poisson regression models. Not enough detail is presented here to deal with certain nuances of zero-inflated models, but we want you to know about models of this type. ZIP models demonstrate that modeling can be flexible and creative which we hope you see as a theme throughout this book.</p>
</div>
</div>
<div id="references" class="section level2">
<h2><span class="header-section-number">4.14</span> References</h2>
</div>
<div id="exercises-3" class="section level2">
<h2><span class="header-section-number">4.15</span> Exercises</h2>
<div id="exer:concept" class="section level3">
<h3><span class="header-section-number">4.15.1</span> Conceptual Exercises</h3>
<ol style="list-style-type: decimal">
<li>What are features of inferential OLS models that make them less suitable for count data?</li>
<li>Models of the form <span class="math inline">\(Y_i=\beta_0+\beta_1X_i, \epsilon \sim iidN(0,\sigma)\)</span> are fit using the method of least squares [note that least squares estimates for linear regression are also MLEs]. What method is used to fit Poisson regression models?</li>
<li>What should be done before adjusting for overdispersion?</li>
<li>Why is quasilikelihood used and how do the results compare for corresponding models using likelihoods?</li>
<li>Why is the log of means, log(<span class="math inline">\(\bar{Y}\)</span>), not <span class="math inline">\(\bar{Y}\)</span>, plotted against X when assessing the assumptions for Poisson regression?</li>
<li>How can this assumption of <em>mean=variance</em> be checked for Poisson regression? What if there are not many repeated observations at each level of X?</li>
<li>Is it possible that a predictor is significant for a model fit using a likelihood, but not for a model for the same data fit using a quasilikelihood? Explain.</li>
</ol>
<p>Complete (a)-(d) in the context of the study for Exercises 8-10.</p>
<ol style="list-style-type: lower-alpha">
<li>Define the response.</li>
<li>What are the possible values for the response?<br />
</li>
<li>What does <span class="math inline">\(\lambda\)</span> represent?</li>
<li>Would a zero-inflated model be considered here? If so, what would be a “true zero?”</li>
</ol>
<ol start="8" style="list-style-type: decimal">
<li><p><strong>Fish (Poisson)</strong> A state wildlife biologist collected data from 250 park visitors as they left at the end of their stay. Each were asked to report the number of fish they caught during their one week stay. On average visitors caught 21.5 fish per week.</p></li>
<li><p><strong>Methadone Program Recidivism.</strong> Program facilitators keep track of the number of times their program’s patients relapse within five years of initial treatment. Data on 100 patients yielded a mean number of 2.8 relapses per patient within the five years of initial treatment.</p></li>
<li><p><strong>Clutch size.</strong> Thirty nests were located and the number of eggs in each nest are counted at the start of a season. Later in the season following a particularly destructive storm, the mean clutch size of the 30 nests was only 1.7 eggs per nest.</p></li>
<li><p><strong>Credit card use</strong> A survey of 1,000 consumers asked respondents how many credit cards they use. Interest centers on the relationship between credit card use and income, in $10,000. The estimated coefficient for income is 2.1.</p>
<ul>
<li>Identify the predictor and interpret the estimated coefficient for the predictor in this context.</li>
<li>Describe how the assumption of linearity can be assessed in this example.</li>
<li>Suggest a way in which to assess the equal mean and variance assumption.</li>
</ul></li>
<li><p><strong>Dating Online</strong> Researchers are interested in the number of dates respondents arranged online and whether the rates differ by age group. Questions which elicit responses similar to this can be found in the Pew survey concerning dating online and relationships (Pew 2013). Each survey respondent was asked how many dates they have arranged on line in the past 3 months as well as the typical amount of time, <span class="math inline">\(t\)</span>, in hours, they spend on line weekly. Some rows of data appear below.</p></li>
</ol>
<table>
<thead>
<tr class="header">
<th align="right">Age</th>
<th align="right">Time online</th>
<th align="right">Number of dates arranged online</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">19</td>
<td align="right">35</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="right">29</td>
<td align="right">20</td>
<td align="right">5</td>
</tr>
<tr class="odd">
<td align="right">38</td>
<td align="right">15</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">55</td>
<td align="right">10</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<ul>
<li>Identify the response, predictor and offset in this context.</li>
<li>Write out a model for this data. As part of your model description, define the parameter, <span class="math inline">\(\lambda\)</span>.</li>
<li>Consider a Zero-inflated Poisson model for this data. Describe what the `true zeros’ would be in this setting.</li>
</ul>
<ol start="14" style="list-style-type: decimal">
<li><strong>Poisson Approximation: Rare Events</strong> For rare diseases, the probability of a case occurring, <span class="math inline">\(p\)</span>, in a very large population, <span class="math inline">\(n\)</span>, is small. With a small <span class="math inline">\(p\)</span> and large <span class="math inline">\(n\)</span>, the random variable <span class="math inline">\(Y\)</span>= the number of cases out of <span class="math inline">\(n\)</span> people can be approximated using a Poisson random variable with <span class="math inline">\(\lambda = np\)</span>. If the count of those with the disease is observed in several different populations independently of one another, the <span class="math inline">\(Y_i\)</span> represents the number of cases in the <span class="math inline">\(i^{th}\)</span> population and can be approximated using a Poisson random variable with <span class="math inline">\(\lambda_i=n_ip_i\)</span> where <span class="math inline">\(p_i\)</span> is the probability of a case for the <span class="math inline">\(i^{th}\)</span> population. Poisson regression can take into account the differences in the population sizes, <span class="math inline">\(n_i\)</span>, using as an offset which is the log(<span class="math inline">\(n_i\)</span>). The coefficient of the offset is set at one, it is not estimated like the other coefficients.Thus the model statement has the form: <span class="math display">\[
log(\lambda_i) = \beta_0+\beta_1x_i + log(n_i)
\]</span> where <span class="math inline">\(Y_i \sim\)</span> Poisson(<span class="math inline">\(n_i\lambda_i\)</span>). Note that <span class="math inline">\(\lambda_i\)</span> depends on <span class="math inline">\(x_i\)</span> which may differ for the different populations.</li>
</ol>
<p><strong>Skin Cancer: an example.</strong> Data from Scotto, Kopf, and Urbach (1974) reported the number of cases of non melanoma skin cancer for women by age group in two metropolitan areas (Minneapolis-St Paul and Dallas-Ft Worth); the year is unknown. They wondered if cancer rates by age group differ by city? The columns contain: number of cases of skin cancer, population size of the age group per city, age group (1=15-24, 2=25-34, 3=35-44, 4=45-54, 5=55-64, 6=65-74, 7=75-84, 8=85+), and metropolitan area (1=Minneapolis-St Paul, 2=Dallas-Ft Worth).</p>
<table>
<thead>
<tr class="header">
<th align="right">Number of Cases</th>
<th align="right">Population</th>
<th align="left">Age Group</th>
<th align="right">City</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">172675</td>
<td align="left">15-24</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="right">16</td>
<td align="right">123065</td>
<td align="left">25-34</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">226</td>
<td align="right">29007</td>
<td align="left">75-84</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td align="right">65</td>
<td align="right">7538</td>
<td align="left">85+</td>
<td align="right">2</td>
</tr>
</tbody>
</table>
<p>Identify the following quantities which appear in the description of the Poisson approximation for rare events:</p>
<ul>
<li>A case,</li>
<li>The population size, n,</li>
<li>The random variable <span class="math inline">\(Y=\)</span>the number of events out of <span class="math inline">\(n\)</span> trials,</li>
<li>The offset</li>
<li>The corresponding Poisson random variables, and</li>
<li>The predictors.</li>
</ul>
</div>
<div id="guided-exercise-2" class="section level3">
<h3><span class="header-section-number">4.15.2</span> Guided Exercise</h3>
<ol style="list-style-type: decimal">
<li><strong>Elephant Mating</strong> How does age affect male elephant mating patterns? An article by Poole (1989) investigated whether mating success in male elephants increases with age and whether there is a peak age for mating success. To address this question, the research team followed 41 elephants for one year and recorded both their ages and their number of matings. The data is found in <strong>elephant.csv,</strong> and relevant R code can be found under elephantMating.R.</li>
</ol>
<p>The variables are:</p>
<p>MATINGS: the number of matings in a given year</p>
<p>AGE: the age of the elephant in years.</p>
<ol style="list-style-type: lower-alpha">
<li>Create a histogram of MATINGS. Is there preliminary evidence that number of matings could be modeled as a Poisson response? Explain.</li>
<li>Plot MATINGS by AGE. Add a least squares line. Is there evidence that modeling matings using a linear regression with age might not be appropriate? Explain.</li>
<li>For each age, calculate the mean number of matings. Take the log of each mean and plot it by AGE.
<ol style="list-style-type: lower-roman">
<li>What assumption can be assessed with this plot?</li>
<li>Is there evidence of a quadratic trend on this plot?</li>
</ol></li>
<li>Fit a Poisson regression model with a linear term for AGE. Interpret the coefficient for AGE. Exponentiate and interpret the result.</li>
<li>Construct a 95% confidence interval for the slope and interpret in context (you may want to exponentiate endpoints).</li>
<li>Are the number of matings significantly related to age? Test with
<ol style="list-style-type: lower-roman">
<li>a Wald test and</li>
<li>a drop in deviance test.</li>
</ol></li>
<li>Add a quadratic term in AGE to determine whether there is a maximum age for the number of matings for elephants. Is a quadratic model preferred to a linear model? To investigate this question, use
<ol style="list-style-type: lower-roman">
<li>a Wald test and</li>
<li>a drop in deviance test.</li>
</ol></li>
<li>What can we say about the goodness of fit of the model with age as the sole predictor? Compare the residual deviance for the linear model to a <span class="math inline">\(\chi^2\)</span> distribution with the residual model degrees of freedom.</li>
<li>Fit the linear model using a quasilikelihood. (Why?)
<ol style="list-style-type: lower-roman">
<li>How do the estimated coefficients change?</li>
<li>How do the standard errors change?</li>
<li>What is the estimated dispersion parameter?</li>
<li>An estimated dispersion parameter greater than one suggests overdispersion. When adjusting for overdispersion, are you more of less likely to obtain a significant result when testing coefficients? Why?</li>
</ol></li>
</ol>
<p>Source: <span class="citation">[@Ramsey2002]</span>.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Sensitivity training</strong></li>
</ol>
<p>Microaggressions have been defined as “brief, everyday exchanges that send denigrating messages to certain individuals because of their group membership.” <span class="citation">[@Sue2010]</span>. Microaggressions are different from overt, deliberate acts of bigotry, such as the use of racist epithets, because the people perpetrating microaggressions often intend no offense and are unaware they are causing harm. A (hypothetical) study was conducted to determine whether sensitivity training would reduce the number of microaggressions.</p>
<p>Students from the dominant culture were randomly selected from a student population in a small liberal arts college. Participants were randomly assigned to one, two, three or four days of sensitivity training. A control group received no training. Following the completion of the training, subjects agreed to be observed while taking part in several task-oriented activities and discussions over the course of one or more hours. The number of hours under surveillance varied due to the availability of the participant. The data is recorded in <strong>sensitivity.csv</strong>.</p>
<p><code>id</code> = Subject identifier</p>
<p><code>daysTraining</code> = Days of sensitivity training</p>
<p><code>microaggressions</code> = Number of observed microaggressions</p>
<p><code>hrsSurv</code> = Number of hours under observation since the completion of the sensitivity training</p>
<ol style="list-style-type: lower-alpha">
<li>How many students took part in the study? How many students had none, one, two, three or four days of training? What is the distribution of the number of hours of surveillance?<br />
</li>
<li>Plot the distribution of the number of microaggressions. Does the distribution suggest that a Poisson regression would be useful for modeling? Why is this plot not expected to display a single Poisson distribution?</li>
<li>Does it appear that average number of microaggressions differs for different levels of sensitivity training?</li>
<li>Why is it misleading to simply compare the average number of microaggressions by hours of training?</li>
<li>Does the mean number of microaggressions per hour differ for different levels of training? In what way?</li>
<li>Fit the model with the offset <span class="math inline">\(log(hrsSurv)\)</span> and interpret the coefficients.</li>
<li>Determine how well the model fits using the deviance test.</li>
<li>Fit a model using quasilikelihood. How does this approach change the model results?</li>
</ol>
<p>Source: <span class="citation">[@Sue2010]</span> ISBN 0-470-49140-X.</p>
<ol start="3" style="list-style-type: decimal">
<li><p><strong>Bullfrogs</strong> Big Bullfrog on the Pond: Use the field observation bullfrog data <strong>bullfrogs.csv</strong> to determine whether there is convincing evidence that the number of mates is related to the size of the bullfrog.</p>
<ol style="list-style-type: lower-alpha">
<li>Graph number of mates by size and comment.</li>
<li>Graph log(number of mates) by size and comment.</li>
<li>Write out the likelihood for the Poisson regression model.</li>
<li>Fit the Poisson regression model and interpret the coefficient. Provide a measure of uncertainty.</li>
<li>Conduct a goodness-of-fit test.</li>
<li>Look at the residuals and comment.</li>
<li>Is there evidence of overdispersion? Explain.</li>
</ol></li>
</ol>
<p>Source: <span class="citation">[@Ramsey2002]</span>.</p>
</div>
<div id="open-ended" class="section level3">
<h3><span class="header-section-number">4.15.3</span> Open-ended</h3>
<ol style="list-style-type: decimal">
<li><strong>Current Population Survey: Number of children at home.</strong> We examine factors associated with the number of children at home in the U.S. using an (admittedly old) sample from the March 1993 U. S. Current Population Survey (CPS). This data set is the <strong>Health Insurance and Hours Worked By Wives (HI)</strong> available through the Data Sets for Econometrics <code>Ecdat</code> package in R. There are 22,272 observations in <code>data(HI)</code> of which we sample 1000. We will focus on the following 12 variables:</li>
</ol>
<ul>
<li><code>whrswk</code> = hours worked per week by wife</li>
<li><code>hhi</code> = wife covered by husband’s health insurance (HI) ?</li>
<li><code>whi</code> = wife has HI thru her job ?</li>
<li><code>hhi2</code> = husband has HI thru own job ?</li>
<li><code>education</code> = a factor with levels, “&lt; 9years”, “9-11years”, “12years”, “13-15years”, “16years”, “&gt; 16years”</li>
<li><code>race</code> = one of white, black, other</li>
<li><code>hispanic</code> = hispanic ?</li>
<li><code>experience</code> = years of potential work experience</li>
<li><code>kidslt6</code> = number of kids under age of 6 at home</li>
<li><code>kids618</code> = number of kids 6-18 years old at home</li>
<li><code>husby</code> = husband’s income in thousands of dollars</li>
<li><code>region</code> = one of other, northcentral, south, west</li>
<li><code>wght</code> = sampling weight</li>
</ul>
<p><em>Source</em> <span class="citation">[@Olson1998]</span></p>
<ol style="list-style-type: lower-alpha">
<li><strong>Preliminaries.</strong> First total up the number of childen (which counts the number of children still at home). Second, calculate the wife’s age, taking advantage of the <code>experience</code> variable which is years since the wife turned 16.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
HIsample =<span class="st"> </span><span class="kw">sample</span>(HI,<span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">totalKids=</span>kidslt6<span class="op">+</span>kids618, <span class="dt">age =</span> <span class="dv">15</span><span class="op">+</span>experience)</code></pre></div>
<p>It is nice to center continuous covariates so the intercepts are meaningful.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Centering income</span>
cIncome =<span class="st"> </span><span class="kw">with</span>(HIsample,husby<span class="op">-</span><span class="kw">mean</span>(husby))</code></pre></div>
<p>The levels for the <code>education</code> variable show up in a messy format when modeling, so we can relabel them.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">favstats</span>(totalKids<span class="op">~</span>education,<span class="dt">data=</span>HIsample)
<span class="kw">levels</span>(HIsample<span class="op">$</span>education)
<span class="kw">levels</span>(HIsample<span class="op">$</span>education) 
    <span class="kw">c</span>(<span class="st">&quot;Middle School&quot;</span>, <span class="st">&quot;Some HS&quot;</span>, <span class="st">&quot;HS Grad&quot;</span>, <span class="st">&quot;Some College&quot;</span>, 
    <span class="st">&quot;College Grad&quot;</span>, <span class="st">&quot;Grad School&quot;</span>)
<span class="co">#check:</span>
<span class="kw">favstats</span>(totalKids<span class="op">~</span>education,<span class="dt">data=</span>HIsample)</code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li><strong>EDA</strong>. Perform an exploratory data analysis using the HIsample data set. Use <code>totalKids</code> as the response variable.</li>
<li><strong>Modeling. Part I</strong>. Fit a series of models to investigate which factors are associated with the number of children at home. Start with model(s) involving <code>age</code>.</li>
<li><strong>Modeling. Part II</strong>.
<ol style="list-style-type: lower-roman">
<li>Consider assessing the need for fitting a zero-inflated by comparing the observed distribution of the number of totalKids to a modeled distribution of a Poisson model with <span class="math inline">\(\lambda\)</span> = mean(totalKids).<br />
</li>
<li>Fit the simple model which includes only age. Perform a lack-of-fit test.</li>
<li>What would a “true zero” be for a zero-inflated model in this case?</li>
<li>Fit a ZIP model detailing your choice of covariates for the Poisson and binomial portions of your model.</li>
<li>Fit a ZIP model with an offset for age. Defend your choice of covariates for the Poisson and binomial portions of your model.</li>
<li>Summarize the results of your modeling including interpretations of the estimated coefficients.</li>
</ol></li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li><strong>Airbnb</strong> In a break from traditional industrial models, companies like Airbnb and Uber are promoting the growth of a “sharing economy,” a way to supplement income by renting out or otherwise utilizing existing assets for individual profit. There are few barriers to entry to become a seller on the rental market for Airbnb, and its global reach provides an instantaneous way to make money for its wide user base. Airbnb is an online service that allows travelers to book a stay with only a few clicks at any given time. Customers are given the ability to tailor their travel experience to fit their budget and lifestyle, choosing from castles to tree houses, and finding plenty of offerings in rural towns as well as busy metropolitan areas.</li>
</ol>
<p>The range of options and immediate availability of many properties contribute to the rising popularity of Airbnb, but there has been little research done on the impact of individual user ratings for each listing on specific property features (such as location, number of bedrooms, etc.). As its consumer base expands across the globe, it is worth considering the factors that matter more or less to renters in different countries, and why that variation exists. With the data provided you can investigate the different housing characteristics associated with the number of reservations for an Airbnb listing and how these factors vary by country. London, New York City, and Sydney represent three of the top ten most popular destinations for both inbound and outbound guests, so those cities are included with this data to allow for an intercontinental comparative analysis of housing factors.</p>
<p>There are three data files <strong>(LONDON 2 W DATES.csv, NYC 2 W DATES.csv, SYDNEY 2 W DATES.csv)</strong> and a file with preliminary R code <strong>(Intro Code for Airbnb Data.R)</strong> to help you get started.</p>
<ol style="list-style-type: lower-alpha">
<li>Perform an analysis that describes variation in the number of reviews (a proxy for the number or rentals, which is not available) as a function of the variables provided. Don’t forget to consider an offset, if needed.</li>
<li>Use your model to determine whether there exists differences in this relationship between the cities.</li>
</ol>
<p>Source: <span class="citation">[@Awad2017]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Crab Satellites</strong> <span class="citation">[@Brockmann1996]</span> carried out a study of nesting female horseshoe crabs. Female horseshoe crabs often have male crabs attached to a female’s nest known as <em>satellites</em>. One objective of the study was to determine which characteristics of the female were associated with the number of satellites. Of particular interest is the relationship between the width of the female carapace and satellites. The data can be found in <strong>crab.csv</strong> It includes:</li>
</ol>
<ul>
<li><code>NumSat</code> = number of satellites</li>
<li><code>Width</code> = carapace width</li>
<li><code>Wt</code> = weight</li>
<li><code>Sp</code> = spine condition and</li>
<li><code>C</code> = color.</li>
</ul>
<p>Use Poisson regression to investigate the research question. Be sure you work to obtain an appropriate model before considering overdispersion.</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>Doctor Visits I</strong> Data available via the US National Medical Expenditure Study <span class="citation">[@NMES1988]</span> was used to study the demand for medical care as measured by the number of doctor visits. It was conducted by Deb and Trivedi and involved a study of 4406 person 66 years and older. <span class="citation">[@Deb1997]</span>.</li>
</ol>
<p>The R package, Applied Econometrics with R (AER), contains a number of datasets. Here we consider the dataset related to doctor visits. To access the data</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Install the package AER.</span>
<span class="kw">library</span>(AER)
<span class="kw">data</span>(NMES1988)
<span class="kw">help</span>(NMES1988)  <span class="co"># to see variable descriptions</span></code></pre></div>
<p>Use the number of office <code>visits</code> as your dependent variable. Define a well-articulated research question and perform an analysis that includes relevant EDA. Consider the use of zero-inflated Poisson regression.</p>
<ol start="5" style="list-style-type: decimal">
<li><strong>Doctor Visits II</strong> Data on doctor visits on a sample of 5,190 from the 1977/1978 Australian Health Survey. The study seeks to explain the variation in doctor visits using one or more explanatory variables. The data is an R data set accessible with the command <code>data(&quot;DoctorVisits&quot;)</code>. Variable descriptions can be found under <code>help(NMES1988)</code></li>
</ol>
<p>Explore the use of a zero-inflated model for this data. Begin with a histogram of the number of visits, some EDA and fitting several models. Summarize your results.</p>
<ol start="6" style="list-style-type: decimal">
<li><strong>More Fish</strong></li>
</ol>
<p>The number of fish caught, persons in the party, the number of children in the party, and the length of stay were recorded for 250 campers. The data can be found in <strong>fish2.csv</strong>.</p>
<p>Create and assess a model for the number of fish caught.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-distthry.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-glms.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
